{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/workspace/gatech/cs7643-deep-learning/contrastive-learning-in-distilled-models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_HOME = os.path.join(\n",
    "    '/',\n",
    "    'workspace',\n",
    "    'gatech',\n",
    "    'cs7643-deep-learning',\n",
    "    'contrastive-learning-in-distilled-models')\n",
    "\n",
    "%cd {PROJECT_HOME}"
   ]
  },
  {
   "source": [
    "## How STS evaluation works\n",
    "\n",
    "Refer to: https://github.com/facebookresearch/SentEval/blob/main/senteval/sts.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(fpath):\n",
    "    data = {'X_A': [], 'X_B': [], 'y': []}\n",
    "    with io.open(fpath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            text = line.strip().split('\\t')\n",
    "            data['X_A'].append(text[5].split())\n",
    "            data['X_B'].append(text[6].split())\n",
    "            data['y'].append(text[4])\n",
    "\n",
    "    data['y'] = [float(s) for s in data['y']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadFile('data/downstream/STS/STSBenchmark/sts-dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['A', 'man', 'with', 'a', 'hard', 'hat', 'is', 'dancing.']\n['A', 'man', 'wearing', 'a', 'hard', 'hat', 'is', 'dancing.']\n5.0\n"
     ]
    }
   ],
   "source": [
    "print(data['X_A'][0])\n",
    "print(data['X_B'][0])\n",
    "print(data['y'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_corpus = sorted(zip(data['X_A'],\n",
    "                           data['X_B'],\n",
    "                           data['y']),\n",
    "                       key=lambda z: (len(z[0]), len(z[1]), z[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(params, batch):\n",
    "    sentences = [' '.join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "    )\n",
    "    \n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch, output_hidden_states=True, return_dict=True)\n",
    "    \n",
    "    # Pooler\n",
    "    attention_mask = batch.attention_mask\n",
    "    last_hidden = outputs.last_hidden_state\n",
    "    hidden_states = outputs.hidden_states\n",
    "\n",
    "    first_hidden = hidden_states[0]\n",
    "    last_hidden = hidden_states[-1]\n",
    "    pooled_result = ((first_hidden + last_hidden) / 2.0 * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(-1).unsqueeze(-1)\n",
    "\n",
    "    return pooled_result.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = {}\n",
    "bsize = 5\n",
    "\n",
    "for txt_type in ['X_A', 'X_B']:\n",
    "    embed[txt_type] = []\n",
    "\n",
    "    for ii in range(0, len(data['y']), bsize):\n",
    "        batch = data[txt_type][ii:ii + bsize]\n",
    "        embeddings = batcher(None, batch)\n",
    "        embed[txt_type].append(embeddings)\n",
    "\n",
    "    embed[txt_type] = np.vstack(embed[txt_type])\n",
    "\n",
    "embed['y'] = np.array(data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1500, 768)\n"
     ]
    }
   ],
   "source": [
    "print(embed['X_A'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1500, 768)\n"
     ]
    }
   ],
   "source": [
    "print(embed['X_B'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "print(embed['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels, nclass=5):\n",
    "    \"\"\"\n",
    "    Label encoding from Tree LSTM paper (Tai, Socher, Manning)\n",
    "    \"\"\"\n",
    "    Y = np.zeros((len(labels), nclass)).astype('float32')\n",
    "    for j, y in enumerate(labels):\n",
    "        for i in range(nclass):\n",
    "            if i+1 == np.floor(y) + 1:\n",
    "                Y[j, i] = y - np.floor(y)\n",
    "            if i+1 == np.floor(y):\n",
    "                Y[j, i] = np.floor(y) - y + 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senteval.utils import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentA = embed['X_A']\n",
    "sentB = embed['X_B']\n",
    "Y = encode_labels(embed['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = []\n",
    "for i in range(sentA.shape[0]):\n",
    "    sim.append(cosine(sentA[i, :], sentB[i, :]))\n",
    "sim = np.array(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6321576605053028, 3.5669448020499635e-168)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "pearsonr(sim, embed['y'])"
   ]
  }
 ]
}