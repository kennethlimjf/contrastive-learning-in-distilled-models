{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Learning From Scratch - DistilBERT\n",
    "\n",
    "An attempt to build contrastive learning model from scratch. Parts include:\n",
    "\n",
    "- Loading and preparing Wiki-1M data for model input\n",
    "- Contrastive learning model\n",
    "  - Forward passing using pre-trained model\n",
    "  - Constrastive layer\n",
    "  - Calculate loss\n",
    "- Training procedure\n",
    "  - Default trainer optimizer\n",
    "  - Default trainer hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set Project home\n",
    "PROJECT_HOME = os.path.join('/',\n",
    "                            'Users',\n",
    "                            'ng-ka',\n",
    "                            'OMSCS',\n",
    "                            'DL',\n",
    "                            'DLProject',\n",
    "                            'contrastive-learning-in-distilled-models')\n",
    "%cd {PROJECT_HOME}\n",
    "\n",
    "# Load project code\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "#import distilface\n",
    "import src.distilface as distilface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ng-ka\\\\OMSCS\\\\DL\\\\DLProject\\\\contrastive-learning-in-distilled-models'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertCLModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertCLModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel, DistilBertPreTrainedModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPooling\n",
    "\n",
    "from src.distilface.modules.pooler import Pooler\n",
    "from src.distilface.modules.similarity import Similarity\n",
    "\n",
    "class DistilBertCLModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_last4', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        if self.training:\n",
    "            return self.cl_forward(self.distilbert, input_ids, attention_mask)\n",
    "        else:\n",
    "            return self.sent_emb(self.distilbert, input_ids, attention_mask)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None):\n",
    "        batch_size = input_ids.size(0)#64#input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "\n",
    "pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "#model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertCLModel(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): Pooler()\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('batch128_model.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model =torch.quantization.quantize_dynamic(model, qconfig_spec={nn.Linear},  dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  fp32  \t Size (KB): 265489.337\n",
      "model:  int8  \t Size (KB): 138116.329\n",
      "1.92 times smaller\n"
     ]
    }
   ],
   "source": [
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size\n",
    "\n",
    "# compare the sizes\n",
    "f=print_size_of_model(model,\"fp32\")\n",
    "q=print_size_of_model(quantized_model,\"int8\")\n",
    "print(\"{0:.2f} times smaller\".format(f/q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following does not succeed due to lack of compatibility of our model with Torch Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedNodeError",
     "evalue": "GeneratorExp aren't supported:\n  File \"C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\modeling_utils.py\", line 999\n    \n        x=False\n        for it_element in (hasattr(m, \"gradient_checkpointing\") and m.gradient_checkpointing for m in self.modules()):\n                          ~ <--- HERE\n            if it_element:\n                x = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedNodeError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scripted_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\_script.py:1265\u001b[0m, in \u001b[0;36mscript\u001b[1;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m   1264\u001b[0m     obj \u001b[38;5;241m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[1;32m-> 1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_methods_to_compile\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_script_dict(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\_recursive.py:454\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[1;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[0;32m    453\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\_recursive.py:467\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[1;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[0;32m    465\u001b[0m cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_create_module_with_type(concrete_type\u001b[38;5;241m.\u001b[39mjit_type)\n\u001b[0;32m    466\u001b[0m method_stubs \u001b[38;5;241m=\u001b[39m stubs_fn(nn_module)\n\u001b[1;32m--> 467\u001b[0m property_stubs \u001b[38;5;241m=\u001b[39m \u001b[43mget_property_stubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m hook_stubs, pre_hook_stubs \u001b[38;5;241m=\u001b[39m get_hook_stubs(nn_module)\n\u001b[0;32m    470\u001b[0m user_annotated_ignored_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(nn_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__jit_ignored_attributes__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\_recursive.py:781\u001b[0m, in \u001b[0;36mget_property_stubs\u001b[1;34m(nn_module)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;124;03mCreate property stubs for the properties of the module by creating method\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;124;03mstubs for the getter and setter.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    780\u001b[0m module_ty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(nn_module)\n\u001b[1;32m--> 781\u001b[0m properties_asts \u001b[38;5;241m=\u001b[39m \u001b[43mget_class_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_ty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRecursiveScriptModule\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m rcbs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(module_ty):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\frontend.py:161\u001b[0m, in \u001b[0;36mget_class_properties\u001b[1;34m(cls, self_name)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prop[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m unused_properties \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_drop(prop[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfget):\n\u001b[1;32m--> 161\u001b[0m         getter \u001b[38;5;241m=\u001b[39m \u001b[43mget_jit_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_getter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m         setter \u001b[38;5;241m=\u001b[39m get_jit_def(prop[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfset, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprop[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_setter\u001b[39m\u001b[38;5;124m\"\u001b[39m, self_name\u001b[38;5;241m=\u001b[39mself_name) \u001b[38;5;28;01mif\u001b[39;00m prop[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfset \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    163\u001b[0m         properties\u001b[38;5;241m.\u001b[39mappend(Property(getter\u001b[38;5;241m.\u001b[39mrange(), Ident(getter\u001b[38;5;241m.\u001b[39mrange(), prop[\u001b[38;5;241m0\u001b[39m]), getter, setter))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\frontend.py:264\u001b[0m, in \u001b[0;36mget_jit_def\u001b[1;34m(fn, def_name, self_name, is_classmethod)\u001b[0m\n\u001b[0;32m    261\u001b[0m     qualname \u001b[38;5;241m=\u001b[39m get_qualified_name(fn)\n\u001b[0;32m    262\u001b[0m     pdt_arg_types \u001b[38;5;241m=\u001b[39m type_trace_db\u001b[38;5;241m.\u001b[39mget_args_types(qualname)\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdef_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdt_arg_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdt_arg_types\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\frontend.py:315\u001b[0m, in \u001b[0;36mbuild_def\u001b[1;34m(ctx, py_def, type_line, def_name, self_name, pdt_arg_types)\u001b[0m\n\u001b[0;32m    310\u001b[0m     type_comment_decl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mparse_type_comment(type_line)\n\u001b[0;32m    311\u001b[0m     decl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mmerge_type_from_type_comment(decl, type_comment_decl, is_method)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Def(Ident(r, def_name),\n\u001b[0;32m    314\u001b[0m            decl,\n\u001b[1;32m--> 315\u001b[0m            \u001b[43mbuild_stmts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\frontend.py:137\u001b[0m, in \u001b[0;36mbuild_stmts\u001b[1;34m(ctx, stmts)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_stmts\u001b[39m(ctx, stmts):\n\u001b[1;32m--> 137\u001b[0m     stmts \u001b[38;5;241m=\u001b[39m [build_stmt(ctx, s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m stmts]\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, stmts))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\frontend.py:137\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_stmts\u001b[39m(ctx, stmts):\n\u001b[1;32m--> 137\u001b[0m     stmts \u001b[38;5;241m=\u001b[39m [\u001b[43mbuild_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m stmts]\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, stmts))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\frontend.py:287\u001b[0m, in \u001b[0;36mBuilder.__call__\u001b[1;34m(self, ctx, node)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedNodeError(ctx, node)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\frontend.py:609\u001b[0m, in \u001b[0;36mStmtBuilder.build_For\u001b[1;34m(ctx, stmt)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stmt\u001b[38;5;241m.\u001b[39morelse:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotSupportedError(r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melse branches of for loops aren\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m For(\n\u001b[0;32m    608\u001b[0m     r, [build_expr(ctx, stmt\u001b[38;5;241m.\u001b[39mtarget)],\n\u001b[1;32m--> 609\u001b[0m     [\u001b[43mbuild_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m)\u001b[49m], build_stmts(ctx, stmt\u001b[38;5;241m.\u001b[39mbody))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\frontend.py:286\u001b[0m, in \u001b[0;36mBuilder.__call__\u001b[1;34m(self, ctx, node)\u001b[0m\n\u001b[0;32m    284\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuild_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedNodeError(ctx, node)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(ctx, node)\n",
      "\u001b[1;31mUnsupportedNodeError\u001b[0m: GeneratorExp aren't supported:\n  File \"C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\modeling_utils.py\", line 999\n    \n        x=False\n        for it_element in (hasattr(m, \"gradient_checkpointing\") and m.gradient_checkpointing for m in self.modules()):\n                          ~ <--- HERE\n            if it_element:\n                x = True\n"
     ]
    }
   ],
   "source": [
    "scripted_model = torch.jit.script(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempts with the alternative method of tracing were also not successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tracer cannot infer type of BaseModelOutputWithPooling(last_hidden_state=tensor([[[-2.8095e-01,  1.9375e-01, -2.3601e-01,  ...,  2.4750e-04,\n           1.8413e-01,  7.4281e-01],\n         [-2.0558e-01,  5.6973e-01, -3.4450e-01,  ...,  3.1061e-01,\n           7.4593e-03,  6.6465e-01],\n         [-2.6471e-01,  4.7577e-01, -8.7475e-01,  ...,  4.3364e-01,\n           1.6303e-02,  1.2238e+00],\n         ...,\n         [ 2.1979e-01,  2.8544e-02, -4.8508e-01,  ...,  1.5100e-01,\n           5.6132e-01,  6.3370e-01],\n         [ 8.1528e-02,  5.9031e-01, -1.4732e-01,  ..., -5.9024e-02,\n           5.9021e-01,  8.1966e-01],\n         [-7.2517e-03,  1.6594e-01, -7.6334e-01,  ...,  5.0187e-01,\n           3.8227e-01,  5.1416e-01]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 4.6693e-02,  4.0107e-02, -3.7071e-01, -2.7972e-02, -9.5654e-02,\n         -8.7964e-02,  1.8528e-02,  2.7150e-01, -2.4230e-01,  9.8927e-05,\n         -3.4853e-01, -5.7866e-01, -1.3977e-01,  3.4567e-01, -3.4365e-01,\n         -9.6294e-03, -2.6303e-02, -2.1803e-01, -1.1859e-01,  7.5814e-02,\n          2.7154e-01, -2.1654e-01, -3.3980e-01,  3.5713e-01,  7.2184e-02,\n          7.7747e-02,  2.0000e-01,  3.3041e-01,  1.5145e-01, -3.1463e-01,\n         -8.3670e-03, -6.3714e-02,  4.2273e-01,  2.9969e-01,  5.7845e-02,\n          2.3974e-01, -4.7594e-02, -1.6258e-01, -1.6344e-01, -1.2472e-01,\n         -1.7768e-01,  5.6963e-03, -2.2802e-01,  6.1100e-04,  4.6322e-01,\n         -3.9256e-02,  4.0616e-01, -3.4898e-01,  8.9205e-02, -1.6020e-01,\n          9.7896e-02, -1.6947e-01,  2.7750e-02,  3.5056e-01,  2.2463e-01,\n         -2.5251e-02, -8.3530e-02,  1.1967e-02,  1.8789e-01,  3.0655e-01,\n          6.2255e-02, -3.2581e-02,  2.6660e-02, -9.0701e-02, -3.4137e-01,\n         -2.6564e-01, -1.7123e-01,  3.8302e-01, -5.6068e-01,  1.9953e-01,\n          1.5175e-01,  2.5360e-01,  1.3732e-01, -1.1475e-01,  5.0170e-02,\n          2.9594e-01,  4.7890e-01,  8.9323e-02,  4.1593e-01,  2.3964e-01,\n          2.2769e-01,  1.6559e-01,  2.8347e-01,  1.4929e-01,  2.6771e-01,\n         -1.7873e-01, -1.1776e-01, -8.1478e-02, -2.2917e-01,  6.6764e-02,\n         -1.5156e-01,  1.4597e-01,  1.7807e-01, -7.8407e-02, -1.1961e-02,\n         -5.5800e-03,  3.2663e-02, -3.6713e-02, -1.0436e-01, -2.6302e-01,\n          2.9339e-01,  2.6338e-01, -8.5827e-03,  2.8918e-01,  2.0783e-01,\n          6.6061e-02,  8.6752e-02,  2.6657e-01, -2.1378e-01,  5.5170e-01,\n         -3.0502e-01,  1.9279e-02,  2.0699e-01, -4.1495e-01, -1.3450e-03,\n         -3.4352e-02, -6.2233e-01,  5.7239e-02, -5.3565e-01, -1.9556e-01,\n          2.1748e-01, -2.5492e-02, -1.7693e-01, -9.1041e-02, -8.2664e-02,\n          1.1888e-01, -2.6719e-01,  1.9183e-01, -8.6937e-02, -1.1656e-01,\n          9.3656e-02, -2.4710e-01,  4.2405e-01, -9.8818e-02, -1.9976e-01,\n          5.9881e-02, -2.5661e-01, -4.5558e-04,  5.4826e-02, -9.8980e-02,\n         -2.1050e-01, -3.2874e-02, -1.3713e-01,  1.4698e-01,  1.3910e-01,\n         -1.8795e-01,  2.5036e-02,  1.5718e-01,  7.8290e-02,  3.4586e-01,\n         -1.9084e-01, -2.4636e-01, -2.7752e-01, -3.2277e-01, -2.1060e-01,\n          1.5730e-02, -1.6699e-01, -4.1642e-01,  1.0134e-01,  1.4960e-01,\n         -1.6346e-01, -5.3434e-01, -2.3700e-01, -4.8405e-01, -4.0551e-01,\n          1.3371e-01,  1.7637e-01, -4.6814e-01,  2.1758e-01, -9.9638e-02,\n         -6.6738e-02,  5.5015e-01,  1.1654e-01,  1.7745e-02, -4.3454e-01,\n         -9.5787e-02,  3.9904e-01, -1.8967e-01,  1.4247e-01,  4.7395e-01,\n         -1.0383e-02, -2.8846e-02, -4.6897e-02, -1.0486e-01, -5.7609e-01,\n         -3.6152e-01,  2.1397e-01, -3.2449e-01,  3.2640e-01,  1.3473e-01,\n         -4.2674e-02,  3.7581e-01, -1.7810e-01, -1.5909e-01,  4.2082e-01,\n          2.9741e-01, -1.1551e-01, -3.5975e-01,  3.0413e-01,  2.8718e-01,\n          8.3572e-02, -7.6330e-02,  3.6599e-01, -3.5791e-01, -1.1984e-01,\n          4.6330e-02, -2.1017e-01,  9.6010e-02,  2.5951e-01,  3.1474e-01,\n          3.2159e-01,  1.7671e-01, -8.4449e-02,  1.2721e-01,  6.9955e-02,\n          3.3938e-01, -3.6960e-02, -2.6437e-01, -3.6957e-01, -3.1519e-01,\n         -2.8044e-01, -3.1960e-02, -3.2118e-01, -3.3568e-01,  5.6361e-02,\n         -7.9344e-02, -1.0817e-01, -4.1884e-01,  5.6373e-01,  1.7060e-01,\n         -3.7492e-01, -4.9206e-01, -1.1492e-01, -5.3896e-02, -1.0919e-01,\n         -2.6218e-01,  2.0154e-01,  4.4679e-02,  6.2231e-02,  8.6094e-02,\n         -1.1548e-01,  4.0717e-01,  1.0435e-01,  1.1964e-01,  5.5811e-02,\n         -1.3387e-01, -3.0432e-01,  1.9487e-01, -2.3411e-01,  2.3979e-01,\n          8.3957e-02, -1.7051e-01,  2.9582e-01,  7.6980e-02, -2.1012e-01,\n         -2.2019e-01,  5.1967e-02, -2.0904e-01, -3.1589e-01,  1.3976e-01,\n          7.3378e-02,  1.2886e-02, -3.7941e-02, -4.1992e-01, -6.7913e-01,\n         -3.8605e-02,  3.3250e-01, -1.4962e-01, -2.3367e-01,  2.1604e-02,\n          9.5433e-01, -3.3314e-01,  3.3863e-02, -1.1041e-01,  1.3514e-01,\n          1.7344e-01,  3.0827e-01,  1.9480e-02,  1.3813e-01,  7.5715e-03,\n          2.6293e-01,  1.4490e-01, -3.7647e-01,  2.0370e-01, -1.2067e-01,\n         -1.9894e-01, -2.9209e-01, -1.8561e-01, -2.8015e-01, -1.9971e-01,\n          7.9241e-02,  2.7789e-01,  2.0711e-01,  9.2009e-02, -1.2497e-01,\n          1.3548e-02, -4.1796e-01, -9.4340e-02,  3.9416e-02,  4.4411e-02,\n         -2.0689e-01,  7.8503e-02,  2.8727e-01,  4.8503e-01, -3.9871e-01,\n          5.5450e-02, -2.8031e-01, -1.6286e-01,  3.7779e-01, -4.2408e-01,\n          4.3749e-03,  1.3447e-01, -7.2981e-02, -2.7551e-01, -1.6305e-01,\n         -1.8913e-01, -4.5124e-02,  1.1433e-01, -1.1529e-01,  1.6803e-01,\n         -4.9927e-02,  3.2612e-02, -1.4389e-01, -6.5885e-01, -6.7365e-02,\n         -1.4673e-01, -4.8238e-02, -1.4534e-01,  6.4086e-01,  3.6175e-01,\n         -1.3694e-01, -3.0026e-01,  4.9679e-01, -1.2416e-01, -3.7848e-01,\n         -2.7967e-01, -3.2192e-02, -5.8232e-01,  2.5316e-01, -3.7612e-01,\n         -7.5341e-02, -1.0061e-01, -4.2381e-01,  2.0430e-01,  3.5421e-01,\n          4.7512e-01, -2.4318e-02, -3.1277e-01,  5.9076e-02, -2.8672e-01,\n         -2.0519e-01,  1.0690e-01,  2.1698e-01, -4.6779e-01, -4.2751e-01,\n         -7.9820e-02, -1.0694e-01, -1.5257e-01, -2.0322e-01,  2.8396e-01,\n         -9.1225e-02,  5.7800e-02,  2.5577e-01, -3.4644e-01,  1.6233e-01,\n          6.3564e-01, -3.3724e-01,  1.9419e-01, -3.6530e-01,  1.0729e-01,\n         -4.0173e-01, -3.8239e-01, -1.6141e-01,  7.4453e-02, -4.3982e-01,\n         -3.7165e-01,  9.4542e-02, -3.9154e-01, -2.8783e-01, -2.0081e-01,\n          2.1023e-02, -3.1915e-01,  5.1339e-01,  4.0421e-02, -5.2414e-01,\n         -1.3860e-01,  5.0436e-01, -4.0707e-01, -5.7195e-01,  2.2586e-02,\n         -2.6875e-01,  1.8693e-01, -2.5197e-01,  4.9181e-01, -5.9845e-01,\n         -6.9314e-02, -5.7444e-02,  7.7586e-02,  3.3125e-02,  1.4080e-01,\n         -1.8913e-01,  1.2483e-01,  1.8294e-01, -1.0081e+00,  2.8459e-01,\n          2.2694e-01,  2.5965e-01, -7.4635e-02,  3.8446e-01, -4.5130e-01,\n         -1.8509e-01,  8.3799e-02,  1.6537e-01,  3.1572e-01,  7.6182e-02,\n          1.5847e-01,  3.7006e-01,  3.2070e-01,  2.1765e-01,  1.5052e-01,\n         -4.7995e-01, -4.4966e-01, -3.5002e-01,  1.4406e-01, -8.8948e-02,\n          5.1441e-01, -4.1660e-01,  3.4986e-01, -1.1441e-01, -1.0048e-01,\n          1.6408e-01,  8.8887e-02,  1.5933e-01,  9.3904e-02,  1.1400e-01,\n          1.8206e-01,  3.3361e-01, -1.2313e-01, -3.8495e-01,  2.2998e-01,\n          1.0782e-01, -4.6062e-01, -2.9444e-01,  2.4281e-01, -1.2217e-01,\n         -2.4393e-01,  1.8185e-01, -4.1725e-01, -3.6603e-01, -7.4732e-02,\n          3.1326e-01, -1.5488e-01, -6.4646e-01, -8.3071e-02,  2.3564e-02,\n         -3.8589e-01,  1.0421e-01, -1.0521e-01, -1.6525e-01, -1.1996e-01,\n          1.4955e-01,  2.4033e-01, -8.6674e-02, -5.4170e-01, -2.5583e-01,\n          5.6224e-02, -1.6628e-01, -4.1819e-01, -2.3568e-01, -4.9047e-01,\n          1.7005e-02,  3.6465e-04,  2.6325e-01, -2.7289e-01,  1.3864e-01,\n          8.5591e-02,  3.5195e-01, -5.7063e-02,  5.9695e-03,  3.2521e-02,\n         -1.8778e-01,  1.8255e-01,  2.8537e-01, -1.4293e-02,  1.1457e-02,\n         -3.1442e-01,  1.9079e-01, -3.3102e-01, -4.6480e-02, -2.7503e-01,\n          4.3797e-01,  2.5024e-01, -1.1668e-01, -1.2751e-01, -1.4074e-01,\n          1.5598e-01, -6.7441e-02, -1.0944e-01, -4.0199e-01,  1.6955e-01,\n         -3.8893e-01,  1.8294e-01,  1.3988e-01,  3.9773e-01, -1.6795e-01,\n          6.2370e-02, -8.5830e-02, -3.9306e-02, -3.4178e-01, -1.6844e-01,\n          7.8893e-03, -3.4126e-01,  4.5400e-01,  1.6699e-01, -4.2358e-01,\n         -1.6840e-01, -5.7318e-02,  3.9432e-02,  2.4061e-01,  1.4965e-01,\n          1.8138e-01, -6.6945e-02, -3.7419e-01, -7.3155e-02, -2.2167e-01,\n          1.9476e-01, -9.5210e-02,  2.7536e-01, -1.5343e-01, -5.6016e-01,\n         -6.1347e-02,  7.8486e-02,  2.2220e-02,  1.2293e-01,  1.9137e-02,\n          3.6239e-01, -3.9407e-03, -3.0480e-01,  1.0109e-01,  1.4238e-01,\n         -1.0127e-01,  1.8982e-01, -7.3263e-02, -2.4488e-01,  4.4750e-01,\n          3.5579e-01, -1.6979e-01,  1.6875e-01,  2.4465e-02, -1.2170e-01,\n         -9.6275e-02,  8.9936e-02,  6.1709e-01,  1.4500e-01, -4.8076e-01,\n         -3.0713e-01,  1.4727e-01, -7.0945e-03, -1.5526e-01,  9.5915e-02,\n          7.4484e-02,  4.3584e-01,  1.6116e-01, -5.9871e-01, -5.9422e-01,\n          7.6837e-02, -1.5509e-01, -3.6611e-01,  2.8282e-02,  3.7231e-01,\n          3.2762e-01,  2.2060e-02, -3.5888e-01, -2.4051e-01,  6.4066e-02,\n          3.5439e-01,  1.2462e-01,  1.6493e-01, -3.1871e-01,  5.5375e-02,\n          1.1820e-01,  8.3088e-01,  8.5695e-02, -1.1434e-02,  5.5705e-02,\n         -3.7754e-02,  1.1020e-01, -3.7759e-01,  1.2221e-01,  1.5877e-01,\n          3.7045e-01, -2.2702e-01,  4.3940e-01, -1.2291e-01,  6.0639e-02,\n          9.0442e-03, -1.1641e-01,  1.6571e-02, -2.3472e-01,  4.0214e-01,\n          6.4819e-03,  6.5207e-03, -6.6666e-01,  1.4141e-01, -1.0585e-01,\n         -2.4113e-01,  2.0391e-01, -1.0582e-01, -2.7862e-01, -1.3709e-01,\n          2.6258e-03, -7.9851e-02,  4.0725e-03, -4.6333e-01, -8.4179e-02,\n         -3.8501e-02, -2.1379e-01,  9.3424e-02, -3.2262e-01, -3.8604e-01,\n          2.5370e-01,  1.5727e-01, -7.4532e-01, -1.9181e-01,  1.5279e-01,\n         -2.5710e-01, -5.3802e-01,  3.6783e-01,  3.5995e-01, -2.0221e-01,\n         -2.0596e-01,  5.2864e-01,  2.7097e-01,  1.5769e-01,  4.6152e-01,\n         -4.7203e-01, -1.2711e-01,  2.9948e-02, -8.5174e-02, -2.4472e-01,\n         -1.4154e-01,  3.8125e-01,  2.8051e-01, -1.8072e-01,  4.8548e-01,\n          2.4945e-01,  1.4104e-01,  3.8624e-01, -2.8026e-01, -2.0120e-01,\n          2.8732e-02, -1.1231e-02, -3.6426e-01,  2.6251e-02, -3.7851e-02,\n          6.4009e-01, -1.5928e-01,  9.5855e-02, -6.6296e-02,  1.7410e-01,\n          3.8996e-02,  7.4717e-02, -1.3931e-01,  5.8656e-01,  4.9502e-01,\n         -2.6947e-02, -4.5381e-01, -2.7717e-01, -1.0380e-01, -1.1805e-01,\n          3.7948e-01,  9.4765e-02,  2.8403e-01,  1.1377e-01, -4.7931e-01,\n         -2.5457e-01,  1.8128e-02,  1.6517e-01,  3.1461e-01, -2.5417e-02,\n         -2.0248e-01, -4.7060e-02,  6.1397e-02,  5.4805e-01,  1.4530e-01,\n          7.1823e-02, -3.3883e-01, -1.8383e-01,  3.2484e-01,  6.6465e-02,\n         -2.4925e-01,  1.2773e-01,  3.5344e-02,  3.2701e-01, -8.5392e-02,\n          4.4462e-01, -1.3644e-01,  1.4186e-01, -2.9954e-01,  9.3068e-02,\n          4.8697e-01, -4.9256e-01,  1.0619e-01,  4.2752e-01, -1.7284e-01,\n         -2.3642e-01, -4.4011e-02, -2.9467e-01,  6.1980e-01,  5.8373e-01,\n          2.2160e-01, -2.1866e-02,  1.7643e-01, -9.1520e-03,  1.2929e-01,\n         -7.3082e-02,  1.6397e-01,  5.8583e-02, -4.6242e-01,  4.3455e-01,\n         -1.0087e-01, -3.2727e-01,  2.2628e-01, -3.4582e-02,  1.6172e-01,\n         -2.7409e-01,  1.0528e-01, -5.9848e-02,  2.3226e-01,  1.4564e-01,\n         -1.2072e-01,  2.3905e-01, -1.9347e-01, -4.6393e-02,  2.3129e-01,\n         -5.2212e-01, -3.7706e-01,  1.7923e-01, -1.3713e-01, -9.8761e-02,\n         -4.0970e-03,  3.2820e-01, -6.4838e-01,  3.7760e-01,  1.0785e-01,\n         -2.2988e-01,  3.9778e-01, -1.8354e-01, -2.0468e-01,  8.5161e-03,\n          2.8459e-02, -5.1400e-01,  2.5988e-01, -1.5684e-01,  5.7713e-01,\n         -1.2787e-01,  2.5969e-01,  1.0446e-01,  7.4681e-04, -2.0539e-01,\n         -1.1128e-01, -1.0686e-01, -1.8856e-02,  2.0551e-01,  3.8597e-01,\n          3.2728e-01,  2.5913e-01,  5.2154e-01]], device='cuda:0',\n       grad_fn=<DivBackward0>), hidden_states=(tensor([[[ 0.3790, -0.1398, -0.1771,  ...,  0.1405, -0.0283,  0.1839],\n         [-0.3286,  0.1314, -0.1459,  ...,  0.1504, -0.0726, -0.9195],\n         [-0.4018, -0.7783,  0.3085,  ...,  0.2146, -0.1665,  0.1573],\n         ...,\n         [ 0.0851, -0.2625, -0.4894,  ...,  0.2734,  0.4745,  1.1782],\n         [ 0.1677,  0.7349, -0.2215,  ..., -0.0586,  0.4081,  0.0223],\n         [-0.5726,  0.0112,  0.0245,  ..., -0.1072,  0.2156, -0.0299]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0796, -0.0358, -0.2100,  ..., -0.0925,  0.1244,  0.1888],\n         [-0.1361,  0.1932, -0.3597,  ..., -0.0295,  0.2344, -0.5821],\n         [-0.1606, -0.3572, -0.7043,  ..., -0.0127,  0.1001,  0.1497],\n         ...,\n         [ 0.5795, -0.2205, -0.4840,  ..., -0.1051,  0.7013,  0.6734],\n         [ 0.5804,  0.1233, -0.3604,  ..., -0.4208,  0.3692, -0.3083],\n         [ 0.1685, -0.1799, -0.1704,  ..., -0.3674,  0.2134,  0.0064]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0183, -0.3107, -0.1695,  ..., -0.4951, -0.3178,  0.3724],\n         [-0.7932,  0.6165, -0.3781,  ..., -0.1443, -0.8263, -0.0594],\n         [-0.5486, -0.0839, -0.6945,  ..., -0.4000, -0.2905,  0.2969],\n         ...,\n         [ 0.8178,  0.1379, -0.1783,  ..., -0.4655, -0.3185,  0.7949],\n         [ 0.5836,  0.5550, -0.3810,  ..., -0.6955, -0.9483, -0.0760],\n         [ 0.0729, -0.0122, -0.0600,  ..., -0.0596, -0.1522,  0.0302]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.2324, -0.0543, -0.6694,  ..., -0.5096, -0.4335,  0.2488],\n         [-1.4307,  1.3544, -0.3003,  ..., -0.7542, -1.0228, -0.9291],\n         [-1.2292,  0.1476, -0.9470,  ..., -0.4628, -0.2401,  0.3044],\n         ...,\n         [ 1.0194,  0.5541, -0.2348,  ..., -0.1541, -0.1016,  0.5341],\n         [ 0.8387,  1.2867, -0.0927,  ..., -0.7560, -0.3953, -0.5713],\n         [ 0.0315, -0.0189,  0.0095,  ..., -0.0260, -0.0536, -0.0273]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-9.5326e-01, -4.3661e-01, -9.4581e-01,  ..., -1.5457e-01,\n          -6.4549e-01, -1.9762e-01],\n         [-2.1118e+00,  8.4958e-01,  3.3048e-01,  ...,  1.1778e-01,\n          -8.8292e-01, -9.3446e-01],\n         [-1.1577e+00, -3.1500e-01, -7.4675e-01,  ...,  2.2091e-01,\n          -2.0268e-01,  4.8733e-01],\n         ...,\n         [ 4.8777e-01,  2.2107e-01,  3.3298e-01,  ...,  1.6233e-01,\n           9.3253e-02,  3.7051e-01],\n         [ 2.6080e-01,  9.9856e-01,  3.5275e-01,  ..., -2.5345e-02,\n          -2.1419e-01, -8.3197e-01],\n         [ 2.2233e-02,  2.0702e-03,  3.6527e-02,  ..., -5.7560e-02,\n          -1.1700e-01, -5.4931e-02]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.9370, -0.6154,  0.0175,  ..., -0.2686,  0.0505,  0.3943],\n         [-1.4244, -0.1362,  0.5284,  ...,  0.1380, -0.2261, -0.3084],\n         [-0.7744, -0.5110, -0.2723,  ...,  0.0668,  0.0397,  0.6541],\n         ...,\n         [ 0.0961,  0.1713,  0.6896,  ..., -0.0356,  0.1312,  0.2198],\n         [-0.2215,  0.0862,  0.9392,  ..., -0.1537, -0.0156, -0.4499],\n         [-0.1323, -0.0390,  0.1072,  ...,  0.0682, -0.0397, -0.2653]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-2.8095e-01,  1.9375e-01, -2.3601e-01,  ...,  2.4750e-04,\n           1.8413e-01,  7.4281e-01],\n         [-2.0558e-01,  5.6973e-01, -3.4450e-01,  ...,  3.1061e-01,\n           7.4593e-03,  6.6465e-01],\n         [-2.6471e-01,  4.7577e-01, -8.7475e-01,  ...,  4.3364e-01,\n           1.6303e-02,  1.2238e+00],\n         ...,\n         [ 2.1979e-01,  2.8544e-02, -4.8508e-01,  ...,  1.5100e-01,\n           5.6132e-01,  6.3370e-01],\n         [ 8.1528e-02,  5.9031e-01, -1.4732e-01,  ..., -5.9024e-02,\n           5.9021e-01,  8.1966e-01],\n         [-7.2517e-03,  1.6594e-01, -7.6334e-01,  ...,  5.0187e-01,\n           3.8227e-01,  5.1416e-01]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>)), attentions=None)\n:Dictionary inputs to traced functions must have consistent type. Found Tensor and Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m tokens_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([indexed_tokens])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m segments_tensors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([segments_ids])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtokens_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments_tensors\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\_trace.py:741\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m--> 741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    757\u001b[0m ):\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    759\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    760\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    767\u001b[0m         _module_class,\n\u001b[0;32m    768\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\_trace.py:958\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    954\u001b[0m     argument_names \u001b[38;5;241m=\u001b[39m get_callable_argument_names(func)\n\u001b[0;32m    956\u001b[0m example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m--> 958\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tracer cannot infer type of BaseModelOutputWithPooling(last_hidden_state=tensor([[[-2.8095e-01,  1.9375e-01, -2.3601e-01,  ...,  2.4750e-04,\n           1.8413e-01,  7.4281e-01],\n         [-2.0558e-01,  5.6973e-01, -3.4450e-01,  ...,  3.1061e-01,\n           7.4593e-03,  6.6465e-01],\n         [-2.6471e-01,  4.7577e-01, -8.7475e-01,  ...,  4.3364e-01,\n           1.6303e-02,  1.2238e+00],\n         ...,\n         [ 2.1979e-01,  2.8544e-02, -4.8508e-01,  ...,  1.5100e-01,\n           5.6132e-01,  6.3370e-01],\n         [ 8.1528e-02,  5.9031e-01, -1.4732e-01,  ..., -5.9024e-02,\n           5.9021e-01,  8.1966e-01],\n         [-7.2517e-03,  1.6594e-01, -7.6334e-01,  ...,  5.0187e-01,\n           3.8227e-01,  5.1416e-01]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 4.6693e-02,  4.0107e-02, -3.7071e-01, -2.7972e-02, -9.5654e-02,\n         -8.7964e-02,  1.8528e-02,  2.7150e-01, -2.4230e-01,  9.8927e-05,\n         -3.4853e-01, -5.7866e-01, -1.3977e-01,  3.4567e-01, -3.4365e-01,\n         -9.6294e-03, -2.6303e-02, -2.1803e-01, -1.1859e-01,  7.5814e-02,\n          2.7154e-01, -2.1654e-01, -3.3980e-01,  3.5713e-01,  7.2184e-02,\n          7.7747e-02,  2.0000e-01,  3.3041e-01,  1.5145e-01, -3.1463e-01,\n         -8.3670e-03, -6.3714e-02,  4.2273e-01,  2.9969e-01,  5.7845e-02,\n          2.3974e-01, -4.7594e-02, -1.6258e-01, -1.6344e-01, -1.2472e-01,\n         -1.7768e-01,  5.6963e-03, -2.2802e-01,  6.1100e-04,  4.6322e-01,\n         -3.9256e-02,  4.0616e-01, -3.4898e-01,  8.9205e-02, -1.6020e-01,\n          9.7896e-02, -1.6947e-01,  2.7750e-02,  3.5056e-01,  2.2463e-01,\n         -2.5251e-02, -8.3530e-02,  1.1967e-02,  1.8789e-01,  3.0655e-01,\n          6.2255e-02, -3.2581e-02,  2.6660e-02, -9.0701e-02, -3.4137e-01,\n         -2.6564e-01, -1.7123e-01,  3.8302e-01, -5.6068e-01,  1.9953e-01,\n          1.5175e-01,  2.5360e-01,  1.3732e-01, -1.1475e-01,  5.0170e-02,\n          2.9594e-01,  4.7890e-01,  8.9323e-02,  4.1593e-01,  2.3964e-01,\n          2.2769e-01,  1.6559e-01,  2.8347e-01,  1.4929e-01,  2.6771e-01,\n         -1.7873e-01, -1.1776e-01, -8.1478e-02, -2.2917e-01,  6.6764e-02,\n         -1.5156e-01,  1.4597e-01,  1.7807e-01, -7.8407e-02, -1.1961e-02,\n         -5.5800e-03,  3.2663e-02, -3.6713e-02, -1.0436e-01, -2.6302e-01,\n          2.9339e-01,  2.6338e-01, -8.5827e-03,  2.8918e-01,  2.0783e-01,\n          6.6061e-02,  8.6752e-02,  2.6657e-01, -2.1378e-01,  5.5170e-01,\n         -3.0502e-01,  1.9279e-02,  2.0699e-01, -4.1495e-01, -1.3450e-03,\n         -3.4352e-02, -6.2233e-01,  5.7239e-02, -5.3565e-01, -1.9556e-01,\n          2.1748e-01, -2.5492e-02, -1.7693e-01, -9.1041e-02, -8.2664e-02,\n          1.1888e-01, -2.6719e-01,  1.9183e-01, -8.6937e-02, -1.1656e-01,\n          9.3656e-02, -2.4710e-01,  4.2405e-01, -9.8818e-02, -1.9976e-01,\n          5.9881e-02, -2.5661e-01, -4.5558e-04,  5.4826e-02, -9.8980e-02,\n         -2.1050e-01, -3.2874e-02, -1.3713e-01,  1.4698e-01,  1.3910e-01,\n         -1.8795e-01,  2.5036e-02,  1.5718e-01,  7.8290e-02,  3.4586e-01,\n         -1.9084e-01, -2.4636e-01, -2.7752e-01, -3.2277e-01, -2.1060e-01,\n          1.5730e-02, -1.6699e-01, -4.1642e-01,  1.0134e-01,  1.4960e-01,\n         -1.6346e-01, -5.3434e-01, -2.3700e-01, -4.8405e-01, -4.0551e-01,\n          1.3371e-01,  1.7637e-01, -4.6814e-01,  2.1758e-01, -9.9638e-02,\n         -6.6738e-02,  5.5015e-01,  1.1654e-01,  1.7745e-02, -4.3454e-01,\n         -9.5787e-02,  3.9904e-01, -1.8967e-01,  1.4247e-01,  4.7395e-01,\n         -1.0383e-02, -2.8846e-02, -4.6897e-02, -1.0486e-01, -5.7609e-01,\n         -3.6152e-01,  2.1397e-01, -3.2449e-01,  3.2640e-01,  1.3473e-01,\n         -4.2674e-02,  3.7581e-01, -1.7810e-01, -1.5909e-01,  4.2082e-01,\n          2.9741e-01, -1.1551e-01, -3.5975e-01,  3.0413e-01,  2.8718e-01,\n          8.3572e-02, -7.6330e-02,  3.6599e-01, -3.5791e-01, -1.1984e-01,\n          4.6330e-02, -2.1017e-01,  9.6010e-02,  2.5951e-01,  3.1474e-01,\n          3.2159e-01,  1.7671e-01, -8.4449e-02,  1.2721e-01,  6.9955e-02,\n          3.3938e-01, -3.6960e-02, -2.6437e-01, -3.6957e-01, -3.1519e-01,\n         -2.8044e-01, -3.1960e-02, -3.2118e-01, -3.3568e-01,  5.6361e-02,\n         -7.9344e-02, -1.0817e-01, -4.1884e-01,  5.6373e-01,  1.7060e-01,\n         -3.7492e-01, -4.9206e-01, -1.1492e-01, -5.3896e-02, -1.0919e-01,\n         -2.6218e-01,  2.0154e-01,  4.4679e-02,  6.2231e-02,  8.6094e-02,\n         -1.1548e-01,  4.0717e-01,  1.0435e-01,  1.1964e-01,  5.5811e-02,\n         -1.3387e-01, -3.0432e-01,  1.9487e-01, -2.3411e-01,  2.3979e-01,\n          8.3957e-02, -1.7051e-01,  2.9582e-01,  7.6980e-02, -2.1012e-01,\n         -2.2019e-01,  5.1967e-02, -2.0904e-01, -3.1589e-01,  1.3976e-01,\n          7.3378e-02,  1.2886e-02, -3.7941e-02, -4.1992e-01, -6.7913e-01,\n         -3.8605e-02,  3.3250e-01, -1.4962e-01, -2.3367e-01,  2.1604e-02,\n          9.5433e-01, -3.3314e-01,  3.3863e-02, -1.1041e-01,  1.3514e-01,\n          1.7344e-01,  3.0827e-01,  1.9480e-02,  1.3813e-01,  7.5715e-03,\n          2.6293e-01,  1.4490e-01, -3.7647e-01,  2.0370e-01, -1.2067e-01,\n         -1.9894e-01, -2.9209e-01, -1.8561e-01, -2.8015e-01, -1.9971e-01,\n          7.9241e-02,  2.7789e-01,  2.0711e-01,  9.2009e-02, -1.2497e-01,\n          1.3548e-02, -4.1796e-01, -9.4340e-02,  3.9416e-02,  4.4411e-02,\n         -2.0689e-01,  7.8503e-02,  2.8727e-01,  4.8503e-01, -3.9871e-01,\n          5.5450e-02, -2.8031e-01, -1.6286e-01,  3.7779e-01, -4.2408e-01,\n          4.3749e-03,  1.3447e-01, -7.2981e-02, -2.7551e-01, -1.6305e-01,\n         -1.8913e-01, -4.5124e-02,  1.1433e-01, -1.1529e-01,  1.6803e-01,\n         -4.9927e-02,  3.2612e-02, -1.4389e-01, -6.5885e-01, -6.7365e-02,\n         -1.4673e-01, -4.8238e-02, -1.4534e-01,  6.4086e-01,  3.6175e-01,\n         -1.3694e-01, -3.0026e-01,  4.9679e-01, -1.2416e-01, -3.7848e-01,\n         -2.7967e-01, -3.2192e-02, -5.8232e-01,  2.5316e-01, -3.7612e-01,\n         -7.5341e-02, -1.0061e-01, -4.2381e-01,  2.0430e-01,  3.5421e-01,\n          4.7512e-01, -2.4318e-02, -3.1277e-01,  5.9076e-02, -2.8672e-01,\n         -2.0519e-01,  1.0690e-01,  2.1698e-01, -4.6779e-01, -4.2751e-01,\n         -7.9820e-02, -1.0694e-01, -1.5257e-01, -2.0322e-01,  2.8396e-01,\n         -9.1225e-02,  5.7800e-02,  2.5577e-01, -3.4644e-01,  1.6233e-01,\n          6.3564e-01, -3.3724e-01,  1.9419e-01, -3.6530e-01,  1.0729e-01,\n         -4.0173e-01, -3.8239e-01, -1.6141e-01,  7.4453e-02, -4.3982e-01,\n         -3.7165e-01,  9.4542e-02, -3.9154e-01, -2.8783e-01, -2.0081e-01,\n          2.1023e-02, -3.1915e-01,  5.1339e-01,  4.0421e-02, -5.2414e-01,\n         -1.3860e-01,  5.0436e-01, -4.0707e-01, -5.7195e-01,  2.2586e-02,\n         -2.6875e-01,  1.8693e-01, -2.5197e-01,  4.9181e-01, -5.9845e-01,\n         -6.9314e-02, -5.7444e-02,  7.7586e-02,  3.3125e-02,  1.4080e-01,\n         -1.8913e-01,  1.2483e-01,  1.8294e-01, -1.0081e+00,  2.8459e-01,\n          2.2694e-01,  2.5965e-01, -7.4635e-02,  3.8446e-01, -4.5130e-01,\n         -1.8509e-01,  8.3799e-02,  1.6537e-01,  3.1572e-01,  7.6182e-02,\n          1.5847e-01,  3.7006e-01,  3.2070e-01,  2.1765e-01,  1.5052e-01,\n         -4.7995e-01, -4.4966e-01, -3.5002e-01,  1.4406e-01, -8.8948e-02,\n          5.1441e-01, -4.1660e-01,  3.4986e-01, -1.1441e-01, -1.0048e-01,\n          1.6408e-01,  8.8887e-02,  1.5933e-01,  9.3904e-02,  1.1400e-01,\n          1.8206e-01,  3.3361e-01, -1.2313e-01, -3.8495e-01,  2.2998e-01,\n          1.0782e-01, -4.6062e-01, -2.9444e-01,  2.4281e-01, -1.2217e-01,\n         -2.4393e-01,  1.8185e-01, -4.1725e-01, -3.6603e-01, -7.4732e-02,\n          3.1326e-01, -1.5488e-01, -6.4646e-01, -8.3071e-02,  2.3564e-02,\n         -3.8589e-01,  1.0421e-01, -1.0521e-01, -1.6525e-01, -1.1996e-01,\n          1.4955e-01,  2.4033e-01, -8.6674e-02, -5.4170e-01, -2.5583e-01,\n          5.6224e-02, -1.6628e-01, -4.1819e-01, -2.3568e-01, -4.9047e-01,\n          1.7005e-02,  3.6465e-04,  2.6325e-01, -2.7289e-01,  1.3864e-01,\n          8.5591e-02,  3.5195e-01, -5.7063e-02,  5.9695e-03,  3.2521e-02,\n         -1.8778e-01,  1.8255e-01,  2.8537e-01, -1.4293e-02,  1.1457e-02,\n         -3.1442e-01,  1.9079e-01, -3.3102e-01, -4.6480e-02, -2.7503e-01,\n          4.3797e-01,  2.5024e-01, -1.1668e-01, -1.2751e-01, -1.4074e-01,\n          1.5598e-01, -6.7441e-02, -1.0944e-01, -4.0199e-01,  1.6955e-01,\n         -3.8893e-01,  1.8294e-01,  1.3988e-01,  3.9773e-01, -1.6795e-01,\n          6.2370e-02, -8.5830e-02, -3.9306e-02, -3.4178e-01, -1.6844e-01,\n          7.8893e-03, -3.4126e-01,  4.5400e-01,  1.6699e-01, -4.2358e-01,\n         -1.6840e-01, -5.7318e-02,  3.9432e-02,  2.4061e-01,  1.4965e-01,\n          1.8138e-01, -6.6945e-02, -3.7419e-01, -7.3155e-02, -2.2167e-01,\n          1.9476e-01, -9.5210e-02,  2.7536e-01, -1.5343e-01, -5.6016e-01,\n         -6.1347e-02,  7.8486e-02,  2.2220e-02,  1.2293e-01,  1.9137e-02,\n          3.6239e-01, -3.9407e-03, -3.0480e-01,  1.0109e-01,  1.4238e-01,\n         -1.0127e-01,  1.8982e-01, -7.3263e-02, -2.4488e-01,  4.4750e-01,\n          3.5579e-01, -1.6979e-01,  1.6875e-01,  2.4465e-02, -1.2170e-01,\n         -9.6275e-02,  8.9936e-02,  6.1709e-01,  1.4500e-01, -4.8076e-01,\n         -3.0713e-01,  1.4727e-01, -7.0945e-03, -1.5526e-01,  9.5915e-02,\n          7.4484e-02,  4.3584e-01,  1.6116e-01, -5.9871e-01, -5.9422e-01,\n          7.6837e-02, -1.5509e-01, -3.6611e-01,  2.8282e-02,  3.7231e-01,\n          3.2762e-01,  2.2060e-02, -3.5888e-01, -2.4051e-01,  6.4066e-02,\n          3.5439e-01,  1.2462e-01,  1.6493e-01, -3.1871e-01,  5.5375e-02,\n          1.1820e-01,  8.3088e-01,  8.5695e-02, -1.1434e-02,  5.5705e-02,\n         -3.7754e-02,  1.1020e-01, -3.7759e-01,  1.2221e-01,  1.5877e-01,\n          3.7045e-01, -2.2702e-01,  4.3940e-01, -1.2291e-01,  6.0639e-02,\n          9.0442e-03, -1.1641e-01,  1.6571e-02, -2.3472e-01,  4.0214e-01,\n          6.4819e-03,  6.5207e-03, -6.6666e-01,  1.4141e-01, -1.0585e-01,\n         -2.4113e-01,  2.0391e-01, -1.0582e-01, -2.7862e-01, -1.3709e-01,\n          2.6258e-03, -7.9851e-02,  4.0725e-03, -4.6333e-01, -8.4179e-02,\n         -3.8501e-02, -2.1379e-01,  9.3424e-02, -3.2262e-01, -3.8604e-01,\n          2.5370e-01,  1.5727e-01, -7.4532e-01, -1.9181e-01,  1.5279e-01,\n         -2.5710e-01, -5.3802e-01,  3.6783e-01,  3.5995e-01, -2.0221e-01,\n         -2.0596e-01,  5.2864e-01,  2.7097e-01,  1.5769e-01,  4.6152e-01,\n         -4.7203e-01, -1.2711e-01,  2.9948e-02, -8.5174e-02, -2.4472e-01,\n         -1.4154e-01,  3.8125e-01,  2.8051e-01, -1.8072e-01,  4.8548e-01,\n          2.4945e-01,  1.4104e-01,  3.8624e-01, -2.8026e-01, -2.0120e-01,\n          2.8732e-02, -1.1231e-02, -3.6426e-01,  2.6251e-02, -3.7851e-02,\n          6.4009e-01, -1.5928e-01,  9.5855e-02, -6.6296e-02,  1.7410e-01,\n          3.8996e-02,  7.4717e-02, -1.3931e-01,  5.8656e-01,  4.9502e-01,\n         -2.6947e-02, -4.5381e-01, -2.7717e-01, -1.0380e-01, -1.1805e-01,\n          3.7948e-01,  9.4765e-02,  2.8403e-01,  1.1377e-01, -4.7931e-01,\n         -2.5457e-01,  1.8128e-02,  1.6517e-01,  3.1461e-01, -2.5417e-02,\n         -2.0248e-01, -4.7060e-02,  6.1397e-02,  5.4805e-01,  1.4530e-01,\n          7.1823e-02, -3.3883e-01, -1.8383e-01,  3.2484e-01,  6.6465e-02,\n         -2.4925e-01,  1.2773e-01,  3.5344e-02,  3.2701e-01, -8.5392e-02,\n          4.4462e-01, -1.3644e-01,  1.4186e-01, -2.9954e-01,  9.3068e-02,\n          4.8697e-01, -4.9256e-01,  1.0619e-01,  4.2752e-01, -1.7284e-01,\n         -2.3642e-01, -4.4011e-02, -2.9467e-01,  6.1980e-01,  5.8373e-01,\n          2.2160e-01, -2.1866e-02,  1.7643e-01, -9.1520e-03,  1.2929e-01,\n         -7.3082e-02,  1.6397e-01,  5.8583e-02, -4.6242e-01,  4.3455e-01,\n         -1.0087e-01, -3.2727e-01,  2.2628e-01, -3.4582e-02,  1.6172e-01,\n         -2.7409e-01,  1.0528e-01, -5.9848e-02,  2.3226e-01,  1.4564e-01,\n         -1.2072e-01,  2.3905e-01, -1.9347e-01, -4.6393e-02,  2.3129e-01,\n         -5.2212e-01, -3.7706e-01,  1.7923e-01, -1.3713e-01, -9.8761e-02,\n         -4.0970e-03,  3.2820e-01, -6.4838e-01,  3.7760e-01,  1.0785e-01,\n         -2.2988e-01,  3.9778e-01, -1.8354e-01, -2.0468e-01,  8.5161e-03,\n          2.8459e-02, -5.1400e-01,  2.5988e-01, -1.5684e-01,  5.7713e-01,\n         -1.2787e-01,  2.5969e-01,  1.0446e-01,  7.4681e-04, -2.0539e-01,\n         -1.1128e-01, -1.0686e-01, -1.8856e-02,  2.0551e-01,  3.8597e-01,\n          3.2728e-01,  2.5913e-01,  5.2154e-01]], device='cuda:0',\n       grad_fn=<DivBackward0>), hidden_states=(tensor([[[ 0.3790, -0.1398, -0.1771,  ...,  0.1405, -0.0283,  0.1839],\n         [-0.3286,  0.1314, -0.1459,  ...,  0.1504, -0.0726, -0.9195],\n         [-0.4018, -0.7783,  0.3085,  ...,  0.2146, -0.1665,  0.1573],\n         ...,\n         [ 0.0851, -0.2625, -0.4894,  ...,  0.2734,  0.4745,  1.1782],\n         [ 0.1677,  0.7349, -0.2215,  ..., -0.0586,  0.4081,  0.0223],\n         [-0.5726,  0.0112,  0.0245,  ..., -0.1072,  0.2156, -0.0299]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0796, -0.0358, -0.2100,  ..., -0.0925,  0.1244,  0.1888],\n         [-0.1361,  0.1932, -0.3597,  ..., -0.0295,  0.2344, -0.5821],\n         [-0.1606, -0.3572, -0.7043,  ..., -0.0127,  0.1001,  0.1497],\n         ...,\n         [ 0.5795, -0.2205, -0.4840,  ..., -0.1051,  0.7013,  0.6734],\n         [ 0.5804,  0.1233, -0.3604,  ..., -0.4208,  0.3692, -0.3083],\n         [ 0.1685, -0.1799, -0.1704,  ..., -0.3674,  0.2134,  0.0064]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0183, -0.3107, -0.1695,  ..., -0.4951, -0.3178,  0.3724],\n         [-0.7932,  0.6165, -0.3781,  ..., -0.1443, -0.8263, -0.0594],\n         [-0.5486, -0.0839, -0.6945,  ..., -0.4000, -0.2905,  0.2969],\n         ...,\n         [ 0.8178,  0.1379, -0.1783,  ..., -0.4655, -0.3185,  0.7949],\n         [ 0.5836,  0.5550, -0.3810,  ..., -0.6955, -0.9483, -0.0760],\n         [ 0.0729, -0.0122, -0.0600,  ..., -0.0596, -0.1522,  0.0302]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.2324, -0.0543, -0.6694,  ..., -0.5096, -0.4335,  0.2488],\n         [-1.4307,  1.3544, -0.3003,  ..., -0.7542, -1.0228, -0.9291],\n         [-1.2292,  0.1476, -0.9470,  ..., -0.4628, -0.2401,  0.3044],\n         ...,\n         [ 1.0194,  0.5541, -0.2348,  ..., -0.1541, -0.1016,  0.5341],\n         [ 0.8387,  1.2867, -0.0927,  ..., -0.7560, -0.3953, -0.5713],\n         [ 0.0315, -0.0189,  0.0095,  ..., -0.0260, -0.0536, -0.0273]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-9.5326e-01, -4.3661e-01, -9.4581e-01,  ..., -1.5457e-01,\n          -6.4549e-01, -1.9762e-01],\n         [-2.1118e+00,  8.4958e-01,  3.3048e-01,  ...,  1.1778e-01,\n          -8.8292e-01, -9.3446e-01],\n         [-1.1577e+00, -3.1500e-01, -7.4675e-01,  ...,  2.2091e-01,\n          -2.0268e-01,  4.8733e-01],\n         ...,\n         [ 4.8777e-01,  2.2107e-01,  3.3298e-01,  ...,  1.6233e-01,\n           9.3253e-02,  3.7051e-01],\n         [ 2.6080e-01,  9.9856e-01,  3.5275e-01,  ..., -2.5345e-02,\n          -2.1419e-01, -8.3197e-01],\n         [ 2.2233e-02,  2.0702e-03,  3.6527e-02,  ..., -5.7560e-02,\n          -1.1700e-01, -5.4931e-02]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.9370, -0.6154,  0.0175,  ..., -0.2686,  0.0505,  0.3943],\n         [-1.4244, -0.1362,  0.5284,  ...,  0.1380, -0.2261, -0.3084],\n         [-0.7744, -0.5110, -0.2723,  ...,  0.0668,  0.0397,  0.6541],\n         ...,\n         [ 0.0961,  0.1713,  0.6896,  ..., -0.0356,  0.1312,  0.2198],\n         [-0.2215,  0.0862,  0.9392,  ..., -0.1537, -0.0156, -0.4499],\n         [-0.1323, -0.0390,  0.1072,  ...,  0.0682, -0.0397, -0.2653]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-2.8095e-01,  1.9375e-01, -2.3601e-01,  ...,  2.4750e-04,\n           1.8413e-01,  7.4281e-01],\n         [-2.0558e-01,  5.6973e-01, -3.4450e-01,  ...,  3.1061e-01,\n           7.4593e-03,  6.6465e-01],\n         [-2.6471e-01,  4.7577e-01, -8.7475e-01,  ...,  4.3364e-01,\n           1.6303e-02,  1.2238e+00],\n         ...,\n         [ 2.1979e-01,  2.8544e-02, -4.8508e-01,  ...,  1.5100e-01,\n           5.6132e-01,  6.3370e-01],\n         [ 8.1528e-02,  5.9031e-01, -1.4732e-01,  ..., -5.9024e-02,\n           5.9021e-01,  8.1966e-01],\n         [-7.2517e-03,  1.6594e-01, -7.6334e-01,  ...,  5.0187e-01,\n           3.8227e-01,  5.1416e-01]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>)), attentions=None)\n:Dictionary inputs to traced functions must have consistent type. Found Tensor and Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "\n",
    "enc = BertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "segments_tensors = torch.tensor([segments_ids]).to('cuda')\n",
    "\n",
    "traced_model = torch.jit.trace(quantized_model, [tokens_tensor, segments_tensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tracer cannot infer type of BaseModelOutputWithPooling(last_hidden_state=tensor([[[-2.8095e-01,  1.9375e-01, -2.3601e-01,  ...,  2.4750e-04,\n           1.8413e-01,  7.4281e-01],\n         [-2.0558e-01,  5.6973e-01, -3.4450e-01,  ...,  3.1061e-01,\n           7.4593e-03,  6.6465e-01],\n         [-2.6471e-01,  4.7577e-01, -8.7475e-01,  ...,  4.3364e-01,\n           1.6303e-02,  1.2238e+00],\n         ...,\n         [ 2.1979e-01,  2.8544e-02, -4.8508e-01,  ...,  1.5100e-01,\n           5.6132e-01,  6.3370e-01],\n         [ 8.1528e-02,  5.9031e-01, -1.4732e-01,  ..., -5.9024e-02,\n           5.9021e-01,  8.1966e-01],\n         [-7.2517e-03,  1.6594e-01, -7.6334e-01,  ...,  5.0187e-01,\n           3.8227e-01,  5.1416e-01]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 4.6693e-02,  4.0107e-02, -3.7071e-01, -2.7972e-02, -9.5654e-02,\n         -8.7964e-02,  1.8528e-02,  2.7150e-01, -2.4230e-01,  9.8927e-05,\n         -3.4853e-01, -5.7866e-01, -1.3977e-01,  3.4567e-01, -3.4365e-01,\n         -9.6294e-03, -2.6303e-02, -2.1803e-01, -1.1859e-01,  7.5814e-02,\n          2.7154e-01, -2.1654e-01, -3.3980e-01,  3.5713e-01,  7.2184e-02,\n          7.7747e-02,  2.0000e-01,  3.3041e-01,  1.5145e-01, -3.1463e-01,\n         -8.3670e-03, -6.3714e-02,  4.2273e-01,  2.9969e-01,  5.7845e-02,\n          2.3974e-01, -4.7594e-02, -1.6258e-01, -1.6344e-01, -1.2472e-01,\n         -1.7768e-01,  5.6963e-03, -2.2802e-01,  6.1100e-04,  4.6322e-01,\n         -3.9256e-02,  4.0616e-01, -3.4898e-01,  8.9205e-02, -1.6020e-01,\n          9.7896e-02, -1.6947e-01,  2.7750e-02,  3.5056e-01,  2.2463e-01,\n         -2.5251e-02, -8.3530e-02,  1.1967e-02,  1.8789e-01,  3.0655e-01,\n          6.2255e-02, -3.2581e-02,  2.6660e-02, -9.0701e-02, -3.4137e-01,\n         -2.6564e-01, -1.7123e-01,  3.8302e-01, -5.6068e-01,  1.9953e-01,\n          1.5175e-01,  2.5360e-01,  1.3732e-01, -1.1475e-01,  5.0170e-02,\n          2.9594e-01,  4.7890e-01,  8.9323e-02,  4.1593e-01,  2.3964e-01,\n          2.2769e-01,  1.6559e-01,  2.8347e-01,  1.4929e-01,  2.6771e-01,\n         -1.7873e-01, -1.1776e-01, -8.1478e-02, -2.2917e-01,  6.6764e-02,\n         -1.5156e-01,  1.4597e-01,  1.7807e-01, -7.8407e-02, -1.1961e-02,\n         -5.5800e-03,  3.2663e-02, -3.6713e-02, -1.0436e-01, -2.6302e-01,\n          2.9339e-01,  2.6338e-01, -8.5827e-03,  2.8918e-01,  2.0783e-01,\n          6.6061e-02,  8.6752e-02,  2.6657e-01, -2.1378e-01,  5.5170e-01,\n         -3.0502e-01,  1.9279e-02,  2.0699e-01, -4.1495e-01, -1.3450e-03,\n         -3.4352e-02, -6.2233e-01,  5.7239e-02, -5.3565e-01, -1.9556e-01,\n          2.1748e-01, -2.5492e-02, -1.7693e-01, -9.1041e-02, -8.2664e-02,\n          1.1888e-01, -2.6719e-01,  1.9183e-01, -8.6937e-02, -1.1656e-01,\n          9.3656e-02, -2.4710e-01,  4.2405e-01, -9.8818e-02, -1.9976e-01,\n          5.9881e-02, -2.5661e-01, -4.5558e-04,  5.4826e-02, -9.8980e-02,\n         -2.1050e-01, -3.2874e-02, -1.3713e-01,  1.4698e-01,  1.3910e-01,\n         -1.8795e-01,  2.5036e-02,  1.5718e-01,  7.8290e-02,  3.4586e-01,\n         -1.9084e-01, -2.4636e-01, -2.7752e-01, -3.2277e-01, -2.1060e-01,\n          1.5730e-02, -1.6699e-01, -4.1642e-01,  1.0134e-01,  1.4960e-01,\n         -1.6346e-01, -5.3434e-01, -2.3700e-01, -4.8405e-01, -4.0551e-01,\n          1.3371e-01,  1.7637e-01, -4.6814e-01,  2.1758e-01, -9.9638e-02,\n         -6.6738e-02,  5.5015e-01,  1.1654e-01,  1.7745e-02, -4.3454e-01,\n         -9.5787e-02,  3.9904e-01, -1.8967e-01,  1.4247e-01,  4.7395e-01,\n         -1.0383e-02, -2.8846e-02, -4.6897e-02, -1.0486e-01, -5.7609e-01,\n         -3.6152e-01,  2.1397e-01, -3.2449e-01,  3.2640e-01,  1.3473e-01,\n         -4.2674e-02,  3.7581e-01, -1.7810e-01, -1.5909e-01,  4.2082e-01,\n          2.9741e-01, -1.1551e-01, -3.5975e-01,  3.0413e-01,  2.8718e-01,\n          8.3572e-02, -7.6330e-02,  3.6599e-01, -3.5791e-01, -1.1984e-01,\n          4.6330e-02, -2.1017e-01,  9.6010e-02,  2.5951e-01,  3.1474e-01,\n          3.2159e-01,  1.7671e-01, -8.4449e-02,  1.2721e-01,  6.9955e-02,\n          3.3938e-01, -3.6960e-02, -2.6437e-01, -3.6957e-01, -3.1519e-01,\n         -2.8044e-01, -3.1960e-02, -3.2118e-01, -3.3568e-01,  5.6361e-02,\n         -7.9344e-02, -1.0817e-01, -4.1884e-01,  5.6373e-01,  1.7060e-01,\n         -3.7492e-01, -4.9206e-01, -1.1492e-01, -5.3896e-02, -1.0919e-01,\n         -2.6218e-01,  2.0154e-01,  4.4679e-02,  6.2231e-02,  8.6094e-02,\n         -1.1548e-01,  4.0717e-01,  1.0435e-01,  1.1964e-01,  5.5811e-02,\n         -1.3387e-01, -3.0432e-01,  1.9487e-01, -2.3411e-01,  2.3979e-01,\n          8.3957e-02, -1.7051e-01,  2.9582e-01,  7.6980e-02, -2.1012e-01,\n         -2.2019e-01,  5.1967e-02, -2.0904e-01, -3.1589e-01,  1.3976e-01,\n          7.3378e-02,  1.2886e-02, -3.7941e-02, -4.1992e-01, -6.7913e-01,\n         -3.8605e-02,  3.3250e-01, -1.4962e-01, -2.3367e-01,  2.1604e-02,\n          9.5433e-01, -3.3314e-01,  3.3863e-02, -1.1041e-01,  1.3514e-01,\n          1.7344e-01,  3.0827e-01,  1.9480e-02,  1.3813e-01,  7.5715e-03,\n          2.6293e-01,  1.4490e-01, -3.7647e-01,  2.0370e-01, -1.2067e-01,\n         -1.9894e-01, -2.9209e-01, -1.8561e-01, -2.8015e-01, -1.9971e-01,\n          7.9241e-02,  2.7789e-01,  2.0711e-01,  9.2009e-02, -1.2497e-01,\n          1.3548e-02, -4.1796e-01, -9.4340e-02,  3.9416e-02,  4.4411e-02,\n         -2.0689e-01,  7.8503e-02,  2.8727e-01,  4.8503e-01, -3.9871e-01,\n          5.5450e-02, -2.8031e-01, -1.6286e-01,  3.7779e-01, -4.2408e-01,\n          4.3749e-03,  1.3447e-01, -7.2981e-02, -2.7551e-01, -1.6305e-01,\n         -1.8913e-01, -4.5124e-02,  1.1433e-01, -1.1529e-01,  1.6803e-01,\n         -4.9927e-02,  3.2612e-02, -1.4389e-01, -6.5885e-01, -6.7365e-02,\n         -1.4673e-01, -4.8238e-02, -1.4534e-01,  6.4086e-01,  3.6175e-01,\n         -1.3694e-01, -3.0026e-01,  4.9679e-01, -1.2416e-01, -3.7848e-01,\n         -2.7967e-01, -3.2192e-02, -5.8232e-01,  2.5316e-01, -3.7612e-01,\n         -7.5341e-02, -1.0061e-01, -4.2381e-01,  2.0430e-01,  3.5421e-01,\n          4.7512e-01, -2.4318e-02, -3.1277e-01,  5.9076e-02, -2.8672e-01,\n         -2.0519e-01,  1.0690e-01,  2.1698e-01, -4.6779e-01, -4.2751e-01,\n         -7.9820e-02, -1.0694e-01, -1.5257e-01, -2.0322e-01,  2.8396e-01,\n         -9.1225e-02,  5.7800e-02,  2.5577e-01, -3.4644e-01,  1.6233e-01,\n          6.3564e-01, -3.3724e-01,  1.9419e-01, -3.6530e-01,  1.0729e-01,\n         -4.0173e-01, -3.8239e-01, -1.6141e-01,  7.4453e-02, -4.3982e-01,\n         -3.7165e-01,  9.4542e-02, -3.9154e-01, -2.8783e-01, -2.0081e-01,\n          2.1023e-02, -3.1915e-01,  5.1339e-01,  4.0421e-02, -5.2414e-01,\n         -1.3860e-01,  5.0436e-01, -4.0707e-01, -5.7195e-01,  2.2586e-02,\n         -2.6875e-01,  1.8693e-01, -2.5197e-01,  4.9181e-01, -5.9845e-01,\n         -6.9314e-02, -5.7444e-02,  7.7586e-02,  3.3125e-02,  1.4080e-01,\n         -1.8913e-01,  1.2483e-01,  1.8294e-01, -1.0081e+00,  2.8459e-01,\n          2.2694e-01,  2.5965e-01, -7.4635e-02,  3.8446e-01, -4.5130e-01,\n         -1.8509e-01,  8.3799e-02,  1.6537e-01,  3.1572e-01,  7.6182e-02,\n          1.5847e-01,  3.7006e-01,  3.2070e-01,  2.1765e-01,  1.5052e-01,\n         -4.7995e-01, -4.4966e-01, -3.5002e-01,  1.4406e-01, -8.8948e-02,\n          5.1441e-01, -4.1660e-01,  3.4986e-01, -1.1441e-01, -1.0048e-01,\n          1.6408e-01,  8.8887e-02,  1.5933e-01,  9.3904e-02,  1.1400e-01,\n          1.8206e-01,  3.3361e-01, -1.2313e-01, -3.8495e-01,  2.2998e-01,\n          1.0782e-01, -4.6062e-01, -2.9444e-01,  2.4281e-01, -1.2217e-01,\n         -2.4393e-01,  1.8185e-01, -4.1725e-01, -3.6603e-01, -7.4732e-02,\n          3.1326e-01, -1.5488e-01, -6.4646e-01, -8.3071e-02,  2.3564e-02,\n         -3.8589e-01,  1.0421e-01, -1.0521e-01, -1.6525e-01, -1.1996e-01,\n          1.4955e-01,  2.4033e-01, -8.6674e-02, -5.4170e-01, -2.5583e-01,\n          5.6224e-02, -1.6628e-01, -4.1819e-01, -2.3568e-01, -4.9047e-01,\n          1.7005e-02,  3.6465e-04,  2.6325e-01, -2.7289e-01,  1.3864e-01,\n          8.5591e-02,  3.5195e-01, -5.7063e-02,  5.9695e-03,  3.2521e-02,\n         -1.8778e-01,  1.8255e-01,  2.8537e-01, -1.4293e-02,  1.1457e-02,\n         -3.1442e-01,  1.9079e-01, -3.3102e-01, -4.6480e-02, -2.7503e-01,\n          4.3797e-01,  2.5024e-01, -1.1668e-01, -1.2751e-01, -1.4074e-01,\n          1.5598e-01, -6.7441e-02, -1.0944e-01, -4.0199e-01,  1.6955e-01,\n         -3.8893e-01,  1.8294e-01,  1.3988e-01,  3.9773e-01, -1.6795e-01,\n          6.2370e-02, -8.5830e-02, -3.9306e-02, -3.4178e-01, -1.6844e-01,\n          7.8893e-03, -3.4126e-01,  4.5400e-01,  1.6699e-01, -4.2358e-01,\n         -1.6840e-01, -5.7318e-02,  3.9432e-02,  2.4061e-01,  1.4965e-01,\n          1.8138e-01, -6.6945e-02, -3.7419e-01, -7.3155e-02, -2.2167e-01,\n          1.9476e-01, -9.5210e-02,  2.7536e-01, -1.5343e-01, -5.6016e-01,\n         -6.1347e-02,  7.8486e-02,  2.2220e-02,  1.2293e-01,  1.9137e-02,\n          3.6239e-01, -3.9407e-03, -3.0480e-01,  1.0109e-01,  1.4238e-01,\n         -1.0127e-01,  1.8982e-01, -7.3263e-02, -2.4488e-01,  4.4750e-01,\n          3.5579e-01, -1.6979e-01,  1.6875e-01,  2.4465e-02, -1.2170e-01,\n         -9.6275e-02,  8.9936e-02,  6.1709e-01,  1.4500e-01, -4.8076e-01,\n         -3.0713e-01,  1.4727e-01, -7.0945e-03, -1.5526e-01,  9.5915e-02,\n          7.4484e-02,  4.3584e-01,  1.6116e-01, -5.9871e-01, -5.9422e-01,\n          7.6837e-02, -1.5509e-01, -3.6611e-01,  2.8282e-02,  3.7231e-01,\n          3.2762e-01,  2.2060e-02, -3.5888e-01, -2.4051e-01,  6.4066e-02,\n          3.5439e-01,  1.2462e-01,  1.6493e-01, -3.1871e-01,  5.5375e-02,\n          1.1820e-01,  8.3088e-01,  8.5695e-02, -1.1434e-02,  5.5705e-02,\n         -3.7754e-02,  1.1020e-01, -3.7759e-01,  1.2221e-01,  1.5877e-01,\n          3.7045e-01, -2.2702e-01,  4.3940e-01, -1.2291e-01,  6.0639e-02,\n          9.0442e-03, -1.1641e-01,  1.6571e-02, -2.3472e-01,  4.0214e-01,\n          6.4819e-03,  6.5207e-03, -6.6666e-01,  1.4141e-01, -1.0585e-01,\n         -2.4113e-01,  2.0391e-01, -1.0582e-01, -2.7862e-01, -1.3709e-01,\n          2.6258e-03, -7.9851e-02,  4.0725e-03, -4.6333e-01, -8.4179e-02,\n         -3.8501e-02, -2.1379e-01,  9.3424e-02, -3.2262e-01, -3.8604e-01,\n          2.5370e-01,  1.5727e-01, -7.4532e-01, -1.9181e-01,  1.5279e-01,\n         -2.5710e-01, -5.3802e-01,  3.6783e-01,  3.5995e-01, -2.0221e-01,\n         -2.0596e-01,  5.2864e-01,  2.7097e-01,  1.5769e-01,  4.6152e-01,\n         -4.7203e-01, -1.2711e-01,  2.9948e-02, -8.5174e-02, -2.4472e-01,\n         -1.4154e-01,  3.8125e-01,  2.8051e-01, -1.8072e-01,  4.8548e-01,\n          2.4945e-01,  1.4104e-01,  3.8624e-01, -2.8026e-01, -2.0120e-01,\n          2.8732e-02, -1.1231e-02, -3.6426e-01,  2.6251e-02, -3.7851e-02,\n          6.4009e-01, -1.5928e-01,  9.5855e-02, -6.6296e-02,  1.7410e-01,\n          3.8996e-02,  7.4717e-02, -1.3931e-01,  5.8656e-01,  4.9502e-01,\n         -2.6947e-02, -4.5381e-01, -2.7717e-01, -1.0380e-01, -1.1805e-01,\n          3.7948e-01,  9.4765e-02,  2.8403e-01,  1.1377e-01, -4.7931e-01,\n         -2.5457e-01,  1.8128e-02,  1.6517e-01,  3.1461e-01, -2.5417e-02,\n         -2.0248e-01, -4.7060e-02,  6.1397e-02,  5.4805e-01,  1.4530e-01,\n          7.1823e-02, -3.3883e-01, -1.8383e-01,  3.2484e-01,  6.6465e-02,\n         -2.4925e-01,  1.2773e-01,  3.5344e-02,  3.2701e-01, -8.5392e-02,\n          4.4462e-01, -1.3644e-01,  1.4186e-01, -2.9954e-01,  9.3068e-02,\n          4.8697e-01, -4.9256e-01,  1.0619e-01,  4.2752e-01, -1.7284e-01,\n         -2.3642e-01, -4.4011e-02, -2.9467e-01,  6.1980e-01,  5.8373e-01,\n          2.2160e-01, -2.1866e-02,  1.7643e-01, -9.1520e-03,  1.2929e-01,\n         -7.3082e-02,  1.6397e-01,  5.8583e-02, -4.6242e-01,  4.3455e-01,\n         -1.0087e-01, -3.2727e-01,  2.2628e-01, -3.4582e-02,  1.6172e-01,\n         -2.7409e-01,  1.0528e-01, -5.9848e-02,  2.3226e-01,  1.4564e-01,\n         -1.2072e-01,  2.3905e-01, -1.9347e-01, -4.6393e-02,  2.3129e-01,\n         -5.2212e-01, -3.7706e-01,  1.7923e-01, -1.3713e-01, -9.8761e-02,\n         -4.0970e-03,  3.2820e-01, -6.4838e-01,  3.7760e-01,  1.0785e-01,\n         -2.2988e-01,  3.9778e-01, -1.8354e-01, -2.0468e-01,  8.5161e-03,\n          2.8459e-02, -5.1400e-01,  2.5988e-01, -1.5684e-01,  5.7713e-01,\n         -1.2787e-01,  2.5969e-01,  1.0446e-01,  7.4681e-04, -2.0539e-01,\n         -1.1128e-01, -1.0686e-01, -1.8856e-02,  2.0551e-01,  3.8597e-01,\n          3.2728e-01,  2.5913e-01,  5.2154e-01]], device='cuda:0',\n       grad_fn=<DivBackward0>), hidden_states=(tensor([[[ 0.3790, -0.1398, -0.1771,  ...,  0.1405, -0.0283,  0.1839],\n         [-0.3286,  0.1314, -0.1459,  ...,  0.1504, -0.0726, -0.9195],\n         [-0.4018, -0.7783,  0.3085,  ...,  0.2146, -0.1665,  0.1573],\n         ...,\n         [ 0.0851, -0.2625, -0.4894,  ...,  0.2734,  0.4745,  1.1782],\n         [ 0.1677,  0.7349, -0.2215,  ..., -0.0586,  0.4081,  0.0223],\n         [-0.5726,  0.0112,  0.0245,  ..., -0.1072,  0.2156, -0.0299]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0796, -0.0358, -0.2100,  ..., -0.0925,  0.1244,  0.1888],\n         [-0.1361,  0.1932, -0.3597,  ..., -0.0295,  0.2344, -0.5821],\n         [-0.1606, -0.3572, -0.7043,  ..., -0.0127,  0.1001,  0.1497],\n         ...,\n         [ 0.5795, -0.2205, -0.4840,  ..., -0.1051,  0.7013,  0.6734],\n         [ 0.5804,  0.1233, -0.3604,  ..., -0.4208,  0.3692, -0.3083],\n         [ 0.1685, -0.1799, -0.1704,  ..., -0.3674,  0.2134,  0.0064]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0183, -0.3107, -0.1695,  ..., -0.4951, -0.3178,  0.3724],\n         [-0.7932,  0.6165, -0.3781,  ..., -0.1443, -0.8263, -0.0594],\n         [-0.5486, -0.0839, -0.6945,  ..., -0.4000, -0.2905,  0.2969],\n         ...,\n         [ 0.8178,  0.1379, -0.1783,  ..., -0.4655, -0.3185,  0.7949],\n         [ 0.5836,  0.5550, -0.3810,  ..., -0.6955, -0.9483, -0.0760],\n         [ 0.0729, -0.0122, -0.0600,  ..., -0.0596, -0.1522,  0.0302]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.2324, -0.0543, -0.6694,  ..., -0.5096, -0.4335,  0.2488],\n         [-1.4307,  1.3544, -0.3003,  ..., -0.7542, -1.0228, -0.9291],\n         [-1.2292,  0.1476, -0.9470,  ..., -0.4628, -0.2401,  0.3044],\n         ...,\n         [ 1.0194,  0.5541, -0.2348,  ..., -0.1541, -0.1016,  0.5341],\n         [ 0.8387,  1.2867, -0.0927,  ..., -0.7560, -0.3953, -0.5713],\n         [ 0.0315, -0.0189,  0.0095,  ..., -0.0260, -0.0536, -0.0273]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-9.5326e-01, -4.3661e-01, -9.4581e-01,  ..., -1.5457e-01,\n          -6.4549e-01, -1.9762e-01],\n         [-2.1118e+00,  8.4958e-01,  3.3048e-01,  ...,  1.1778e-01,\n          -8.8292e-01, -9.3446e-01],\n         [-1.1577e+00, -3.1500e-01, -7.4675e-01,  ...,  2.2091e-01,\n          -2.0268e-01,  4.8733e-01],\n         ...,\n         [ 4.8777e-01,  2.2107e-01,  3.3298e-01,  ...,  1.6233e-01,\n           9.3253e-02,  3.7051e-01],\n         [ 2.6080e-01,  9.9856e-01,  3.5275e-01,  ..., -2.5345e-02,\n          -2.1419e-01, -8.3197e-01],\n         [ 2.2233e-02,  2.0702e-03,  3.6527e-02,  ..., -5.7560e-02,\n          -1.1700e-01, -5.4931e-02]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.9370, -0.6154,  0.0175,  ..., -0.2686,  0.0505,  0.3943],\n         [-1.4244, -0.1362,  0.5284,  ...,  0.1380, -0.2261, -0.3084],\n         [-0.7744, -0.5110, -0.2723,  ...,  0.0668,  0.0397,  0.6541],\n         ...,\n         [ 0.0961,  0.1713,  0.6896,  ..., -0.0356,  0.1312,  0.2198],\n         [-0.2215,  0.0862,  0.9392,  ..., -0.1537, -0.0156, -0.4499],\n         [-0.1323, -0.0390,  0.1072,  ...,  0.0682, -0.0397, -0.2653]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-2.8095e-01,  1.9375e-01, -2.3601e-01,  ...,  2.4750e-04,\n           1.8413e-01,  7.4281e-01],\n         [-2.0558e-01,  5.6973e-01, -3.4450e-01,  ...,  3.1061e-01,\n           7.4593e-03,  6.6465e-01],\n         [-2.6471e-01,  4.7577e-01, -8.7475e-01,  ...,  4.3364e-01,\n           1.6303e-02,  1.2238e+00],\n         ...,\n         [ 2.1979e-01,  2.8544e-02, -4.8508e-01,  ...,  1.5100e-01,\n           5.6132e-01,  6.3370e-01],\n         [ 8.1528e-02,  5.9031e-01, -1.4732e-01,  ..., -5.9024e-02,\n           5.9021e-01,  8.1966e-01],\n         [-7.2517e-03,  1.6594e-01, -7.6334e-01,  ...,  5.0187e-01,\n           3.8227e-01,  5.1416e-01]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>)), attentions=None)\n:Dictionary inputs to traced functions must have consistent type. Found Tensor and Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmobile_optimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize_for_mobile\n\u001b[1;32m----> 2\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtokens_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments_tensors\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m opt_model \u001b[38;5;241m=\u001b[39m optimize_for_mobile(traced_model)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\_trace.py:741\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m--> 741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    757\u001b[0m ):\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    759\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    760\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    767\u001b[0m         _module_class,\n\u001b[0;32m    768\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\torch\\jit\\_trace.py:958\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    954\u001b[0m     argument_names \u001b[38;5;241m=\u001b[39m get_callable_argument_names(func)\n\u001b[0;32m    956\u001b[0m example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m--> 958\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tracer cannot infer type of BaseModelOutputWithPooling(last_hidden_state=tensor([[[-2.8095e-01,  1.9375e-01, -2.3601e-01,  ...,  2.4750e-04,\n           1.8413e-01,  7.4281e-01],\n         [-2.0558e-01,  5.6973e-01, -3.4450e-01,  ...,  3.1061e-01,\n           7.4593e-03,  6.6465e-01],\n         [-2.6471e-01,  4.7577e-01, -8.7475e-01,  ...,  4.3364e-01,\n           1.6303e-02,  1.2238e+00],\n         ...,\n         [ 2.1979e-01,  2.8544e-02, -4.8508e-01,  ...,  1.5100e-01,\n           5.6132e-01,  6.3370e-01],\n         [ 8.1528e-02,  5.9031e-01, -1.4732e-01,  ..., -5.9024e-02,\n           5.9021e-01,  8.1966e-01],\n         [-7.2517e-03,  1.6594e-01, -7.6334e-01,  ...,  5.0187e-01,\n           3.8227e-01,  5.1416e-01]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 4.6693e-02,  4.0107e-02, -3.7071e-01, -2.7972e-02, -9.5654e-02,\n         -8.7964e-02,  1.8528e-02,  2.7150e-01, -2.4230e-01,  9.8927e-05,\n         -3.4853e-01, -5.7866e-01, -1.3977e-01,  3.4567e-01, -3.4365e-01,\n         -9.6294e-03, -2.6303e-02, -2.1803e-01, -1.1859e-01,  7.5814e-02,\n          2.7154e-01, -2.1654e-01, -3.3980e-01,  3.5713e-01,  7.2184e-02,\n          7.7747e-02,  2.0000e-01,  3.3041e-01,  1.5145e-01, -3.1463e-01,\n         -8.3670e-03, -6.3714e-02,  4.2273e-01,  2.9969e-01,  5.7845e-02,\n          2.3974e-01, -4.7594e-02, -1.6258e-01, -1.6344e-01, -1.2472e-01,\n         -1.7768e-01,  5.6963e-03, -2.2802e-01,  6.1100e-04,  4.6322e-01,\n         -3.9256e-02,  4.0616e-01, -3.4898e-01,  8.9205e-02, -1.6020e-01,\n          9.7896e-02, -1.6947e-01,  2.7750e-02,  3.5056e-01,  2.2463e-01,\n         -2.5251e-02, -8.3530e-02,  1.1967e-02,  1.8789e-01,  3.0655e-01,\n          6.2255e-02, -3.2581e-02,  2.6660e-02, -9.0701e-02, -3.4137e-01,\n         -2.6564e-01, -1.7123e-01,  3.8302e-01, -5.6068e-01,  1.9953e-01,\n          1.5175e-01,  2.5360e-01,  1.3732e-01, -1.1475e-01,  5.0170e-02,\n          2.9594e-01,  4.7890e-01,  8.9323e-02,  4.1593e-01,  2.3964e-01,\n          2.2769e-01,  1.6559e-01,  2.8347e-01,  1.4929e-01,  2.6771e-01,\n         -1.7873e-01, -1.1776e-01, -8.1478e-02, -2.2917e-01,  6.6764e-02,\n         -1.5156e-01,  1.4597e-01,  1.7807e-01, -7.8407e-02, -1.1961e-02,\n         -5.5800e-03,  3.2663e-02, -3.6713e-02, -1.0436e-01, -2.6302e-01,\n          2.9339e-01,  2.6338e-01, -8.5827e-03,  2.8918e-01,  2.0783e-01,\n          6.6061e-02,  8.6752e-02,  2.6657e-01, -2.1378e-01,  5.5170e-01,\n         -3.0502e-01,  1.9279e-02,  2.0699e-01, -4.1495e-01, -1.3450e-03,\n         -3.4352e-02, -6.2233e-01,  5.7239e-02, -5.3565e-01, -1.9556e-01,\n          2.1748e-01, -2.5492e-02, -1.7693e-01, -9.1041e-02, -8.2664e-02,\n          1.1888e-01, -2.6719e-01,  1.9183e-01, -8.6937e-02, -1.1656e-01,\n          9.3656e-02, -2.4710e-01,  4.2405e-01, -9.8818e-02, -1.9976e-01,\n          5.9881e-02, -2.5661e-01, -4.5558e-04,  5.4826e-02, -9.8980e-02,\n         -2.1050e-01, -3.2874e-02, -1.3713e-01,  1.4698e-01,  1.3910e-01,\n         -1.8795e-01,  2.5036e-02,  1.5718e-01,  7.8290e-02,  3.4586e-01,\n         -1.9084e-01, -2.4636e-01, -2.7752e-01, -3.2277e-01, -2.1060e-01,\n          1.5730e-02, -1.6699e-01, -4.1642e-01,  1.0134e-01,  1.4960e-01,\n         -1.6346e-01, -5.3434e-01, -2.3700e-01, -4.8405e-01, -4.0551e-01,\n          1.3371e-01,  1.7637e-01, -4.6814e-01,  2.1758e-01, -9.9638e-02,\n         -6.6738e-02,  5.5015e-01,  1.1654e-01,  1.7745e-02, -4.3454e-01,\n         -9.5787e-02,  3.9904e-01, -1.8967e-01,  1.4247e-01,  4.7395e-01,\n         -1.0383e-02, -2.8846e-02, -4.6897e-02, -1.0486e-01, -5.7609e-01,\n         -3.6152e-01,  2.1397e-01, -3.2449e-01,  3.2640e-01,  1.3473e-01,\n         -4.2674e-02,  3.7581e-01, -1.7810e-01, -1.5909e-01,  4.2082e-01,\n          2.9741e-01, -1.1551e-01, -3.5975e-01,  3.0413e-01,  2.8718e-01,\n          8.3572e-02, -7.6330e-02,  3.6599e-01, -3.5791e-01, -1.1984e-01,\n          4.6330e-02, -2.1017e-01,  9.6010e-02,  2.5951e-01,  3.1474e-01,\n          3.2159e-01,  1.7671e-01, -8.4449e-02,  1.2721e-01,  6.9955e-02,\n          3.3938e-01, -3.6960e-02, -2.6437e-01, -3.6957e-01, -3.1519e-01,\n         -2.8044e-01, -3.1960e-02, -3.2118e-01, -3.3568e-01,  5.6361e-02,\n         -7.9344e-02, -1.0817e-01, -4.1884e-01,  5.6373e-01,  1.7060e-01,\n         -3.7492e-01, -4.9206e-01, -1.1492e-01, -5.3896e-02, -1.0919e-01,\n         -2.6218e-01,  2.0154e-01,  4.4679e-02,  6.2231e-02,  8.6094e-02,\n         -1.1548e-01,  4.0717e-01,  1.0435e-01,  1.1964e-01,  5.5811e-02,\n         -1.3387e-01, -3.0432e-01,  1.9487e-01, -2.3411e-01,  2.3979e-01,\n          8.3957e-02, -1.7051e-01,  2.9582e-01,  7.6980e-02, -2.1012e-01,\n         -2.2019e-01,  5.1967e-02, -2.0904e-01, -3.1589e-01,  1.3976e-01,\n          7.3378e-02,  1.2886e-02, -3.7941e-02, -4.1992e-01, -6.7913e-01,\n         -3.8605e-02,  3.3250e-01, -1.4962e-01, -2.3367e-01,  2.1604e-02,\n          9.5433e-01, -3.3314e-01,  3.3863e-02, -1.1041e-01,  1.3514e-01,\n          1.7344e-01,  3.0827e-01,  1.9480e-02,  1.3813e-01,  7.5715e-03,\n          2.6293e-01,  1.4490e-01, -3.7647e-01,  2.0370e-01, -1.2067e-01,\n         -1.9894e-01, -2.9209e-01, -1.8561e-01, -2.8015e-01, -1.9971e-01,\n          7.9241e-02,  2.7789e-01,  2.0711e-01,  9.2009e-02, -1.2497e-01,\n          1.3548e-02, -4.1796e-01, -9.4340e-02,  3.9416e-02,  4.4411e-02,\n         -2.0689e-01,  7.8503e-02,  2.8727e-01,  4.8503e-01, -3.9871e-01,\n          5.5450e-02, -2.8031e-01, -1.6286e-01,  3.7779e-01, -4.2408e-01,\n          4.3749e-03,  1.3447e-01, -7.2981e-02, -2.7551e-01, -1.6305e-01,\n         -1.8913e-01, -4.5124e-02,  1.1433e-01, -1.1529e-01,  1.6803e-01,\n         -4.9927e-02,  3.2612e-02, -1.4389e-01, -6.5885e-01, -6.7365e-02,\n         -1.4673e-01, -4.8238e-02, -1.4534e-01,  6.4086e-01,  3.6175e-01,\n         -1.3694e-01, -3.0026e-01,  4.9679e-01, -1.2416e-01, -3.7848e-01,\n         -2.7967e-01, -3.2192e-02, -5.8232e-01,  2.5316e-01, -3.7612e-01,\n         -7.5341e-02, -1.0061e-01, -4.2381e-01,  2.0430e-01,  3.5421e-01,\n          4.7512e-01, -2.4318e-02, -3.1277e-01,  5.9076e-02, -2.8672e-01,\n         -2.0519e-01,  1.0690e-01,  2.1698e-01, -4.6779e-01, -4.2751e-01,\n         -7.9820e-02, -1.0694e-01, -1.5257e-01, -2.0322e-01,  2.8396e-01,\n         -9.1225e-02,  5.7800e-02,  2.5577e-01, -3.4644e-01,  1.6233e-01,\n          6.3564e-01, -3.3724e-01,  1.9419e-01, -3.6530e-01,  1.0729e-01,\n         -4.0173e-01, -3.8239e-01, -1.6141e-01,  7.4453e-02, -4.3982e-01,\n         -3.7165e-01,  9.4542e-02, -3.9154e-01, -2.8783e-01, -2.0081e-01,\n          2.1023e-02, -3.1915e-01,  5.1339e-01,  4.0421e-02, -5.2414e-01,\n         -1.3860e-01,  5.0436e-01, -4.0707e-01, -5.7195e-01,  2.2586e-02,\n         -2.6875e-01,  1.8693e-01, -2.5197e-01,  4.9181e-01, -5.9845e-01,\n         -6.9314e-02, -5.7444e-02,  7.7586e-02,  3.3125e-02,  1.4080e-01,\n         -1.8913e-01,  1.2483e-01,  1.8294e-01, -1.0081e+00,  2.8459e-01,\n          2.2694e-01,  2.5965e-01, -7.4635e-02,  3.8446e-01, -4.5130e-01,\n         -1.8509e-01,  8.3799e-02,  1.6537e-01,  3.1572e-01,  7.6182e-02,\n          1.5847e-01,  3.7006e-01,  3.2070e-01,  2.1765e-01,  1.5052e-01,\n         -4.7995e-01, -4.4966e-01, -3.5002e-01,  1.4406e-01, -8.8948e-02,\n          5.1441e-01, -4.1660e-01,  3.4986e-01, -1.1441e-01, -1.0048e-01,\n          1.6408e-01,  8.8887e-02,  1.5933e-01,  9.3904e-02,  1.1400e-01,\n          1.8206e-01,  3.3361e-01, -1.2313e-01, -3.8495e-01,  2.2998e-01,\n          1.0782e-01, -4.6062e-01, -2.9444e-01,  2.4281e-01, -1.2217e-01,\n         -2.4393e-01,  1.8185e-01, -4.1725e-01, -3.6603e-01, -7.4732e-02,\n          3.1326e-01, -1.5488e-01, -6.4646e-01, -8.3071e-02,  2.3564e-02,\n         -3.8589e-01,  1.0421e-01, -1.0521e-01, -1.6525e-01, -1.1996e-01,\n          1.4955e-01,  2.4033e-01, -8.6674e-02, -5.4170e-01, -2.5583e-01,\n          5.6224e-02, -1.6628e-01, -4.1819e-01, -2.3568e-01, -4.9047e-01,\n          1.7005e-02,  3.6465e-04,  2.6325e-01, -2.7289e-01,  1.3864e-01,\n          8.5591e-02,  3.5195e-01, -5.7063e-02,  5.9695e-03,  3.2521e-02,\n         -1.8778e-01,  1.8255e-01,  2.8537e-01, -1.4293e-02,  1.1457e-02,\n         -3.1442e-01,  1.9079e-01, -3.3102e-01, -4.6480e-02, -2.7503e-01,\n          4.3797e-01,  2.5024e-01, -1.1668e-01, -1.2751e-01, -1.4074e-01,\n          1.5598e-01, -6.7441e-02, -1.0944e-01, -4.0199e-01,  1.6955e-01,\n         -3.8893e-01,  1.8294e-01,  1.3988e-01,  3.9773e-01, -1.6795e-01,\n          6.2370e-02, -8.5830e-02, -3.9306e-02, -3.4178e-01, -1.6844e-01,\n          7.8893e-03, -3.4126e-01,  4.5400e-01,  1.6699e-01, -4.2358e-01,\n         -1.6840e-01, -5.7318e-02,  3.9432e-02,  2.4061e-01,  1.4965e-01,\n          1.8138e-01, -6.6945e-02, -3.7419e-01, -7.3155e-02, -2.2167e-01,\n          1.9476e-01, -9.5210e-02,  2.7536e-01, -1.5343e-01, -5.6016e-01,\n         -6.1347e-02,  7.8486e-02,  2.2220e-02,  1.2293e-01,  1.9137e-02,\n          3.6239e-01, -3.9407e-03, -3.0480e-01,  1.0109e-01,  1.4238e-01,\n         -1.0127e-01,  1.8982e-01, -7.3263e-02, -2.4488e-01,  4.4750e-01,\n          3.5579e-01, -1.6979e-01,  1.6875e-01,  2.4465e-02, -1.2170e-01,\n         -9.6275e-02,  8.9936e-02,  6.1709e-01,  1.4500e-01, -4.8076e-01,\n         -3.0713e-01,  1.4727e-01, -7.0945e-03, -1.5526e-01,  9.5915e-02,\n          7.4484e-02,  4.3584e-01,  1.6116e-01, -5.9871e-01, -5.9422e-01,\n          7.6837e-02, -1.5509e-01, -3.6611e-01,  2.8282e-02,  3.7231e-01,\n          3.2762e-01,  2.2060e-02, -3.5888e-01, -2.4051e-01,  6.4066e-02,\n          3.5439e-01,  1.2462e-01,  1.6493e-01, -3.1871e-01,  5.5375e-02,\n          1.1820e-01,  8.3088e-01,  8.5695e-02, -1.1434e-02,  5.5705e-02,\n         -3.7754e-02,  1.1020e-01, -3.7759e-01,  1.2221e-01,  1.5877e-01,\n          3.7045e-01, -2.2702e-01,  4.3940e-01, -1.2291e-01,  6.0639e-02,\n          9.0442e-03, -1.1641e-01,  1.6571e-02, -2.3472e-01,  4.0214e-01,\n          6.4819e-03,  6.5207e-03, -6.6666e-01,  1.4141e-01, -1.0585e-01,\n         -2.4113e-01,  2.0391e-01, -1.0582e-01, -2.7862e-01, -1.3709e-01,\n          2.6258e-03, -7.9851e-02,  4.0725e-03, -4.6333e-01, -8.4179e-02,\n         -3.8501e-02, -2.1379e-01,  9.3424e-02, -3.2262e-01, -3.8604e-01,\n          2.5370e-01,  1.5727e-01, -7.4532e-01, -1.9181e-01,  1.5279e-01,\n         -2.5710e-01, -5.3802e-01,  3.6783e-01,  3.5995e-01, -2.0221e-01,\n         -2.0596e-01,  5.2864e-01,  2.7097e-01,  1.5769e-01,  4.6152e-01,\n         -4.7203e-01, -1.2711e-01,  2.9948e-02, -8.5174e-02, -2.4472e-01,\n         -1.4154e-01,  3.8125e-01,  2.8051e-01, -1.8072e-01,  4.8548e-01,\n          2.4945e-01,  1.4104e-01,  3.8624e-01, -2.8026e-01, -2.0120e-01,\n          2.8732e-02, -1.1231e-02, -3.6426e-01,  2.6251e-02, -3.7851e-02,\n          6.4009e-01, -1.5928e-01,  9.5855e-02, -6.6296e-02,  1.7410e-01,\n          3.8996e-02,  7.4717e-02, -1.3931e-01,  5.8656e-01,  4.9502e-01,\n         -2.6947e-02, -4.5381e-01, -2.7717e-01, -1.0380e-01, -1.1805e-01,\n          3.7948e-01,  9.4765e-02,  2.8403e-01,  1.1377e-01, -4.7931e-01,\n         -2.5457e-01,  1.8128e-02,  1.6517e-01,  3.1461e-01, -2.5417e-02,\n         -2.0248e-01, -4.7060e-02,  6.1397e-02,  5.4805e-01,  1.4530e-01,\n          7.1823e-02, -3.3883e-01, -1.8383e-01,  3.2484e-01,  6.6465e-02,\n         -2.4925e-01,  1.2773e-01,  3.5344e-02,  3.2701e-01, -8.5392e-02,\n          4.4462e-01, -1.3644e-01,  1.4186e-01, -2.9954e-01,  9.3068e-02,\n          4.8697e-01, -4.9256e-01,  1.0619e-01,  4.2752e-01, -1.7284e-01,\n         -2.3642e-01, -4.4011e-02, -2.9467e-01,  6.1980e-01,  5.8373e-01,\n          2.2160e-01, -2.1866e-02,  1.7643e-01, -9.1520e-03,  1.2929e-01,\n         -7.3082e-02,  1.6397e-01,  5.8583e-02, -4.6242e-01,  4.3455e-01,\n         -1.0087e-01, -3.2727e-01,  2.2628e-01, -3.4582e-02,  1.6172e-01,\n         -2.7409e-01,  1.0528e-01, -5.9848e-02,  2.3226e-01,  1.4564e-01,\n         -1.2072e-01,  2.3905e-01, -1.9347e-01, -4.6393e-02,  2.3129e-01,\n         -5.2212e-01, -3.7706e-01,  1.7923e-01, -1.3713e-01, -9.8761e-02,\n         -4.0970e-03,  3.2820e-01, -6.4838e-01,  3.7760e-01,  1.0785e-01,\n         -2.2988e-01,  3.9778e-01, -1.8354e-01, -2.0468e-01,  8.5161e-03,\n          2.8459e-02, -5.1400e-01,  2.5988e-01, -1.5684e-01,  5.7713e-01,\n         -1.2787e-01,  2.5969e-01,  1.0446e-01,  7.4681e-04, -2.0539e-01,\n         -1.1128e-01, -1.0686e-01, -1.8856e-02,  2.0551e-01,  3.8597e-01,\n          3.2728e-01,  2.5913e-01,  5.2154e-01]], device='cuda:0',\n       grad_fn=<DivBackward0>), hidden_states=(tensor([[[ 0.3790, -0.1398, -0.1771,  ...,  0.1405, -0.0283,  0.1839],\n         [-0.3286,  0.1314, -0.1459,  ...,  0.1504, -0.0726, -0.9195],\n         [-0.4018, -0.7783,  0.3085,  ...,  0.2146, -0.1665,  0.1573],\n         ...,\n         [ 0.0851, -0.2625, -0.4894,  ...,  0.2734,  0.4745,  1.1782],\n         [ 0.1677,  0.7349, -0.2215,  ..., -0.0586,  0.4081,  0.0223],\n         [-0.5726,  0.0112,  0.0245,  ..., -0.1072,  0.2156, -0.0299]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0796, -0.0358, -0.2100,  ..., -0.0925,  0.1244,  0.1888],\n         [-0.1361,  0.1932, -0.3597,  ..., -0.0295,  0.2344, -0.5821],\n         [-0.1606, -0.3572, -0.7043,  ..., -0.0127,  0.1001,  0.1497],\n         ...,\n         [ 0.5795, -0.2205, -0.4840,  ..., -0.1051,  0.7013,  0.6734],\n         [ 0.5804,  0.1233, -0.3604,  ..., -0.4208,  0.3692, -0.3083],\n         [ 0.1685, -0.1799, -0.1704,  ..., -0.3674,  0.2134,  0.0064]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0183, -0.3107, -0.1695,  ..., -0.4951, -0.3178,  0.3724],\n         [-0.7932,  0.6165, -0.3781,  ..., -0.1443, -0.8263, -0.0594],\n         [-0.5486, -0.0839, -0.6945,  ..., -0.4000, -0.2905,  0.2969],\n         ...,\n         [ 0.8178,  0.1379, -0.1783,  ..., -0.4655, -0.3185,  0.7949],\n         [ 0.5836,  0.5550, -0.3810,  ..., -0.6955, -0.9483, -0.0760],\n         [ 0.0729, -0.0122, -0.0600,  ..., -0.0596, -0.1522,  0.0302]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.2324, -0.0543, -0.6694,  ..., -0.5096, -0.4335,  0.2488],\n         [-1.4307,  1.3544, -0.3003,  ..., -0.7542, -1.0228, -0.9291],\n         [-1.2292,  0.1476, -0.9470,  ..., -0.4628, -0.2401,  0.3044],\n         ...,\n         [ 1.0194,  0.5541, -0.2348,  ..., -0.1541, -0.1016,  0.5341],\n         [ 0.8387,  1.2867, -0.0927,  ..., -0.7560, -0.3953, -0.5713],\n         [ 0.0315, -0.0189,  0.0095,  ..., -0.0260, -0.0536, -0.0273]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-9.5326e-01, -4.3661e-01, -9.4581e-01,  ..., -1.5457e-01,\n          -6.4549e-01, -1.9762e-01],\n         [-2.1118e+00,  8.4958e-01,  3.3048e-01,  ...,  1.1778e-01,\n          -8.8292e-01, -9.3446e-01],\n         [-1.1577e+00, -3.1500e-01, -7.4675e-01,  ...,  2.2091e-01,\n          -2.0268e-01,  4.8733e-01],\n         ...,\n         [ 4.8777e-01,  2.2107e-01,  3.3298e-01,  ...,  1.6233e-01,\n           9.3253e-02,  3.7051e-01],\n         [ 2.6080e-01,  9.9856e-01,  3.5275e-01,  ..., -2.5345e-02,\n          -2.1419e-01, -8.3197e-01],\n         [ 2.2233e-02,  2.0702e-03,  3.6527e-02,  ..., -5.7560e-02,\n          -1.1700e-01, -5.4931e-02]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.9370, -0.6154,  0.0175,  ..., -0.2686,  0.0505,  0.3943],\n         [-1.4244, -0.1362,  0.5284,  ...,  0.1380, -0.2261, -0.3084],\n         [-0.7744, -0.5110, -0.2723,  ...,  0.0668,  0.0397,  0.6541],\n         ...,\n         [ 0.0961,  0.1713,  0.6896,  ..., -0.0356,  0.1312,  0.2198],\n         [-0.2215,  0.0862,  0.9392,  ..., -0.1537, -0.0156, -0.4499],\n         [-0.1323, -0.0390,  0.1072,  ...,  0.0682, -0.0397, -0.2653]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-2.8095e-01,  1.9375e-01, -2.3601e-01,  ...,  2.4750e-04,\n           1.8413e-01,  7.4281e-01],\n         [-2.0558e-01,  5.6973e-01, -3.4450e-01,  ...,  3.1061e-01,\n           7.4593e-03,  6.6465e-01],\n         [-2.6471e-01,  4.7577e-01, -8.7475e-01,  ...,  4.3364e-01,\n           1.6303e-02,  1.2238e+00],\n         ...,\n         [ 2.1979e-01,  2.8544e-02, -4.8508e-01,  ...,  1.5100e-01,\n           5.6132e-01,  6.3370e-01],\n         [ 8.1528e-02,  5.9031e-01, -1.4732e-01,  ..., -5.9024e-02,\n           5.9021e-01,  8.1966e-01],\n         [-7.2517e-03,  1.6594e-01, -7.6334e-01,  ...,  5.0187e-01,\n           3.8227e-01,  5.1416e-01]]], device='cuda:0',\n       grad_fn=<NativeLayerNormBackward0>)), attentions=None)\n:Dictionary inputs to traced functions must have consistent type. Found Tensor and Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]"
     ]
    }
   ],
   "source": [
    "opt_model = optimize_for_mobile(traced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'quantized_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mquantized_model\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./quantized_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'quantized_model' is not defined"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# torch.save(quantized_model, './quantized_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with default BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preparing Wiki-1M data\n",
    "\n",
    "Use huggingface `datasets` library to load local file data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-84caea1147087fa9\n",
      "Reusing dataset text (C:\\Users\\ng-ka\\.cache\\huggingface\\datasets\\text\\default-84caea1147087fa9\\0.0.0\\4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "100%|| 1/1 [00:00<00:00,  5.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {'train': 'data/training/wiki1m_for_simcse.txt'}\n",
    "datasets = load_dataset('text', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_names: ['text']\n",
      "sent0_cname: text | sent1_cname: text\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised / Self-supervised dataset\n",
    "\n",
    "column_names = datasets[\"train\"].column_names\n",
    "sent0_cname = column_names[0]\n",
    "sent1_cname = column_names[0]\n",
    "\n",
    "print('column_names:', column_names)\n",
    "print('sent0_cname:', sent0_cname, '| sent1_cname:', sent1_cname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(examples):\n",
    "    total = len(examples[sent0_cname])\n",
    "\n",
    "    # Avoid \"None\" fields \n",
    "    for idx in range(total):\n",
    "        if examples[sent0_cname][idx] is None:\n",
    "            examples[sent0_cname][idx] = \" \"\n",
    "        if examples[sent1_cname][idx] is None:\n",
    "            examples[sent1_cname][idx] = \" \"\n",
    "    \n",
    "    sentences = examples[sent0_cname] + examples[sent1_cname]\n",
    "\n",
    "    sent_features = tokenizer(\n",
    "        sentences,\n",
    "        max_length=32,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    features = {}\n",
    "    for key in sent_features:\n",
    "        features[key] = [[sent_features[key][i], sent_features[key][i+total]] for i in range(total)]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ng-ka\\.cache\\huggingface\\datasets\\text\\default-84caea1147087fa9\\0.0.0\\4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\\cache-dd04d9dec26aeca9.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"].map(prepare_features,\n",
    "                                      batched=True,\n",
    "                                    #   num_proc=24,\n",
    "                                      remove_columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence 1 and Sentence 2 are the same sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Contrastive Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertCLModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, BertModel, BertPreTrainedModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPooling\n",
    "\n",
    "from distilface.modules.pooler import Pooler\n",
    "from distilface.modules.similarity import Similarity\n",
    "\n",
    "\n",
    "class BertCLModel(BertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_first_last', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        if self.training:\n",
    "            return self.cl_forward(self.bert, input_ids, attention_mask, token_type_ids)\n",
    "        else:\n",
    "            return self.sent_emb(self.bert, input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        batch_size = input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "        token_type_ids = token_type_ids.view((-1, token_type_ids.size(-1))) # (bs * num_sent, len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "\n",
    "pretrained_model_name = 'bert-base-uncased'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model = BertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Initial BERT embeddings performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senteval\n",
    "\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [\" \".join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    pooled_result = outputs.pooler_output.cpu()\n",
    "\n",
    "    return pooled_result\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    PATH_TO_DATA = \"./data\"\n",
    "\n",
    "    params = {\"task_path\": PATH_TO_DATA, \"usepytorch\": True, \"kfold\": 10}\n",
    "    tasks = [\"STSBenchmark\", 'STS12', 'STS13', 'STS14', 'STS15']\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    #se = se_engine.SE(params, batcher, prepare)\n",
    "    results = se.eval(tasks)\n",
    "\n",
    "    print('STS12: ', results[\"STS12\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS13: ', results[\"STS13\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS14: ', results[\"STS14\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS15: ', results[\"STS15\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STSB: ', results[\"STSBenchmark\"][\"test\"][\"spearman\"][0])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=1e-05,\n",
    "    per_device_train_batch_size= 128,\n",
    "    per_device_eval_batch_size = 128,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=2,\n",
    "    max_steps= 30000,\n",
    "    logging_steps=5000,\n",
    "    save_steps=5000\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ng-ka\\\\OMSCS\\\\DL\\\\DLProject\\\\contrastive-learning-in-distilled-models'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7614' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7614/30000 1:04:09 < 3:08:39, 1.98 it/s, Epoch 0.97/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-5000\n",
      "Configuration saved in output\\checkpoint-5000\\config.json\n",
      "Model weights saved in output\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-5000\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/bert_cl'\n",
    "\n",
    "train_result = trainer.train()\n",
    "torch.save(model, './bert_model_best_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  fp32  \t Size (KB): 435650.293\n"
     ]
    }
   ],
   "source": [
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size\n",
    "\n",
    "# compare the sizes\n",
    "f=print_size_of_model(model,\"fp32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=print_size_of_model(quantized_model,\"int8\")\n",
    "print(\"{0:.2f} times smaller\".format(f/q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate DistilBert CL Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.6522348679699254\n",
      "STS13:  0.7245264269994489\n",
      "STS14:  0.6591385536542372\n",
      "STS15:  0.7803083813296277\n",
      "STSB:  0.7317242200449551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7701978269277896, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7444988754489594, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.792601430214866, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7923150663580373, pvalue=0.0),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7395838046909169, 4.979487826512024e-239),\n",
       "   'spearman': SpearmanrResult(correlation=0.7317242200449551, pvalue=1.7326856147338482e-231),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.7683647566030786,\n",
       "    'mean': 0.7674610206111909,\n",
       "    'wmean': 0.7691997588084071},\n",
       "   'spearman': {'all': 0.7548919636159135,\n",
       "    'mean': 0.7561793872839839,\n",
       "    'wmean': 0.7507700897004076}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.6587949262407169, 1.5689202234706753e-94),\n",
       "   'spearman': SpearmanrResult(correlation=0.6366967124028455, pvalue=1.678438485809478e-86),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.8536988445568228, 3.8250578501088855e-214),\n",
       "   'spearman': SpearmanrResult(correlation=0.8484792708623435, pvalue=6.624907739378852e-209),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.5164816904486852, 1.1635179273872324e-32),\n",
       "   'spearman': SpearmanrResult(correlation=0.5952382035750191, pvalue=2.43260390535798e-45),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7138032874990049, 8.029507875907565e-118),\n",
       "   'spearman': SpearmanrResult(correlation=0.6947446645580526, pvalue=3.7278633554301037e-109),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6581016211793618, 7.143974085692276e-51),\n",
       "   'spearman': SpearmanrResult(correlation=0.5879248830777675, pvalue=1.8555478590687155e-38),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.7069207633714811,\n",
       "    'mean': 0.6801760739849183,\n",
       "    'wmean': 0.697995635935946},\n",
       "   'spearman': {'all': 0.6522348679699254,\n",
       "    'mean': 0.6726167468952057,\n",
       "    'wmean': 0.6894262708032157}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.5403151553255987, 1.0207250701755277e-15),\n",
       "   'spearman': SpearmanrResult(correlation=0.5848838782020366, pvalue=9.832741978366368e-19),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7313093681559517, 1.9625236627075765e-126),\n",
       "   'spearman': SpearmanrResult(correlation=0.7173859181606141, pvalue=1.568992515213928e-119),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7345926321227985, 3.167469276742905e-96),\n",
       "   'spearman': SpearmanrResult(correlation=0.7342747263141658, pvalue=4.206869681517781e-96),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.7171945633150137,\n",
       "    'mean': 0.6687390518681163,\n",
       "    'wmean': 0.7084720380629278},\n",
       "   'spearman': {'all': 0.7245264269994489,\n",
       "    'mean': 0.6788481742256055,\n",
       "    'wmean': 0.7070070753752618}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.5215587622662345,\n",
       "    9.343138531670588e-33),\n",
       "   'spearman': SpearmanrResult(correlation=0.508523934763729, pvalue=5.744448186293206e-31),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.8013870476948712, 1.7717330852474213e-68),\n",
       "   'spearman': SpearmanrResult(correlation=0.7709496848235667, pvalue=2.4484395981516876e-60),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7451721200687449, 9.46220917969318e-134),\n",
       "   'spearman': SpearmanrResult(correlation=0.7212894362502648, pvalue=2.0088375511523874e-121),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7749328096219927, 3.4197289017445545e-151),\n",
       "   'spearman': SpearmanrResult(correlation=0.7440169915774423, pvalue=4.015389089369636e-133),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7994813884766737, 9.832759062944258e-168),\n",
       "   'spearman': SpearmanrResult(correlation=0.8123071843031526, pvalue=2.528974415180825e-177),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7000792322868198, 1.6406231191391438e-111),\n",
       "   'spearman': SpearmanrResult(correlation=0.6527722606870168, pvalue=2.8233458924619958e-92),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.6834652955428022,\n",
       "    'mean': 0.7237685600692227,\n",
       "    'wmean': 0.7306311253783841},\n",
       "   'spearman': {'all': 0.6591385536542372,\n",
       "    'mean': 0.7016432487341953,\n",
       "    'wmean': 0.7087760215211081}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.7143622843810458,\n",
       "    8.521334360334148e-60),\n",
       "   'spearman': SpearmanrResult(correlation=0.717130123341652, pvalue=1.865638104815194e-60),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7390487700610201,\n",
       "    1.8428341692904094e-130),\n",
       "   'spearman': SpearmanrResult(correlation=0.7404577040278972, pvalue=3.287398896408933e-131),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.768297587208495, 2.871357227274023e-74),\n",
       "   'spearman': SpearmanrResult(correlation=0.7826415004393404, pvalue=8.479720632987105e-79),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7876011189010238, 1.8720917648392475e-159),\n",
       "   'spearman': SpearmanrResult(correlation=0.788291434898209, pvalue=6.395881563291198e-160),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8437452641992345, 2.5360315476033285e-204),\n",
       "   'spearman': SpearmanrResult(correlation=0.850240206668032, pvalue=1.1918244530676417e-210),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7787279451354893,\n",
       "    'mean': 0.7706110049501638,\n",
       "    'wmean': 0.7779312722390123},\n",
       "   'spearman': {'all': 0.7803083813296277,\n",
       "    'mean': 0.7757521938750261,\n",
       "    'wmean': 0.7822187893711586}}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "results = evaluate_model()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertCLModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertCLModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel, DistilBertPreTrainedModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPooling\n",
    "\n",
    "from src.distilface.modules.pooler import Pooler\n",
    "from src.distilface.modules.similarity import Similarity\n",
    "\n",
    "from torch.cuda.amp import autocast \n",
    "\n",
    "#scaler = GradScaler()\n",
    "\n",
    "class DistilBertCLModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_first_last', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        with autocast():\n",
    "            if self.training:\n",
    "                return self.cl_forward(self.distilbert, input_ids, attention_mask)\n",
    "            else:\n",
    "                return self.sent_emb(self.distilbert, input_ids, attention_mask)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None):\n",
    "        batch_size = input_ids.size(0)#64#input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "\n",
    "pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model2 = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "#model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "#model2 = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "\n",
    "training_args2 = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=False,\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size= 64,\n",
    "    per_device_eval_batch_size = 64,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=2,\n",
    "    max_steps= 30000,\n",
    "    logging_steps=5000,\n",
    "    save_steps=5000,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "model2.train()\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model=model2,\n",
    "    args=training_args2,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 49:40, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-5000\n",
      "Configuration saved in output\\checkpoint-5000\\config.json\n",
      "Model weights saved in output\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-10000\n",
      "Configuration saved in output\\checkpoint-10000\\config.json\n",
      "Model weights saved in output\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-15000\n",
      "Configuration saved in output\\checkpoint-15000\\config.json\n",
      "Model weights saved in output\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-20000\n",
      "Configuration saved in output\\checkpoint-20000\\config.json\n",
      "Model weights saved in output\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-25000\n",
      "Configuration saved in output\\checkpoint-25000\\config.json\n",
      "Model weights saved in output\\checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-30000\n",
      "Configuration saved in output\\checkpoint-30000\\config.json\n",
      "Model weights saved in output\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-30000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/distilbert_cl'\n",
    "\n",
    "#train_result = trainer.train(model_path=model_path)\n",
    "train_result2 = trainer2.train()\n",
    "torch.save(model2, './batch64_fp16_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senteval\n",
    "#import SentEval.senteval as senteval\n",
    "#import SentEval_simcse.senteval as senteval\n",
    "#import SentEval_simcse.senteval.engine as se_engine\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [\" \".join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model2(**batch)\n",
    "\n",
    "    pooled_result = outputs.pooler_output.cpu()\n",
    "\n",
    "    return pooled_result\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    PATH_TO_DATA = \"./data\"\n",
    "\n",
    "    params = {\"task_path\": PATH_TO_DATA, \"usepytorch\": True, \"kfold\": 10}\n",
    "    tasks = [\"STSBenchmark\", 'STS12', 'STS13', 'STS14', 'STS15']\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    #se = se_engine.SE(params, batcher, prepare)\n",
    "    results = se.eval(tasks)\n",
    "\n",
    "    print('STS12: ', results[\"STS12\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS13: ', results[\"STS13\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS14: ', results[\"STS14\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS15: ', results[\"STS15\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STSB: ', results[\"STSBenchmark\"][\"test\"][\"spearman\"][0])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.5860086657732572\n",
      "STS13:  0.7462740979049128\n",
      "STS14:  0.6726454938423136\n",
      "STS15:  0.7632500735789172\n",
      "STSB:  0.7239425725655111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7514974091222588, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.728916173975978, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7515928663596871, 5.587693491694605e-273),\n",
       "   'spearman': SpearmanrResult(correlation=0.7571062733767996, pvalue=2.91924659407765e-279),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7324146663602896, 3.863341707867918e-232),\n",
       "   'spearman': SpearmanrResult(correlation=0.7239425725655111, pvalue=2.7955081361595227e-224),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.745320014694186,\n",
       "    'mean': 0.7451683139474118,\n",
       "    'wmean': 0.7484640391161609},\n",
       "   'spearman': {'all': 0.7376444193730962,\n",
       "    'mean': 0.7366550066394296,\n",
       "    'wmean': 0.7330221722091952}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.6420318665513999, 2.2231580917506402e-88),\n",
       "   'spearman': SpearmanrResult(correlation=0.6250375288907182, pvalue=1.5936298376149268e-82),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.7821232084995746, 8.181160183934045e-156),\n",
       "   'spearman': SpearmanrResult(correlation=0.7790254725438126, pvalue=8.414656636378357e-154),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.45579831148351924, 6.297898948763149e-25),\n",
       "   'spearman': SpearmanrResult(correlation=0.5411141409400582, pvalue=2.857397403925653e-36),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7136179540663932, 9.826163343218386e-118),\n",
       "   'spearman': SpearmanrResult(correlation=0.6934438014827883, pvalue=1.3748744170757464e-108),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6382798657374623, 4.883208877814331e-47),\n",
       "   'spearman': SpearmanrResult(correlation=0.5870457672237382, pvalue=2.541504852813737e-38),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.6183244598202621,\n",
       "    'mean': 0.6463702412676698,\n",
       "    'wmean': 0.6651270473739409},\n",
       "   'spearman': {'all': 0.5860086657732572,\n",
       "    'mean': 0.6451333422162231,\n",
       "    'wmean': 0.6614326750327374}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.5921135950867219, 2.8765211843152323e-19),\n",
       "   'spearman': SpearmanrResult(correlation=0.6319923990253394, pvalue=1.8117240840180167e-22),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7731684011000663, 4.38333085981378e-150),\n",
       "   'spearman': SpearmanrResult(correlation=0.7648096228034668, pvalue=5.712060967612397e-145),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7505444160034295, 1.1982965729735423e-102),\n",
       "   'spearman': SpearmanrResult(correlation=0.7529617459710697, pvalue=1.155236306238404e-103),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.7356590985615045,\n",
       "    'mean': 0.7052754707300726,\n",
       "    'wmean': 0.7418941251162428},\n",
       "   'spearman': {'all': 0.7462740979049128,\n",
       "    'mean': 0.7165879225999586,\n",
       "    'wmean': 0.7436435466721062}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.49831797558248253,\n",
       "    1.2792776975535832e-29),\n",
       "   'spearman': SpearmanrResult(correlation=0.4926043889193346, pvalue=6.948272302777438e-29),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.8110025260607239, 2.380008735032673e-71),\n",
       "   'spearman': SpearmanrResult(correlation=0.7784025416510902, pvalue=3.2806411805675245e-62),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7329794941714723, 2.726975432764373e-127),\n",
       "   'spearman': SpearmanrResult(correlation=0.7083285273142585, pvalue=2.9246656405827755e-115),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7772277704984392, 1.1963720155832323e-152),\n",
       "   'spearman': SpearmanrResult(correlation=0.7520869211811828, pvalue=1.3993776204836034e-137),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.8194292780522218, 5.661217058142552e-183),\n",
       "   'spearman': SpearmanrResult(correlation=0.8233160109197186, pvalue=3.656972868344196e-186),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7580125092137587, 5.774364069468944e-141),\n",
       "   'spearman': SpearmanrResult(correlation=0.693617134014335, pvalue=1.155885093917403e-108),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7000196305767966,\n",
       "    'mean': 0.7328282589298497,\n",
       "    'wmean': 0.7422081695419342},\n",
       "   'spearman': {'all': 0.6726454938423136,\n",
       "    'mean': 0.7080592539999867,\n",
       "    'wmean': 0.7168544486883064}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.7173434681197128,\n",
       "    1.6582532080464822e-60),\n",
       "   'spearman': SpearmanrResult(correlation=0.7142110057220189, pvalue=9.25415062761234e-60),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7474115712934761, 5.613920515876082e-135),\n",
       "   'spearman': SpearmanrResult(correlation=0.7473711672805158, pvalue=5.908993578060504e-135),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.7646068271362548, 3.723372015412307e-73),\n",
       "   'spearman': SpearmanrResult(correlation=0.7678182729123182, pvalue=4.015857954976702e-74),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7832781266505436, 1.4260279924234083e-156),\n",
       "   'spearman': SpearmanrResult(correlation=0.781320748444706, pvalue=2.7367543960174458e-155),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8425177008665632, 3.6954389140605657e-203),\n",
       "   'spearman': SpearmanrResult(correlation=0.8518734860030123, pvalue=2.7387336828358623e-212),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7603051391751539,\n",
       "    'mean': 0.77103153881331,\n",
       "    'wmean': 0.7785456366096417},\n",
       "   'spearman': {'all': 0.7632500735789172,\n",
       "    'mean': 0.7725189360725142,\n",
       "    'wmean': 0.7803950102613506}}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()\n",
    "\n",
    "results2 = evaluate_model()\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "model3 = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "\n",
    "training_args3 = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size= 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=2,\n",
    "    max_steps= 30000,\n",
    "    logging_steps=10000,\n",
    "    save_steps=10000\n",
    ")\n",
    "\n",
    "model3.train()\n",
    "\n",
    "trainer3 = Trainer(\n",
    "    model=model3,\n",
    "    args=training_args3,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 2:16:18, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-10000\n",
      "Configuration saved in output\\checkpoint-10000\\config.json\n",
      "Model weights saved in output\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-20000\n",
      "Configuration saved in output\\checkpoint-20000\\config.json\n",
      "Model weights saved in output\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-30000\n",
      "Configuration saved in output\\checkpoint-30000\\config.json\n",
      "Model weights saved in output\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-30000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/distilbert_cl'\n",
    "\n",
    "#train_result = trainer.train(model_path=model_path)\n",
    "train_result3 = trainer3.train()\n",
    "torch.save(model3, './batch256_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.5697409578579856\n",
      "STS13:  0.6769343320004665\n",
      "STS14:  0.6357083664225791\n",
      "STS15:  0.744575188106335\n",
      "STSB:  0.6320978112448171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7108974767715875, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.6957934629797473, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7092411378218643, 1.0445253840454627e-229),\n",
       "   'spearman': SpearmanrResult(correlation=0.7145470998781457, pvalue=1.0790202728598763e-234),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.6362564654216417, 2.357894834089188e-157),\n",
       "   'spearman': SpearmanrResult(correlation=0.6320978112448171, pvalue=1.0318637044184543e-154),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.694542147265105,\n",
       "    'mean': 0.6854650266716978,\n",
       "    'wmean': 0.6986797596788475},\n",
       "   'spearman': {'all': 0.692993221621729,\n",
       "    'mean': 0.68081279136757,\n",
       "    'wmean': 0.6888734527346301}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.5685692938261935, 1.922991733409069e-65),\n",
       "   'spearman': SpearmanrResult(correlation=0.5768180019887325, pvalue=9.865649661539039e-68),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.7231459307017963, 2.4625344140537457e-122),\n",
       "   'spearman': SpearmanrResult(correlation=0.7286285308858846, pvalue=4.5212690570561215e-125),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.4552691576823324, 7.245333920427569e-25),\n",
       "   'spearman': SpearmanrResult(correlation=0.5652776900635411, pvalue=4.102512606437534e-40),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7052620559338071, 7.496786418423562e-114),\n",
       "   'spearman': SpearmanrResult(correlation=0.6820584737385141, pvalue=9.392905669563112e-104),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.5305233033717558, 2.4040708126567676e-30),\n",
       "   'spearman': SpearmanrResult(correlation=0.5054581332408665, pvalue=2.897420355990552e-27),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.5730881336602889,\n",
       "    'mean': 0.5965539483031771,\n",
       "    'wmean': 0.6172394793332912},\n",
       "   'spearman': {'all': 0.5697409578579856,\n",
       "    'mean': 0.6116481659835078,\n",
       "    'wmean': 0.6279823069054438}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.4756524584171261, 4.624072307242327e-12),\n",
       "   'spearman': SpearmanrResult(correlation=0.5113077740400039, pvalue=5.556470480427763e-14),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7621181361889477, 2.283711136237502e-143),\n",
       "   'spearman': SpearmanrResult(correlation=0.7555961434929108, pvalue=1.4234421879289685e-139),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.6084402620525589, 4.166232111198533e-58),\n",
       "   'spearman': SpearmanrResult(correlation=0.6193585571805185, pvalue=1.0011027739565939e-60),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.6575950672170406,\n",
       "    'mean': 0.615403618886211,\n",
       "    'wmean': 0.6685479358626888},\n",
       "   'spearman': {'all': 0.6769343320004665,\n",
       "    'mean': 0.628754158237811,\n",
       "    'wmean': 0.67386295166101}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.49407384596966303,\n",
       "    4.510113001940756e-29),\n",
       "   'spearman': SpearmanrResult(correlation=0.49240417290292743, pvalue=7.368507905860281e-29),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7780622258261892, 4.009255437301985e-62),\n",
       "   'spearman': SpearmanrResult(correlation=0.7427848525503551, pvalue=7.446349832307482e-54),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7432213991850618, 1.0817147703149346e-132),\n",
       "   'spearman': SpearmanrResult(correlation=0.7196824151471459, pvalue=1.219101168718968e-120),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7054349774996785, 6.2505242558663144e-114),\n",
       "   'spearman': SpearmanrResult(correlation=0.7030675288710679, pvalue=7.44650639954171e-113),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7165954891406879, 3.758118604101963e-119),\n",
       "   'spearman': SpearmanrResult(correlation=0.7432297325332733, pvalue=1.070564915797356e-132),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7485302385446341, 1.3539932639329752e-135),\n",
       "   'spearman': SpearmanrResult(correlation=0.6983425494584553, pvalue=9.724897786576716e-111),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.6494945972063338,\n",
       "    'mean': 0.6976530293609858,\n",
       "    'wmean': 0.7042902604564671},\n",
       "   'spearman': {'all': 0.6357083664225791,\n",
       "    'mean': 0.6832518752438709,\n",
       "    'wmean': 0.6913757341543681}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.6607010288385147,\n",
       "    2.1493530919525173e-48),\n",
       "   'spearman': SpearmanrResult(correlation=0.6458298799190522, pvalue=1.2242984122795279e-45),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7441626662553017,\n",
       "    3.3477261803153333e-133),\n",
       "   'spearman': SpearmanrResult(correlation=0.7497939271081, pvalue=2.691221448723987e-136),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.6857797494730589, 2.045705688150149e-53),\n",
       "   'spearman': SpearmanrResult(correlation=0.6781616879833227, pvalue=7.745591607805545e-52),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7823121289240607, 6.152161449073835e-156),\n",
       "   'spearman': SpearmanrResult(correlation=0.7836294107948686, pvalue=8.364444785613939e-157),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7792083240587948, 6.414589359548605e-154),\n",
       "   'spearman': SpearmanrResult(correlation=0.7855348556994918, pvalue=4.550816591458857e-158),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7431130125811777,\n",
       "    'mean': 0.7304327795099461,\n",
       "    'wmean': 0.7447308770984861},\n",
       "   'spearman': {'all': 0.744575188106335,\n",
       "    'mean': 0.7285899523009671,\n",
       "    'wmean': 0.7452384943884118}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.eval()\n",
    "\n",
    "results3 = evaluate_model()\n",
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertCLModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_first_last', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        if self.training:\n",
    "            return self.cl_forward(self.distilbert, input_ids, attention_mask)\n",
    "        else:\n",
    "            return self.sent_emb(self.distilbert, input_ids, attention_mask)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None):\n",
    "        batch_size = input_ids.size(0)#64#input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "model4 = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "\n",
    "training_args4 = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size= 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=2,\n",
    "    max_steps= 30000,\n",
    "    logging_steps=10000,\n",
    "    save_steps=10000,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "model4.train()\n",
    "\n",
    "trainer4 = Trainer(\n",
    "    model=model4,\n",
    "    args=training_args4,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 2:20:12, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-10000\n",
      "Configuration saved in output\\checkpoint-10000\\config.json\n",
      "Model weights saved in output\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-20000\n",
      "Configuration saved in output\\checkpoint-20000\\config.json\n",
      "Model weights saved in output\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-30000\n",
      "Configuration saved in output\\checkpoint-30000\\config.json\n",
      "Model weights saved in output\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-30000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/distilbert_cl'\n",
    "\n",
    "#train_result = trainer.train(model_path=model_path)\n",
    "train_result4 = trainer4.train()\n",
    "torch.save(model4, './batch256_16bit_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import senteval\n",
    "#import SentEval.senteval as senteval\n",
    "#import SentEval_simcse.senteval as senteval\n",
    "#import SentEval_simcse.senteval.engine as se_engine\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [\" \".join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model4(**batch)\n",
    "\n",
    "    pooled_result = outputs.pooler_output.cpu()\n",
    "\n",
    "    return pooled_result\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    PATH_TO_DATA = \"./data\"\n",
    "\n",
    "    params = {\"task_path\": PATH_TO_DATA, \"usepytorch\": True, \"kfold\": 10}\n",
    "    tasks = [\"STSBenchmark\", 'STS12', 'STS13', 'STS14', 'STS15']\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    #se = se_engine.SE(params, batcher, prepare)\n",
    "    results = se.eval(tasks)\n",
    "\n",
    "    print('STS12: ', results[\"STS12\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS13: ', results[\"STS13\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS14: ', results[\"STS14\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS15: ', results[\"STS15\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STSB: ', results[\"STSBenchmark\"][\"test\"][\"spearman\"][0])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.6028650839372993\n",
      "STS13:  0.740729745204717\n",
      "STS14:  0.692465335997525\n",
      "STS15:  0.779843190057093\n",
      "STSB:  0.7226870749431175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7654012355643011, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7482016388305586, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7670311528467801, 5.261345910632041e-291),\n",
       "   'spearman': SpearmanrResult(correlation=0.7708464868002052, pvalue=1.119990676071557e-295),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7318742172557201, 1.2511244745112543e-231),\n",
       "   'spearman': SpearmanrResult(correlation=0.7226870749431175, pvalue=3.856394414212571e-223),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.7581791623069682,\n",
       "    'mean': 0.7547688685556003,\n",
       "    'wmean': 0.7603260289899136},\n",
       "   'spearman': {'all': 0.7518720772834617,\n",
       "    'mean': 0.7472450668579604,\n",
       "    'wmean': 0.7480605503226412}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.6638885051937329, 1.767074037152879e-96),\n",
       "   'spearman': SpearmanrResult(correlation=0.6412098115217912, pvalue=4.352737200439051e-88),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.7927758724538693, 5.40449629193965e-163),\n",
       "   'spearman': SpearmanrResult(correlation=0.7968791798219567, pvalue=7.134120069574861e-166),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.4883130499588775, 7.050370165247265e-29),\n",
       "   'spearman': SpearmanrResult(correlation=0.5617743042099863, pvalue=1.5484094953816606e-39),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7033376326266234, 5.619884938784154e-113),\n",
       "   'spearman': SpearmanrResult(correlation=0.6892578269390826, pvalue=8.745419703218659e-107),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6080656023385231, 1.0486671075968402e-41),\n",
       "   'spearman': SpearmanrResult(correlation=0.5443363044978058, pvalue=3.7156818879919706e-32),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.6248317529346296,\n",
       "    'mean': 0.6512761325143253,\n",
       "    'wmean': 0.6714142126672666},\n",
       "   'spearman': {'all': 0.6028650839372993,\n",
       "    'mean': 0.6466914853981246,\n",
       "    'wmean': 0.6662016424836329}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.5146130120631479, 3.5912269769391216e-14),\n",
       "   'spearman': SpearmanrResult(correlation=0.5541006568636835, pvalue=1.3296955257355115e-16),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.791466568163673, 4.343420463492872e-162),\n",
       "   'spearman': SpearmanrResult(correlation=0.7867191383722396, pvalue=7.340512667313412e-159),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.718557980499374, 3.1875352751854185e-90),\n",
       "   'spearman': SpearmanrResult(correlation=0.7196172523078505, pvalue=1.3179279906224866e-90),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.7300588889331164,\n",
       "    'mean': 0.6748791869087315,\n",
       "    'wmean': 0.7293152083085589},\n",
       "   'spearman': {'all': 0.740729745204717,\n",
       "    'mean': 0.6868123491812579,\n",
       "    'wmean': 0.7323131043140799}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.5482619939866078,\n",
       "    1.1340073971181462e-36),\n",
       "   'spearman': SpearmanrResult(correlation=0.5465012098040761, pvalue=2.1073801020387983e-36),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.8040898056033967, 2.866409535608092e-69),\n",
       "   'spearman': SpearmanrResult(correlation=0.7820627545980403, pvalue=3.7087254650744173e-63),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7720103540905534, 2.309219404096038e-149),\n",
       "   'spearman': SpearmanrResult(correlation=0.7484062908114091, pvalue=1.585670027031293e-135),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7894573369989675, 1.0331236218204271e-160),\n",
       "   'spearman': SpearmanrResult(correlation=0.7658776866620939, pvalue=1.3036430142850932e-145),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7827745917618757, 3.0583123984807816e-156),\n",
       "   'spearman': SpearmanrResult(correlation=0.7960594594391224, pvalue=2.7154627127692566e-165),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7839778031262034, 4.922939526615252e-157),\n",
       "   'spearman': SpearmanrResult(correlation=0.7282291668892134, pvalue=7.191616695300215e-125),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7165183287279627,\n",
       "    'mean': 0.7467619809279341,\n",
       "    'wmean': 0.7557626409221846},\n",
       "   'spearman': {'all': 0.692465335997525,\n",
       "    'mean': 0.7278560947006593,\n",
       "    'wmean': 0.7358596863047}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.7090791257127155,\n",
       "    1.4727280952748954e-58),\n",
       "   'spearman': SpearmanrResult(correlation=0.7072934280830891, pvalue=3.803429223181467e-58),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7434218437198311, 8.430054312425235e-133),\n",
       "   'spearman': SpearmanrResult(correlation=0.7452786342918362, pvalue=8.278240687049306e-134),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.767196130871143, 6.199544565738762e-74),\n",
       "   'spearman': SpearmanrResult(correlation=0.7719957694989369, pvalue=2.0991322486796266e-75),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.8187385387418046, 2.0499519323950233e-182),\n",
       "   'spearman': SpearmanrResult(correlation=0.8194708023401971, pvalue=5.238884421992033e-183),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8488625315593523, 2.7751885771480814e-209),\n",
       "   'spearman': SpearmanrResult(correlation=0.8526581459634256, pvalue=4.3980824199909614e-213),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7781699965647223,\n",
       "    'mean': 0.7774596341209694,\n",
       "    'wmean': 0.7872901355782294},\n",
       "   'spearman': {'all': 0.779843190057093,\n",
       "    'mean': 0.7793393560354971,\n",
       "    'wmean': 0.7892630453466182}}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.eval()\n",
    "\n",
    "results4 = evaluate_model()\n",
    "results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl-distilled",
   "language": "python",
   "name": "cl-distilled"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
