{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Learning From Scratch - DistilBERT\n",
    "\n",
    "An attempt to build contrastive learning model from scratch. Parts include:\n",
    "\n",
    "- Loading and preparing Wiki-1M data for model input\n",
    "- Contrastive learning model\n",
    "  - Forward passing using pre-trained model\n",
    "  - Constrastive layer\n",
    "  - Calculate loss\n",
    "- Training procedure\n",
    "  - Default trainer optimizer\n",
    "  - Default trainer hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set Project home\n",
    "PROJECT_HOME = os.path.join('/',\n",
    "                            'Users',\n",
    "                            'ng-ka',\n",
    "                            'OMSCS',\n",
    "                            'DL',\n",
    "                            'DLProject',\n",
    "                            'contrastive-learning-in-distilled-models')\n",
    "%cd {PROJECT_HOME}\n",
    "\n",
    "# Load project code\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "#import distilface\n",
    "import src.distilface as distilface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preparing Wiki-1M data\n",
    "\n",
    "Use huggingface `datasets` library to load local file data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration default-84caea1147087fa9\n",
      "Reusing dataset text (C:\\Users\\ng-ka\\.cache\\huggingface\\datasets\\text\\default-84caea1147087fa9\\0.0.0\\4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {'train': 'data/training/wiki1m_for_simcse.txt'}\n",
    "# data_files = {'train': 'data/training/wiki5k.txt'}\n",
    "datasets = load_dataset('text', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_names: ['text']\n",
      "sent0_cname: text | sent1_cname: text\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised / Self-supervised dataset\n",
    "\n",
    "column_names = datasets[\"train\"].column_names\n",
    "sent0_cname = column_names[0]\n",
    "sent1_cname = column_names[0]\n",
    "\n",
    "print('column_names:', column_names)\n",
    "print('sent0_cname:', sent0_cname, '| sent1_cname:', sent1_cname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(examples):\n",
    "    total = len(examples[sent0_cname])\n",
    "\n",
    "    # Avoid \"None\" fields \n",
    "    for idx in range(total):\n",
    "        if examples[sent0_cname][idx] is None:\n",
    "            examples[sent0_cname][idx] = \" \"\n",
    "        if examples[sent1_cname][idx] is None:\n",
    "            examples[sent1_cname][idx] = \" \"\n",
    "    \n",
    "    sentences = examples[sent0_cname] + examples[sent1_cname]\n",
    "\n",
    "    sent_features = tokenizer(\n",
    "        sentences,\n",
    "        max_length=32,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    features = {}\n",
    "    for key in sent_features:\n",
    "        features[key] = [[sent_features[key][i], sent_features[key][i+total]] for i in range(total)]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ng-ka\\.cache\\huggingface\\datasets\\text\\default-84caea1147087fa9\\0.0.0\\4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\\cache-1293cb42b0393e2c.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"].map(prepare_features,\n",
    "                                      batched=True,\n",
    "                                    #   num_proc=24,\n",
    "                                      remove_columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[101, 26866, 1999, 2148, 2660, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_dataset['input_ids'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[101, 26866, 1999, 2148, 2660, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_dataset['input_ids'][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attention_mask', 'input_ids'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence 1 and Sentence 2 are the same sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Contrastive Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel, DistilBertPreTrainedModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPooling\n",
    "\n",
    "from src.distilface.modules.pooler import Pooler\n",
    "from src.distilface.modules.similarity import Similarity\n",
    "\n",
    "class DistilBertCLModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_first_last', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        if self.training:\n",
    "            return self.cl_forward(self.distilbert, input_ids, attention_mask)\n",
    "        else:\n",
    "            return self.sent_emb(self.distilbert, input_ids, attention_mask)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None):\n",
    "        batch_size = input_ids.size(0)#64#input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "\n",
    "pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "#model = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "#model.eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initial DistilBERT embeddings performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senteval\n",
    "#import SentEval.senteval as senteval\n",
    "#import SentEval_simcse.senteval as senteval\n",
    "#import SentEval_simcse.senteval.engine as se_engine\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [\" \".join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model3(**batch)\n",
    "\n",
    "    pooled_result = outputs.pooler_output.cpu()\n",
    "\n",
    "    return pooled_result\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    PATH_TO_DATA = \"./data\"\n",
    "\n",
    "    params = {\"task_path\": PATH_TO_DATA, \"usepytorch\": True, \"kfold\": 10}\n",
    "    tasks = [\"STSBenchmark\", 'STS12', 'STS13', 'STS14', 'STS15']\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    #se = se_engine.SE(params, batcher, prepare)\n",
    "    results = se.eval(tasks)\n",
    "\n",
    "    print('STS12: ', results[\"STS12\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS13: ', results[\"STS13\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS14: ', results[\"STS14\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS15: ', results[\"STS15\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STSB: ', results[\"STSBenchmark\"][\"test\"][\"spearman\"][0])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.47596608898755144\n",
      "STS13:  0.618674507613396\n",
      "STS14:  0.5294342415078909\n",
      "STS15:  0.6969415778069489\n",
      "STSB:  0.5905314299135291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.607072923019217, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.5955188195020807, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.6714570536745258, 3.2552287443463876e-197),\n",
       "   'spearman': SpearmanrResult(correlation=0.6842681833563105, pvalue=1.122076247507796e-207),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.5632499403360769, 2.9511246107835275e-116),\n",
       "   'spearman': SpearmanrResult(correlation=0.5905314299135291, pvalue=2.169060496705334e-130),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.6130684398138361,\n",
       "    'mean': 0.6139266390099399,\n",
       "    'wmean': 0.6112621097209918},\n",
       "   'spearman': {'all': 0.6145998749710233,\n",
       "    'mean': 0.6234394775906401,\n",
       "    'wmean': 0.6101509979372606}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.42118590394249555, 1.3145639639932755e-33),\n",
       "   'spearman': SpearmanrResult(correlation=0.45991561737043646, pvalue=1.5821923016995031e-40),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.6352879593428346, 5.183287142463953e-86),\n",
       "   'spearman': SpearmanrResult(correlation=0.6401519760834063, pvalue=1.0302269231217165e-87),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.5022933949818664, 1.0349314233022616e-30),\n",
       "   'spearman': SpearmanrResult(correlation=0.5933517188464215, pvalue=5.388261366699939e-45),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.6877233214631762, 3.937747104046696e-106),\n",
       "   'spearman': SpearmanrResult(correlation=0.6910408351722502, pvalue=1.5043383888872297e-107),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6239686926226475, 1.936629867889363e-44),\n",
       "   'spearman': SpearmanrResult(correlation=0.55171310954646, pvalue=3.69868564914955e-33),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.45145305382748163,\n",
       "    'mean': 0.5740918544706041,\n",
       "    'wmean': 0.5751814881642513},\n",
       "   'spearman': {'all': 0.47596608898755144,\n",
       "    'mean': 0.5872346514037948,\n",
       "    'wmean': 0.5906735170943098}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.4721083831978025, 6.9827543985655566e-12),\n",
       "   'spearman': SpearmanrResult(correlation=0.5056664404698936, pvalue=1.1578223671604005e-13),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7104445114930775, 3.042310153878186e-116),\n",
       "   'spearman': SpearmanrResult(correlation=0.6922823812457632, pvalue=4.382855824474567e-108),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.5347802083410838, 8.09701529699335e-43),\n",
       "   'spearman': SpearmanrResult(correlation=0.5696084647773406, pvalue=1.4436226629736743e-49),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.6078202925938808,\n",
       "    'mean': 0.5724443676773213,\n",
       "    'wmean': 0.6147157099490271},\n",
       "   'spearman': {'all': 0.618674507613396,\n",
       "    'mean': 0.5891857621643325,\n",
       "    'wmean': 0.6228887279488137}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.3917755391727156,\n",
       "    5.8568246329610094e-18),\n",
       "   'spearman': SpearmanrResult(correlation=0.4072090543164891, pvalue=2.1076338923720368e-19),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7777888751111236, 4.708872222201854e-62),\n",
       "   'spearman': SpearmanrResult(correlation=0.7388030216217484, pvalue=5.251752312600481e-53),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.6712030793623832, 2.4054316831219454e-99),\n",
       "   'spearman': SpearmanrResult(correlation=0.6258466508423443, pvalue=8.546905534030859e-83),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.6677905891921765, 5.351525206116833e-98),\n",
       "   'spearman': SpearmanrResult(correlation=0.6484275025055973, pvalue=1.111432521900915e-90),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.6718954026358572, 1.2754177080826265e-99),\n",
       "   'spearman': SpearmanrResult(correlation=0.712151158241655, pvalue=4.830318594690074e-117),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.673753528437716, 2.3036170201828703e-100),\n",
       "   'spearman': SpearmanrResult(correlation=0.6339111659638288, pvalue=1.5514556778231942e-85),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.5359667255865653,\n",
       "    'mean': 0.6423678356519954,\n",
       "    'wmean': 0.6461646946352424},\n",
       "   'spearman': {'all': 0.5294342415078909,\n",
       "    'mean': 0.6277247589152771,\n",
       "    'wmean': 0.6320366237584036}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.6212710339076668,\n",
       "    2.0750726869911188e-41),\n",
       "   'spearman': SpearmanrResult(correlation=0.6092295308452247, pvalue=1.8060620383169866e-39),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7166850875969126, 3.4043557410727e-119),\n",
       "   'spearman': SpearmanrResult(correlation=0.7213544950173122, pvalue=1.8669199180594134e-121),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.6882026219663078, 6.290663012093747e-54),\n",
       "   'spearman': SpearmanrResult(correlation=0.7037745246672049, pvalue=2.416171437304839e-57),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7268860584257288, 3.4047667656413547e-124),\n",
       "   'spearman': SpearmanrResult(correlation=0.714097476476157, pvalue=5.825624158024163e-118),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7687635296327311, 2.3132115123040793e-147),\n",
       "   'spearman': SpearmanrResult(correlation=0.7762308473471929, pvalue=5.158601346804e-152),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.6851086541146186,\n",
       "    'mean': 0.7043616663058694,\n",
       "    'wmean': 0.71676787589809},\n",
       "   'spearman': {'all': 0.6969415778069489,\n",
       "    'mean': 0.7049373748706184,\n",
       "    'wmean': 0.7170462116492193}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate_model()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size= 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=2,\n",
    "    max_steps= 30000,\n",
    "    logging_steps=5000,\n",
    "    save_steps=5000\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ng-ka\\\\OMSCS\\\\DL\\\\DLProject\\\\contrastive-learning-in-distilled-models'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 1:01:23, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-10000\n",
      "Configuration saved in output\\checkpoint-10000\\config.json\n",
      "Model weights saved in output\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-20000\n",
      "Configuration saved in output\\checkpoint-20000\\config.json\n",
      "Model weights saved in output\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-30000\n",
      "Configuration saved in output\\checkpoint-30000\\config.json\n",
      "Model weights saved in output\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-30000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/distilbert_cl'\n",
    "\n",
    "#train_result = trainer.train(model_path=model_path)\n",
    "train_result = trainer.train()\n",
    "torch.save(model, './batch64_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate DistilBert CL Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.6090776121491925\n",
      "STS13:  0.7497469551546061\n",
      "STS14:  0.6757974078475796\n",
      "STS15:  0.765551098261831\n",
      "STSB:  0.7204600322058549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7471983353662978, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7262310424718174, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7549626323284834, 8.464706174718347e-277),\n",
       "   'spearman': SpearmanrResult(correlation=0.7611009444961765, pvalue=6.419079616838876e-284),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7278060625526783, 7.928917149564817e-228),\n",
       "   'spearman': SpearmanrResult(correlation=0.7204600322058549, pvalue=3.9122309068436553e-221),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.7436187470522633,\n",
       "    'mean': 0.7433223434158198,\n",
       "    'wmean': 0.7454487411652428},\n",
       "   'spearman': {'all': 0.7357581756301707,\n",
       "    'mean': 0.7359306730579496,\n",
       "    'wmean': 0.7313708929446705}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.6338161318073211, 1.6730762578990187e-85),\n",
       "   'spearman': SpearmanrResult(correlation=0.6244768196631411, pvalue=2.451473574472343e-82),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.7875987979312923, 1.8788512800058655e-159),\n",
       "   'spearman': SpearmanrResult(correlation=0.7871113736642561, pvalue=4.001090788120364e-159),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.48386561118869736, 2.593795280357608e-28),\n",
       "   'spearman': SpearmanrResult(correlation=0.6040916605281718, pvalue=5.42319895211683e-47),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7317453892410892, 1.173992163240154e-126),\n",
       "   'spearman': SpearmanrResult(correlation=0.7086411769080869, pvalue=2.0960780237654807e-115),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.657018316415632, 1.1776667323974416e-50),\n",
       "   'spearman': SpearmanrResult(correlation=0.5643545350221444, pvalue=6.192906785264644e-35),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.6212969578202144,\n",
       "    'mean': 0.6588088493168064,\n",
       "    'wmean': 0.6753908825676403},\n",
       "   'spearman': {'all': 0.6090776121491925,\n",
       "    'mean': 0.65773511315716,\n",
       "    'wmean': 0.6733035905189444}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.5418508415961674, 8.171459420598265e-16),\n",
       "   'spearman': SpearmanrResult(correlation=0.5803775823717117, pvalue=2.083253482448148e-18),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7728812848854208, 6.624087448678468e-150),\n",
       "   'spearman': SpearmanrResult(correlation=0.7695800695413578, pvalue=7.313909684207754e-148),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7516914706971368, 3.9625304390142925e-103),\n",
       "   'spearman': SpearmanrResult(correlation=0.7558049255080654, pvalue=7.122461148065755e-105),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.7379456053919177,\n",
       "    'mean': 0.6888078657262416,\n",
       "    'wmean': 0.7358464585245568},\n",
       "   'spearman': {'all': 0.7497469551546061,\n",
       "    'mean': 0.7019208591403784,\n",
       "    'wmean': 0.7405886522895311}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.551311291909704,\n",
       "    3.8437572748166215e-37),\n",
       "   'spearman': SpearmanrResult(correlation=0.5376401035035576, pvalue=4.510579742306458e-35),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7931896252560788, 3.756848628959481e-66),\n",
       "   'spearman': SpearmanrResult(correlation=0.7638315777845631, pvalue=1.295999204416333e-58),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7559932443756179, 8.42806107624951e-140),\n",
       "   'spearman': SpearmanrResult(correlation=0.7291953001282143, pvalue=2.3365924179291146e-125),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7667359914460894, 3.9540804770012603e-146),\n",
       "   'spearman': SpearmanrResult(correlation=0.7289963780287285, pvalue=2.9463377695535245e-125),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.8011792987256044, 5.804020692352355e-169),\n",
       "   'spearman': SpearmanrResult(correlation=0.8076918300860307, pvalue=8.649023591318222e-174),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7535964679177174, 1.9629571645072004e-138),\n",
       "   'spearman': SpearmanrResult(correlation=0.6923529560516289, pvalue=4.085359100753345e-108),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7072399716538912,\n",
       "    'mean': 0.7370009866051355,\n",
       "    'wmean': 0.7451135255426566},\n",
       "   'spearman': {'all': 0.6757974078475796,\n",
       "    'mean': 0.7099513575971206,\n",
       "    'wmean': 0.7172706315021126}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.6858993099282084,\n",
       "    1.9305801300219585e-53),\n",
       "   'spearman': SpearmanrResult(correlation=0.6882650424555431, pvalue=6.101484919047114e-54),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7291820645724134, 2.372935500464418e-125),\n",
       "   'spearman': SpearmanrResult(correlation=0.7289770781545857, pvalue=3.0133380961366864e-125),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.768584092168063, 2.3487335234225875e-74),\n",
       "   'spearman': SpearmanrResult(correlation=0.7872500602765331, pvalue=2.5071947705296647e-80),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7998635080408133, 5.213537903255184e-168),\n",
       "   'spearman': SpearmanrResult(correlation=0.8025328240287718, pvalue=5.963074373877233e-170),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.825800292967215, 3.0405944618554096e-188),\n",
       "   'spearman': SpearmanrResult(correlation=0.8345721867615303, pvalue=7.323777815555841e-196),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7621063087954598,\n",
       "    'mean': 0.7618658535353426,\n",
       "    'wmean': 0.7705218916571444},\n",
       "   'spearman': {'all': 0.765551098261831,\n",
       "    'mean': 0.7683194383353928,\n",
       "    'wmean': 0.7759599100777315}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "results = evaluate_model()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 128 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\ng-ka/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertCLModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertCLModel for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "model2 = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "\n",
    "training_args2 = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size= 128,\n",
    "    per_device_eval_batch_size = 128,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=2,\n",
    "    max_steps= 30000,\n",
    "    logging_steps=10000,\n",
    "    save_steps=10000\n",
    ")\n",
    "\n",
    "model2.train()\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model=model2,\n",
    "    args=training_args2,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 1:50:09, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-10000\n",
      "Configuration saved in output\\checkpoint-10000\\config.json\n",
      "Model weights saved in output\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-20000\n",
      "Configuration saved in output\\checkpoint-20000\\config.json\n",
      "Model weights saved in output\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-30000\n",
      "Configuration saved in output\\checkpoint-30000\\config.json\n",
      "Model weights saved in output\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-30000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/distilbert_cl'\n",
    "\n",
    "#train_result = trainer.train(model_path=model_path)\n",
    "train_result2 = trainer2.train()\n",
    "torch.save(model2, './batch128_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.6065243466186726\n",
      "STS13:  0.756455395306513\n",
      "STS14:  0.6951194522633876\n",
      "STS15:  0.7856655374420445\n",
      "STSB:  0.7158024372787648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7717160236711569, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7483613114635259, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7803909383217282, 8.988180520442471e-308),\n",
       "   'spearman': SpearmanrResult(correlation=0.7817877772593304, pvalue=1.35640744613233e-309),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7279218768179069, 6.193484465679416e-228),\n",
       "   'spearman': SpearmanrResult(correlation=0.7158024372787648, pvalue=5.3166095979870885e-217),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.7647390756619414,\n",
       "    'mean': 0.7600096129369307,\n",
       "    'wmean': 0.7662246286161297},\n",
       "   'spearman': {'all': 0.7523686653759916,\n",
       "    'mean': 0.7486505086672071,\n",
       "    'wmean': 0.7489687536509297}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.6642231149913949, 1.3119492325269426e-96),\n",
       "   'spearman': SpearmanrResult(correlation=0.6501533351583848, pvalue=2.6025783691238555e-91),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.8086377246714406, 1.661663135486939e-174),\n",
       "   'spearman': SpearmanrResult(correlation=0.7960220303946224, pvalue=2.8859344440213133e-165),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.5158220681523407, 1.4402319226959707e-32),\n",
       "   'spearman': SpearmanrResult(correlation=0.6042606511269596, pvalue=5.0375818855077015e-47),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.696847726140946, 4.4532707020516045e-110),\n",
       "   'spearman': SpearmanrResult(correlation=0.678869670838663, pvalue=1.9388763216307305e-102),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6066361926625587, 1.8147399674376796e-41),\n",
       "   'spearman': SpearmanrResult(correlation=0.5636532108573371, pvalue=7.806188575259098e-35),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.6553457479706091,\n",
       "    'mean': 0.6584333653237362,\n",
       "    'wmean': 0.6776356481683146},\n",
       "   'spearman': {'all': 0.6065243466186726,\n",
       "    'mean': 0.6585917796751934,\n",
       "    'wmean': 0.6744005943671507}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.49879497072747436, 2.780821904104767e-13),\n",
       "   'spearman': SpearmanrResult(correlation=0.5274602341831025, pvalue=6.290003963608147e-15),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.780641092453991, 7.579934521610022e-155),\n",
       "   'spearman': SpearmanrResult(correlation=0.7762838528644348, pvalue=4.773863842258445e-152),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.756711481304888, 2.9060143206925207e-105),\n",
       "   'spearman': SpearmanrResult(correlation=0.7530197943618082, pvalue=1.0917694899670594e-103),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.7467848510072344,\n",
       "    'mean': 0.6787158481621178,\n",
       "    'wmean': 0.7361788065466853},\n",
       "   'spearman': {'all': 0.756455395306513,\n",
       "    'mean': 0.6855879604697819,\n",
       "    'wmean': 0.7362313190306047}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.5441362946351503,\n",
       "    4.8162715004883176e-36),\n",
       "   'spearman': SpearmanrResult(correlation=0.5373602756254423, pvalue=4.961447808358e-35),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7854068857654951, 4.876110043733801e-64),\n",
       "   'spearman': SpearmanrResult(correlation=0.760948144599538, pvalue=6.217711745714958e-58),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7657390098737552, 1.5800167908235663e-145),\n",
       "   'spearman': SpearmanrResult(correlation=0.7453722586587497, pvalue=7.360123360221608e-134),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7662753140294599, 7.506010362116439e-146),\n",
       "   'spearman': SpearmanrResult(correlation=0.7448370422613615, pvalue=1.4402386713611206e-133),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.8075265982044326, 1.1526715144187195e-173),\n",
       "   'spearman': SpearmanrResult(correlation=0.808633395141126, pvalue=1.6742923707984796e-174),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.767932837087493, 7.427372526866851e-147),\n",
       "   'spearman': SpearmanrResult(correlation=0.7248746999437226, pvalue=3.434014786365513e-123),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7191618101878587,\n",
       "    'mean': 0.7395028232659643,\n",
       "    'wmean': 0.7496236580564858},\n",
       "   'spearman': {'all': 0.6951194522633876,\n",
       "    'mean': 0.7203376360383232,\n",
       "    'wmean': 0.730102563844008}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.70200009594983,\n",
       "    6.074945083329526e-57),\n",
       "   'spearman': SpearmanrResult(correlation=0.6995944307273575, pvalue=2.0974175396282986e-56),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7541610043240171, 9.382235758417656e-139),\n",
       "   'spearman': SpearmanrResult(correlation=0.7562269059345607, pvalue=6.188589334586931e-140),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.781376146888132, 2.196424467621526e-78),\n",
       "   'spearman': SpearmanrResult(correlation=0.7865699814313143, pvalue=4.2387084702605796e-80),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.8062913944901298, 9.780861154746547e-173),\n",
       "   'spearman': SpearmanrResult(correlation=0.8082050713489592, pvalue=3.537787814798335e-174),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8450238513559805, 1.5189553494228163e-205),\n",
       "   'spearman': SpearmanrResult(correlation=0.8498143802411343, pvalue=3.163948707245924e-210),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7845774674796814,\n",
       "    'mean': 0.7777704986016178,\n",
       "    'wmean': 0.7867910928972771},\n",
       "   'spearman': {'all': 0.7856655374420445,\n",
       "    'mean': 0.7800821539366651,\n",
       "    'wmean': 0.7893321409009976}}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()\n",
    "\n",
    "results2 = evaluate_model()\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256 batch size no grad scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel, DistilBertPreTrainedModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPooling\n",
    "\n",
    "from src.distilface.modules.pooler import Pooler\n",
    "from src.distilface.modules.similarity import Similarity\n",
    "\n",
    "from torch.cuda.amp import autocast \n",
    "\n",
    "#scaler = GradScaler()\n",
    "\n",
    "class DistilBertCLModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_first_last', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        with autocast():\n",
    "            if self.training:\n",
    "                return self.cl_forward(self.distilbert, input_ids, attention_mask)\n",
    "            else:\n",
    "                return self.sent_emb(self.distilbert, input_ids, attention_mask)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None):\n",
    "        batch_size = input_ids.size(0)#64#input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "\n",
    "pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "#model = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "#model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "model3 = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "\n",
    "training_args3 = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size= 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=2,\n",
    "    max_steps= 30000,\n",
    "    logging_steps=10000,\n",
    "    save_steps=10000\n",
    ")\n",
    "\n",
    "model3.train()\n",
    "\n",
    "trainer3 = Trainer(\n",
    "    model=model3,\n",
    "    args=training_args3,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 2:16:18, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-10000\n",
      "Configuration saved in output\\checkpoint-10000\\config.json\n",
      "Model weights saved in output\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-20000\n",
      "Configuration saved in output\\checkpoint-20000\\config.json\n",
      "Model weights saved in output\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-30000\n",
      "Configuration saved in output\\checkpoint-30000\\config.json\n",
      "Model weights saved in output\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-30000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/distilbert_cl'\n",
    "\n",
    "#train_result = trainer.train(model_path=model_path)\n",
    "train_result3 = trainer3.train()\n",
    "torch.save(model3, './batch256_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.5697409578579856\n",
      "STS13:  0.6769343320004665\n",
      "STS14:  0.6357083664225791\n",
      "STS15:  0.744575188106335\n",
      "STSB:  0.6320978112448171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7108974767715875, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.6957934629797473, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7092411378218643, 1.0445253840454627e-229),\n",
       "   'spearman': SpearmanrResult(correlation=0.7145470998781457, pvalue=1.0790202728598763e-234),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.6362564654216417, 2.357894834089188e-157),\n",
       "   'spearman': SpearmanrResult(correlation=0.6320978112448171, pvalue=1.0318637044184543e-154),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.694542147265105,\n",
       "    'mean': 0.6854650266716978,\n",
       "    'wmean': 0.6986797596788475},\n",
       "   'spearman': {'all': 0.692993221621729,\n",
       "    'mean': 0.68081279136757,\n",
       "    'wmean': 0.6888734527346301}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.5685692938261935, 1.922991733409069e-65),\n",
       "   'spearman': SpearmanrResult(correlation=0.5768180019887325, pvalue=9.865649661539039e-68),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.7231459307017963, 2.4625344140537457e-122),\n",
       "   'spearman': SpearmanrResult(correlation=0.7286285308858846, pvalue=4.5212690570561215e-125),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.4552691576823324, 7.245333920427569e-25),\n",
       "   'spearman': SpearmanrResult(correlation=0.5652776900635411, pvalue=4.102512606437534e-40),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7052620559338071, 7.496786418423562e-114),\n",
       "   'spearman': SpearmanrResult(correlation=0.6820584737385141, pvalue=9.392905669563112e-104),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.5305233033717558, 2.4040708126567676e-30),\n",
       "   'spearman': SpearmanrResult(correlation=0.5054581332408665, pvalue=2.897420355990552e-27),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.5730881336602889,\n",
       "    'mean': 0.5965539483031771,\n",
       "    'wmean': 0.6172394793332912},\n",
       "   'spearman': {'all': 0.5697409578579856,\n",
       "    'mean': 0.6116481659835078,\n",
       "    'wmean': 0.6279823069054438}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.4756524584171261, 4.624072307242327e-12),\n",
       "   'spearman': SpearmanrResult(correlation=0.5113077740400039, pvalue=5.556470480427763e-14),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7621181361889477, 2.283711136237502e-143),\n",
       "   'spearman': SpearmanrResult(correlation=0.7555961434929108, pvalue=1.4234421879289685e-139),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.6084402620525589, 4.166232111198533e-58),\n",
       "   'spearman': SpearmanrResult(correlation=0.6193585571805185, pvalue=1.0011027739565939e-60),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.6575950672170406,\n",
       "    'mean': 0.615403618886211,\n",
       "    'wmean': 0.6685479358626888},\n",
       "   'spearman': {'all': 0.6769343320004665,\n",
       "    'mean': 0.628754158237811,\n",
       "    'wmean': 0.67386295166101}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.49407384596966303,\n",
       "    4.510113001940756e-29),\n",
       "   'spearman': SpearmanrResult(correlation=0.49240417290292743, pvalue=7.368507905860281e-29),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7780622258261892, 4.009255437301985e-62),\n",
       "   'spearman': SpearmanrResult(correlation=0.7427848525503551, pvalue=7.446349832307482e-54),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7432213991850618, 1.0817147703149346e-132),\n",
       "   'spearman': SpearmanrResult(correlation=0.7196824151471459, pvalue=1.219101168718968e-120),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7054349774996785, 6.2505242558663144e-114),\n",
       "   'spearman': SpearmanrResult(correlation=0.7030675288710679, pvalue=7.44650639954171e-113),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7165954891406879, 3.758118604101963e-119),\n",
       "   'spearman': SpearmanrResult(correlation=0.7432297325332733, pvalue=1.070564915797356e-132),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7485302385446341, 1.3539932639329752e-135),\n",
       "   'spearman': SpearmanrResult(correlation=0.6983425494584553, pvalue=9.724897786576716e-111),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.6494945972063338,\n",
       "    'mean': 0.6976530293609858,\n",
       "    'wmean': 0.7042902604564671},\n",
       "   'spearman': {'all': 0.6357083664225791,\n",
       "    'mean': 0.6832518752438709,\n",
       "    'wmean': 0.6913757341543681}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.6607010288385147,\n",
       "    2.1493530919525173e-48),\n",
       "   'spearman': SpearmanrResult(correlation=0.6458298799190522, pvalue=1.2242984122795279e-45),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7441626662553017,\n",
       "    3.3477261803153333e-133),\n",
       "   'spearman': SpearmanrResult(correlation=0.7497939271081, pvalue=2.691221448723987e-136),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.6857797494730589, 2.045705688150149e-53),\n",
       "   'spearman': SpearmanrResult(correlation=0.6781616879833227, pvalue=7.745591607805545e-52),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7823121289240607, 6.152161449073835e-156),\n",
       "   'spearman': SpearmanrResult(correlation=0.7836294107948686, pvalue=8.364444785613939e-157),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7792083240587948, 6.414589359548605e-154),\n",
       "   'spearman': SpearmanrResult(correlation=0.7855348556994918, pvalue=4.550816591458857e-158),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7431130125811777,\n",
       "    'mean': 0.7304327795099461,\n",
       "    'wmean': 0.7447308770984861},\n",
       "   'spearman': {'all': 0.744575188106335,\n",
       "    'mean': 0.7285899523009671,\n",
       "    'wmean': 0.7452384943884118}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.eval()\n",
    "\n",
    "results3 = evaluate_model()\n",
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256 batch size with grad scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertCLModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_first_last', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        if self.training:\n",
    "            return self.cl_forward(self.distilbert, input_ids, attention_mask)\n",
    "        else:\n",
    "            return self.sent_emb(self.distilbert, input_ids, attention_mask)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None):\n",
    "        batch_size = input_ids.size(0)#64#input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "model4 = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "\n",
    "training_args4 = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size= 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=2,\n",
    "    max_steps= 30000,\n",
    "    logging_steps=10000,\n",
    "    save_steps=10000,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "model4.train()\n",
    "\n",
    "trainer4 = Trainer(\n",
    "    model=model4,\n",
    "    args=training_args4,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\anaconda3\\envs\\cl-distilled\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 2:20:12, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-10000\n",
      "Configuration saved in output\\checkpoint-10000\\config.json\n",
      "Model weights saved in output\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-20000\n",
      "Configuration saved in output\\checkpoint-20000\\config.json\n",
      "Model weights saved in output\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to output\\checkpoint-30000\n",
      "Configuration saved in output\\checkpoint-30000\\config.json\n",
      "Model weights saved in output\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-30000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/distilbert_cl'\n",
    "\n",
    "#train_result = trainer.train(model_path=model_path)\n",
    "train_result4 = trainer4.train()\n",
    "torch.save(model4, './batch256_16bit_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import senteval\n",
    "#import SentEval.senteval as senteval\n",
    "#import SentEval_simcse.senteval as senteval\n",
    "#import SentEval_simcse.senteval.engine as se_engine\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [\" \".join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model4(**batch)\n",
    "\n",
    "    pooled_result = outputs.pooler_output.cpu()\n",
    "\n",
    "    return pooled_result\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    PATH_TO_DATA = \"./data\"\n",
    "\n",
    "    params = {\"task_path\": PATH_TO_DATA, \"usepytorch\": True, \"kfold\": 10}\n",
    "    tasks = [\"STSBenchmark\", 'STS12', 'STS13', 'STS14', 'STS15']\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    #se = se_engine.SE(params, batcher, prepare)\n",
    "    results = se.eval(tasks)\n",
    "\n",
    "    print('STS12: ', results[\"STS12\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS13: ', results[\"STS13\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS14: ', results[\"STS14\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS15: ', results[\"STS15\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STSB: ', results[\"STSBenchmark\"][\"test\"][\"spearman\"][0])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\Users\\ng-ka\\OMSCS\\DL\\DLProject\\contrastive-learning-in-distilled-models\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.6028650839372993\n",
      "STS13:  0.740729745204717\n",
      "STS14:  0.692465335997525\n",
      "STS15:  0.779843190057093\n",
      "STSB:  0.7226870749431175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7654012355643011, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7482016388305586, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7670311528467801, 5.261345910632041e-291),\n",
       "   'spearman': SpearmanrResult(correlation=0.7708464868002052, pvalue=1.119990676071557e-295),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7318742172557201, 1.2511244745112543e-231),\n",
       "   'spearman': SpearmanrResult(correlation=0.7226870749431175, pvalue=3.856394414212571e-223),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.7581791623069682,\n",
       "    'mean': 0.7547688685556003,\n",
       "    'wmean': 0.7603260289899136},\n",
       "   'spearman': {'all': 0.7518720772834617,\n",
       "    'mean': 0.7472450668579604,\n",
       "    'wmean': 0.7480605503226412}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.6638885051937329, 1.767074037152879e-96),\n",
       "   'spearman': SpearmanrResult(correlation=0.6412098115217912, pvalue=4.352737200439051e-88),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.7927758724538693, 5.40449629193965e-163),\n",
       "   'spearman': SpearmanrResult(correlation=0.7968791798219567, pvalue=7.134120069574861e-166),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.4883130499588775, 7.050370165247265e-29),\n",
       "   'spearman': SpearmanrResult(correlation=0.5617743042099863, pvalue=1.5484094953816606e-39),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7033376326266234, 5.619884938784154e-113),\n",
       "   'spearman': SpearmanrResult(correlation=0.6892578269390826, pvalue=8.745419703218659e-107),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6080656023385231, 1.0486671075968402e-41),\n",
       "   'spearman': SpearmanrResult(correlation=0.5443363044978058, pvalue=3.7156818879919706e-32),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.6248317529346296,\n",
       "    'mean': 0.6512761325143253,\n",
       "    'wmean': 0.6714142126672666},\n",
       "   'spearman': {'all': 0.6028650839372993,\n",
       "    'mean': 0.6466914853981246,\n",
       "    'wmean': 0.6662016424836329}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.5146130120631479, 3.5912269769391216e-14),\n",
       "   'spearman': SpearmanrResult(correlation=0.5541006568636835, pvalue=1.3296955257355115e-16),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.791466568163673, 4.343420463492872e-162),\n",
       "   'spearman': SpearmanrResult(correlation=0.7867191383722396, pvalue=7.340512667313412e-159),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.718557980499374, 3.1875352751854185e-90),\n",
       "   'spearman': SpearmanrResult(correlation=0.7196172523078505, pvalue=1.3179279906224866e-90),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.7300588889331164,\n",
       "    'mean': 0.6748791869087315,\n",
       "    'wmean': 0.7293152083085589},\n",
       "   'spearman': {'all': 0.740729745204717,\n",
       "    'mean': 0.6868123491812579,\n",
       "    'wmean': 0.7323131043140799}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.5482619939866078,\n",
       "    1.1340073971181462e-36),\n",
       "   'spearman': SpearmanrResult(correlation=0.5465012098040761, pvalue=2.1073801020387983e-36),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.8040898056033967, 2.866409535608092e-69),\n",
       "   'spearman': SpearmanrResult(correlation=0.7820627545980403, pvalue=3.7087254650744173e-63),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7720103540905534, 2.309219404096038e-149),\n",
       "   'spearman': SpearmanrResult(correlation=0.7484062908114091, pvalue=1.585670027031293e-135),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7894573369989675, 1.0331236218204271e-160),\n",
       "   'spearman': SpearmanrResult(correlation=0.7658776866620939, pvalue=1.3036430142850932e-145),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7827745917618757, 3.0583123984807816e-156),\n",
       "   'spearman': SpearmanrResult(correlation=0.7960594594391224, pvalue=2.7154627127692566e-165),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7839778031262034, 4.922939526615252e-157),\n",
       "   'spearman': SpearmanrResult(correlation=0.7282291668892134, pvalue=7.191616695300215e-125),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7165183287279627,\n",
       "    'mean': 0.7467619809279341,\n",
       "    'wmean': 0.7557626409221846},\n",
       "   'spearman': {'all': 0.692465335997525,\n",
       "    'mean': 0.7278560947006593,\n",
       "    'wmean': 0.7358596863047}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.7090791257127155,\n",
       "    1.4727280952748954e-58),\n",
       "   'spearman': SpearmanrResult(correlation=0.7072934280830891, pvalue=3.803429223181467e-58),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7434218437198311, 8.430054312425235e-133),\n",
       "   'spearman': SpearmanrResult(correlation=0.7452786342918362, pvalue=8.278240687049306e-134),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.767196130871143, 6.199544565738762e-74),\n",
       "   'spearman': SpearmanrResult(correlation=0.7719957694989369, pvalue=2.0991322486796266e-75),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.8187385387418046, 2.0499519323950233e-182),\n",
       "   'spearman': SpearmanrResult(correlation=0.8194708023401971, pvalue=5.238884421992033e-183),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8488625315593523, 2.7751885771480814e-209),\n",
       "   'spearman': SpearmanrResult(correlation=0.8526581459634256, pvalue=4.3980824199909614e-213),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7781699965647223,\n",
       "    'mean': 0.7774596341209694,\n",
       "    'wmean': 0.7872901355782294},\n",
       "   'spearman': {'all': 0.779843190057093,\n",
       "    'mean': 0.7793393560354971,\n",
       "    'wmean': 0.7892630453466182}}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.eval()\n",
    "\n",
    "results4 = evaluate_model()\n",
    "results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl-distilled",
   "language": "python",
   "name": "cl-distilled"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
