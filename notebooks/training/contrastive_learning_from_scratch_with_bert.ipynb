{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Contrastive Learning From Scratch\n",
    "\n",
    "An attempt to build contrastive learning model from scratch. Parts include:\n",
    "\n",
    "- Loading and preparing Wiki-1M data for model input\n",
    "- Contrastive learning model\n",
    "  - Forward passing using pre-trained model\n",
    "  - Constrastive layer\n",
    "  - Calculate loss\n",
    "- Training procedure\n",
    "  - Default trainer optimizer\n",
    "  - Default trainer hyper-parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/workspace/gatech/cs7643-deep-learning/contrastive-learning-in-distilled-models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set Project home\n",
    "PROJECT_HOME = os.path.join('/',\n",
    "                            'workspace',\n",
    "                            'gatech',\n",
    "                            'cs7643-deep-learning',\n",
    "                            'contrastive-learning-in-distilled-models')\n",
    "%cd {PROJECT_HOME}\n",
    "\n",
    "# Load project code\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "import distilface"
   ]
  },
  {
   "source": [
    "## 1. Loading and Preparing Wiki-1M data\n",
    "\n",
    "Use huggingface `datasets` library to load local file data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset text (./data/text/default-c7a268390f38dfb5/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {'train': 'data/training/wiki1m_for_simcse.txt'}\n",
    "# data_files = {'train': 'data/training/wiki5k.txt'}\n",
    "datasets = load_dataset('text', data_files=data_files, cache_dir='./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "column_names: ['text']\nsent0_cname: text | sent1_cname: text\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised / Self-supervised dataset\n",
    "\n",
    "column_names = datasets[\"train\"].column_names\n",
    "sent0_cname = column_names[0]\n",
    "sent1_cname = column_names[0]\n",
    "\n",
    "print('column_names:', column_names)\n",
    "print('sent0_cname:', sent0_cname, '| sent1_cname:', sent1_cname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(examples):\n",
    "    total = len(examples[sent0_cname])\n",
    "\n",
    "    # Avoid \"None\" fields \n",
    "    for idx in range(total):\n",
    "        if examples[sent0_cname][idx] is None:\n",
    "            examples[sent0_cname][idx] = \" \"\n",
    "        if examples[sent1_cname][idx] is None:\n",
    "            examples[sent1_cname][idx] = \" \"\n",
    "    \n",
    "    sentences = examples[sent0_cname] + examples[sent1_cname]\n",
    "\n",
    "    sent_features = tokenizer(\n",
    "        sentences,\n",
    "        max_length=32,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    features = {}\n",
    "    for key in sent_features:\n",
    "        features[key] = [[sent_features[key][i], sent_features[key][i+total]] for i in range(total)]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "217e7525773f4d71ada05cded4416663"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"].map(prepare_features,\n",
    "                                      batched=True,\n",
    "                                    #   num_proc=24,\n",
    "                                      remove_columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[101, 26866, 1999, 2148, 2660, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "str(train_dataset['input_ids'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[101, 26866, 1999, 2148, 2660, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "str(train_dataset['input_ids'][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['attention_mask', 'input_ids', 'token_type_ids'])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_dataset.features.keys()"
   ]
  },
  {
   "source": [
    "Sentence 1 and Sentence 2 are the same sentence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Contrastive Learning Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertCLModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n- This IS expected if you are initializing BertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, BertModel, BertPreTrainedModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPooling\n",
    "\n",
    "from distilface.modules.pooler import Pooler\n",
    "from distilface.modules.similarity import Similarity\n",
    "\n",
    "\n",
    "class BertCLModel(BertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_first_last', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        if self.training:\n",
    "            return self.cl_forward(self.bert, input_ids, attention_mask, token_type_ids)\n",
    "        else:\n",
    "            return self.sent_emb(self.bert, input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        batch_size = input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "        token_type_ids = token_type_ids.view((-1, token_type_ids.size(-1))) # (bs * num_sent, len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "\n",
    "pretrained_model_name = 'bert-base-uncased'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model = BertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model.eval();\n"
   ]
  },
  {
   "source": [
    "### 2.1 Initial BERT embeddings performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senteval\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [\" \".join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    pooled_result = outputs.pooler_output.cpu()\n",
    "\n",
    "    return pooled_result\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    PATH_TO_DATA = \"./data\"\n",
    "\n",
    "    params = {\"task_path\": PATH_TO_DATA, \"usepytorch\": True, \"kfold\": 10}\n",
    "    tasks = [\"STSBenchmark\", 'STS12', 'STS13', 'STS14', 'STS15']\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    results = se.eval(tasks)\n",
    "\n",
    "    print('STS12: ', results[\"STS12\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS13: ', results[\"STS13\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS14: ', results[\"STS14\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS15: ', results[\"STS15\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STSB: ', results[\"STSBenchmark\"][\"test\"][\"spearman\"][0])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "/opt/conda/lib/python3.8/site-packages/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
      "STS12:  0.3969643234774765\n",
      "STS13:  0.5936622050356901\n",
      "STS14:  0.49683700844088435\n",
      "STS15:  0.6602504226080194\n",
      "STSB:  0.5386682573723041\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.5619505330308854, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.5384285918923115, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.6321576404364262, 3.5670578268133463e-168),\n",
       "   'spearman': SpearmanrResult(correlation=0.6371150398903414, pvalue=1.3235747770641853e-171),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.5327127002648916, 6.359296565156033e-102),\n",
       "   'spearman': SpearmanrResult(correlation=0.5386682573723041, pvalue=1.3268371385626441e-104),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.5731794732386623,\n",
       "    'mean': 0.5756069579107344,\n",
       "    'wmean': 0.5694831813530928},\n",
       "   'spearman': {'all': 0.5613396961884458,\n",
       "    'mean': 0.5714039630516523,\n",
       "    'wmean': 0.5556237901646753}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.3866872288356371, 3.692213051577658e-28),\n",
       "   'spearman': SpearmanrResult(correlation=0.4283996492577101, pvalue=7.885817678833689e-35),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.5048173209527392, 9.577310409064362e-50),\n",
       "   'spearman': SpearmanrResult(correlation=0.519014346408191, pvalue=5.883875743507445e-53),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.4941972266150361, 1.221463313369415e-29),\n",
       "   'spearman': SpearmanrResult(correlation=0.5844763779528267, pvalue=2.1192992395185165e-43),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.6564660343383546, 1.1852229627457213e-93),\n",
       "   'spearman': SpearmanrResult(correlation=0.6646035186309082, pvalue=9.347052895583248e-97),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.580888371455256, 2.2408030448819582e-37),\n",
       "   'spearman': SpearmanrResult(correlation=0.5389059294269581, pvalue=1.9586549045431672e-31),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.36636318012189345,\n",
       "    'mean': 0.5246112364394045,\n",
       "    'wmean': 0.5211032578256104},\n",
       "   'spearman': {'all': 0.3969643234774765,\n",
       "    'mean': 0.5470799643353188,\n",
       "    'wmean': 0.5445016920991991}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.43324300645854386, 4.761943854203513e-10),\n",
       "   'spearman': SpearmanrResult(correlation=0.45481336421463037, pvalue=4.88264577230132e-11),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.6694110546960526, 1.2329453816275748e-98),\n",
       "   'spearman': SpearmanrResult(correlation=0.6472634694653674, pvalue=2.9431672663200265e-90),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.510211949987416, 1.646258618177077e-38),\n",
       "   'spearman': SpearmanrResult(correlation=0.5329648138075297, pvalue=1.733290082047313e-42),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.5856699325406816,\n",
       "    'mean': 0.5376220037140041,\n",
       "    'wmean': 0.5801134154570965},\n",
       "   'spearman': {'all': 0.5936622050356901,\n",
       "    'mean': 0.5450138824958425,\n",
       "    'wmean': 0.5802670589877431}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.36472585032695737,\n",
       "    1.3227961603838087e-15),\n",
       "   'spearman': SpearmanrResult(correlation=0.35545980649466086, pvalue=7.55513382490159e-15),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7683296758806618, 1.0728367710188497e-59),\n",
       "   'spearman': SpearmanrResult(correlation=0.7389777414249321, pvalue=4.8239687515803875e-53),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.6348757456885733, 7.20135566360036e-86),\n",
       "   'spearman': SpearmanrResult(correlation=0.5859249511072411, pvalue=2.4500494881349765e-70),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.5507593517325867, 1.0311792158491715e-60),\n",
       "   'spearman': SpearmanrResult(correlation=0.5387329474627603, pvalue=1.1202967530316328e-57),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.6533946511397615, 1.6599832540450025e-92),\n",
       "   'spearman': SpearmanrResult(correlation=0.6920056511453007, pvalue=5.7725936815804875e-108),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.6647145464755806, 8.465611947069017e-97),\n",
       "   'spearman': SpearmanrResult(correlation=0.6181114132535963, pvalue=3.064172905111514e-80),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.5123209908369638,\n",
       "    'mean': 0.606133303540687,\n",
       "    'wmean': 0.6059823351169882},\n",
       "   'spearman': {'all': 0.49683700844088435,\n",
       "    'mean': 0.5882020851480819,\n",
       "    'wmean': 0.5887283886871336}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.603409232754371,\n",
       "    1.4616875464714208e-38),\n",
       "   'spearman': SpearmanrResult(correlation=0.5954663469352386, pvalue=2.368339168178236e-37),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.6659531469580959, 2.7958871368783994e-97),\n",
       "   'spearman': SpearmanrResult(correlation=0.6674568987469179, pvalue=7.232032335853489e-98),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.7050974077225625, 1.2096608384284014e-57),\n",
       "   'spearman': SpearmanrResult(correlation=0.7057773978954841, pvalue=8.46383028295922e-58),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.6910012542894907, 1.564500094995091e-107),\n",
       "   'spearman': SpearmanrResult(correlation=0.6798318340078298, pvalue=7.809274429405902e-103),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7102334007352286, 3.816477426463952e-116),\n",
       "   'spearman': SpearmanrResult(correlation=0.7197122444235894, pvalue=1.1791095233860959e-120),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.6531874281178465,\n",
       "    'mean': 0.6751388884919497,\n",
       "    'wmean': 0.6803602805553205},\n",
       "   'spearman': {'all': 0.6602504226080194,\n",
       "    'mean': 0.6736489444018119,\n",
       "    'wmean': 0.6794057123984247}}}}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "results = evaluate_model()\n",
    "results"
   ]
  },
  {
   "source": [
    "## 3. Trainer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-05,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=1,\n",
    "    eval_steps=100,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='2' max='125001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [     2/125001 : < :, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d79ff4facd78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'trained_model/bert_cl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    907\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                             \u001b[0;31m# Revert to normal clipping otherwise, handling Apex or full precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                             torch.nn.utils.clip_grad_norm_(\n\u001b[0m\u001b[1;32m    910\u001b[0m                                 \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = 'trained_model/bert_cl'\n",
    "\n",
    "train_result = trainer.train(model_path=model_path)"
   ]
  },
  {
   "source": [
    "## 4. Evaluate Bert CL Model performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "STS12:  0.5675054534807098\nSTS13:  0.7281554777556237\nSTS14:  0.6335945639499094\nSTS15:  0.7600618289222154\nSTSB:  0.7113600318308351\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7414994287646051, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7102657603877065, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7561389569108177, 3.798134217661319e-278),\n",
       "   'spearman': SpearmanrResult(correlation=0.7619754084096394, pvalue=5.964770119842861e-285),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7272632396921386, 2.519373640229751e-227),\n",
       "   'spearman': SpearmanrResult(correlation=0.7113600318308351, pvalue=3.899147457192333e-213),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.7409343456431441,\n",
       "    'mean': 0.7416338751225204,\n",
       "    'wmean': 0.7417692001471257},\n",
       "   'spearman': {'all': 0.7242768878083036,\n",
       "    'mean': 0.7278670668760604,\n",
       "    'wmean': 0.7194305114717322}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.4222923718591043, 8.57578903746429e-34),\n",
       "   'spearman': SpearmanrResult(correlation=0.44805503021367254, pvalue=2.5934246235314064e-38),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.8216320722327597, 9.008398593888601e-185),\n",
       "   'spearman': SpearmanrResult(correlation=0.8224521757114495, pvalue=1.9001860085853616e-185),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.515932053409946, 1.38994143544846e-32),\n",
       "   'spearman': SpearmanrResult(correlation=0.6361195670121766, pvalue=2.0073558639855149e-53),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7063674433121332, 2.339608699650211e-114),\n",
       "   'spearman': SpearmanrResult(correlation=0.6730993478716646, pvalue=4.214053033034443e-100),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6377911909856145, 6.021450884970318e-47),\n",
       "   'spearman': SpearmanrResult(correlation=0.592244370741714, pvalue=3.900329830774243e-39),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.5997480478874818,\n",
       "    'mean': 0.6208030263599116,\n",
       "    'wmean': 0.6287034791735596},\n",
       "   'spearman': {'all': 0.5675054534807098,\n",
       "    'mean': 0.6343940983101355,\n",
       "    'wmean': 0.638992696438907}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.5694793932541152, 1.2214646800640155e-17),\n",
       "   'spearman': SpearmanrResult(correlation=0.5961879275288781, pvalue=1.4193953559878053e-19),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7420908383714201, 4.395069615722071e-132),\n",
       "   'spearman': SpearmanrResult(correlation=0.7354621848399308, pvalue=1.4108626665057556e-128),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7227932372149044, 9.102418326515145e-92),\n",
       "   'spearman': SpearmanrResult(correlation=0.7306309556286554, pvalue=1.056805898338835e-94),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.7164135927850692,\n",
       "    'mean': 0.6781211562801466,\n",
       "    'wmean': 0.7131244934541028},\n",
       "   'spearman': {'all': 0.7281554777556237,\n",
       "    'mean': 0.6874270226658213,\n",
       "    'wmean': 0.7161067486937212}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.5019017369809224,\n",
       "    4.3539754826687756e-30),\n",
       "   'spearman': SpearmanrResult(correlation=0.4946313770319897, pvalue=3.825933770320795e-29),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7697641789575917, 4.789342131169548e-60),\n",
       "   'spearman': SpearmanrResult(correlation=0.7385259182396289, pvalue=6.008500685858838e-53),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7049380312712636, 1.0535980470866028e-113),\n",
       "   'spearman': SpearmanrResult(correlation=0.6637393508292739, pvalue=2.0176872615970892e-96),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.790724748035009, 1.405211241125639e-161),\n",
       "   'spearman': SpearmanrResult(correlation=0.7471930174723529, pvalue=7.405524469828097e-135),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.791700818533508, 2.9948952846341616e-162),\n",
       "   'spearman': SpearmanrResult(correlation=0.7992326565124671, pvalue=1.4849531102438301e-167),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7202080658733282, 6.768588341161651e-121),\n",
       "   'spearman': SpearmanrResult(correlation=0.6381107170508609, pvalue=5.380284170286621e-87),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.6736347978764035,\n",
       "    'mean': 0.7132062632752706,\n",
       "    'wmean': 0.7233236754969398},\n",
       "   'spearman': {'all': 0.6335945639499094,\n",
       "    'mean': 0.6802388395227622,\n",
       "    'wmean': 0.6880929870760001}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.7030912320822422,\n",
       "    3.448821341945262e-57),\n",
       "   'spearman': SpearmanrResult(correlation=0.7006192528198204, pvalue=1.2390629001684323e-56),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.6914119650712299, 1.041188331753728e-107),\n",
       "   'spearman': SpearmanrResult(correlation=0.6911753670565828, pvalue=1.3165619927070525e-107),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.7852944161965156, 1.1290529417546076e-79),\n",
       "   'spearman': SpearmanrResult(correlation=0.7975877148297975, pvalue=6.702458024498846e-84),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7721763192760744, 1.820970919218139e-149),\n",
       "   'spearman': SpearmanrResult(correlation=0.769377927402412, pvalue=9.730567470252223e-148),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8366643492131784, 9.582482417372567e-198),\n",
       "   'spearman': SpearmanrResult(correlation=0.8456620741198532, pvalue=3.69071021206184e-206),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7535023298767061,\n",
       "    'mean': 0.7577276563678481,\n",
       "    'wmean': 0.7611113644249654},\n",
       "   'spearman': {'all': 0.7600618289222154,\n",
       "    'mean': 0.7608844672456933,\n",
       "    'wmean': 0.7638297131009143}}}}"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "results = evaluate_model()\n",
    "results"
   ]
  }
 ]
}