{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Contrastive Learning From Scratch - DistilBERT\n",
    "\n",
    "An attempt to build contrastive learning model from scratch. Parts include:\n",
    "\n",
    "- Loading and preparing Wiki-1M data for model input\n",
    "- Contrastive learning model\n",
    "  - Forward passing using pre-trained model\n",
    "  - Constrastive layer\n",
    "  - Calculate loss\n",
    "- Training procedure\n",
    "  - Default trainer optimizer\n",
    "  - Default trainer hyper-parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/workspace/gatech/cs7643-deep-learning/contrastive-learning-in-distilled-models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set Project home\n",
    "PROJECT_HOME = os.path.join('/',\n",
    "                            'workspace',\n",
    "                            'gatech',\n",
    "                            'cs7643-deep-learning',\n",
    "                            'contrastive-learning-in-distilled-models')\n",
    "%cd {PROJECT_HOME}\n",
    "\n",
    "# Load project code\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "import distilface"
   ]
  },
  {
   "source": [
    "## 1. Loading and Preparing Wiki-1M data\n",
    "\n",
    "Use huggingface `datasets` library to load local file data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset text (./data/text/default-c7a268390f38dfb5/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {'train': 'data/training/wiki1m_for_simcse.txt'}\n",
    "# data_files = {'train': 'data/training/wiki5k.txt'}\n",
    "datasets = load_dataset('text', data_files=data_files, cache_dir='./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "column_names: ['text']\nsent0_cname: text | sent1_cname: text\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised / Self-supervised dataset\n",
    "\n",
    "column_names = datasets[\"train\"].column_names\n",
    "sent0_cname = column_names[0]\n",
    "sent1_cname = column_names[0]\n",
    "\n",
    "print('column_names:', column_names)\n",
    "print('sent0_cname:', sent0_cname, '| sent1_cname:', sent1_cname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(examples):\n",
    "    total = len(examples[sent0_cname])\n",
    "\n",
    "    # Avoid \"None\" fields \n",
    "    for idx in range(total):\n",
    "        if examples[sent0_cname][idx] is None:\n",
    "            examples[sent0_cname][idx] = \" \"\n",
    "        if examples[sent1_cname][idx] is None:\n",
    "            examples[sent1_cname][idx] = \" \"\n",
    "    \n",
    "    sentences = examples[sent0_cname] + examples[sent1_cname]\n",
    "\n",
    "    sent_features = tokenizer(\n",
    "        sentences,\n",
    "        max_length=32,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    features = {}\n",
    "    for key in sent_features:\n",
    "        features[key] = [[sent_features[key][i], sent_features[key][i+total]] for i in range(total)]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading cached processed dataset at ./data/text/default-c7a268390f38dfb5/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab/cache-640fd6c007024e6d.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"].map(prepare_features,\n",
    "                                      batched=True,\n",
    "                                    #   num_proc=24,\n",
    "                                      remove_columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[101, 26866, 1999, 2148, 2660, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "str(train_dataset['input_ids'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[101, 26866, 1999, 2148, 2660, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "str(train_dataset['input_ids'][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['attention_mask', 'input_ids'])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_dataset.features.keys()"
   ]
  },
  {
   "source": [
    "Sentence 1 and Sentence 2 are the same sentence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Contrastive Learning Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel, DistilBertPreTrainedModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPooling\n",
    "\n",
    "from distilface.modules.pooler import Pooler\n",
    "from distilface.modules.similarity import Similarity\n",
    "\n",
    "\n",
    "class DistilBertCLModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type='avg_first_last', temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = 0.05\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        if self.training:\n",
    "            return self.cl_forward(self.distilbert, input_ids, attention_mask)\n",
    "        else:\n",
    "            return self.sent_emb(self.distilbert, input_ids, attention_mask)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None):\n",
    "        batch_size = input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "\n",
    "pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model.eval();\n"
   ]
  },
  {
   "source": [
    "### 2.1 Initial DistilBERT embeddings performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senteval\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [\" \".join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    pooled_result = outputs.pooler_output.cpu()\n",
    "\n",
    "    return pooled_result\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    PATH_TO_DATA = \"./data\"\n",
    "\n",
    "    params = {\"task_path\": PATH_TO_DATA, \"usepytorch\": True, \"kfold\": 10}\n",
    "    tasks = [\"STSBenchmark\", 'STS12', 'STS13', 'STS14', 'STS15']\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    results = se.eval(tasks)\n",
    "\n",
    "    print('STS12: ', results[\"STS12\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS13: ', results[\"STS13\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS14: ', results[\"STS14\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS15: ', results[\"STS15\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STSB: ', results[\"STSBenchmark\"][\"test\"][\"spearman\"][0])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "/opt/conda/lib/python3.8/site-packages/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
      "STS12:  0.4759496219560386\n",
      "STS13:  0.6186604918388178\n",
      "STS14:  0.529448785151832\n",
      "STS15:  0.6969405564295094\n",
      "STSB:  0.590522771009074\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.6070898833059735, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.595530733737618, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.6714695361612271, 3.181586253494327e-197),\n",
       "   'spearman': SpearmanrResult(correlation=0.684281683692436, pvalue=1.0932311093348739e-207),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.5632638275139215, 2.904861571468197e-116),\n",
       "   'spearman': SpearmanrResult(correlation=0.590522771009074, pvalue=2.1926696952431418e-130),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.6130842362054584,\n",
       "    'mean': 0.6139410823270407,\n",
       "    'wmean': 0.6112778003604056},\n",
       "   'spearman': {'all': 0.6146094901418286,\n",
       "    'mean': 0.6234450628130427,\n",
       "    'wmean': 0.6101598997470715}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.42118852134498924, 1.3132388124236085e-33),\n",
       "   'spearman': SpearmanrResult(correlation=0.45987913574306377, pvalue=1.6077021457625966e-40),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.6353183755632953, 5.058935379408691e-86),\n",
       "   'spearman': SpearmanrResult(correlation=0.6401653435062138, pvalue=1.01909306957718e-87),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.5022991758974056, 1.0330845783563171e-30),\n",
       "   'spearman': SpearmanrResult(correlation=0.593108964857006, pvalue=5.966597000821263e-45),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.6877112839097088, 3.9843540280713794e-106),\n",
       "   'spearman': SpearmanrResult(correlation=0.6910592978736139, pvalue=1.4770691983640824e-107),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6239852699142427, 1.9235996820216506e-44),\n",
       "   'spearman': SpearmanrResult(correlation=0.5515905054750513, pvalue=3.845074453301283e-33),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.4514817247780837,\n",
       "    'mean': 0.5741005253259284,\n",
       "    'wmean': 0.5751895366943974},\n",
       "   'spearman': {'all': 0.4759496219560386,\n",
       "    'mean': 0.5871606494909898,\n",
       "    'wmean': 0.5906208041814929}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.47209866830646435, 6.9906027112638295e-12),\n",
       "   'spearman': SpearmanrResult(correlation=0.5056664404698936, pvalue=1.1578223671604005e-13),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7104457068991469, 3.038405356285829e-116),\n",
       "   'spearman': SpearmanrResult(correlation=0.6922560331048998, pvalue=4.49937035272065e-108),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.5347971537565253, 8.039519311877988e-43),\n",
       "   'spearman': SpearmanrResult(correlation=0.569561787742911, pvalue=1.4758523503130578e-49),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.6078269334929332,\n",
       "    'mean': 0.5724471763207122,\n",
       "    'wmean': 0.6147214211611284},\n",
       "   'spearman': {'all': 0.6186604918388178,\n",
       "    'mean': 0.5891614204392348,\n",
       "    'wmean': 0.6228580966675052}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.39177226292585515,\n",
       "    5.860852149740093e-18),\n",
       "   'spearman': SpearmanrResult(correlation=0.40713374181092804, pvalue=2.1430164779787128e-19),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7777919622211522, 4.700332363384712e-62),\n",
       "   'spearman': SpearmanrResult(correlation=0.7388335141224314, pvalue=5.174477925809937e-53),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.6712068055660643, 2.397242803190302e-99),\n",
       "   'spearman': SpearmanrResult(correlation=0.6258703123979473, pvalue=8.392362421315577e-83),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.6678021402372105, 5.2959922969942754e-98),\n",
       "   'spearman': SpearmanrResult(correlation=0.6483582887347493, pvalue=1.1778301337823169e-90),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.6719083131788053, 1.260395961204209e-99),\n",
       "   'spearman': SpearmanrResult(correlation=0.7121770827042612, pvalue=4.6966715914915416e-117),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.6737572677319621, 2.295668031830716e-100),\n",
       "   'spearman': SpearmanrResult(correlation=0.6339299396207194, pvalue=1.528491970701118e-85),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.5359822774117559,\n",
       "    'mean': 0.6423731253101749,\n",
       "    'wmean': 0.6461709338716033},\n",
       "   'spearman': {'all': 0.529448785151832,\n",
       "    'mean': 0.6277171465651729,\n",
       "    'wmean': 0.6320298548386413}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.6212492347174632,\n",
       "    2.0922866505343168e-41),\n",
       "   'spearman': SpearmanrResult(correlation=0.6091012142226292, pvalue=1.892153126782441e-39),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7166594053705535, 3.502221048785232e-119),\n",
       "   'spearman': SpearmanrResult(correlation=0.7213942481037702, pvalue=1.7851662394062188e-121),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.6882099250704323, 6.26823241656747e-54),\n",
       "   'spearman': SpearmanrResult(correlation=0.7037856898795638, pvalue=2.4021426177349297e-57),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7268846060435941, 3.41047900856589e-124),\n",
       "   'spearman': SpearmanrResult(correlation=0.7141356881906937, pvalue=5.587660680826606e-118),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7687787371034291, 2.2642315836193107e-147),\n",
       "   'spearman': SpearmanrResult(correlation=0.7762450890337114, pvalue=5.052292463526242e-152),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.685110043092448,\n",
       "    'mean': 0.7043563816610945,\n",
       "    'wmean': 0.7167630821028812},\n",
       "   'spearman': {'all': 0.6969405564295094,\n",
       "    'mean': 0.7049323858860737,\n",
       "    'wmean': 0.717054619344818}}}}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "results = evaluate_model()\n",
    "results"
   ]
  },
  {
   "source": [
    "## 3. Trainer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-05,\n",
    "    weight_decay=0.0,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=1500,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 02:06, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "model_path = 'trained_model/distilbert_cl'\n",
    "\n",
    "train_result = trainer.train(model_path=model_path)"
   ]
  },
  {
   "source": [
    "## 4. Evaluate DistilBert CL Model performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "/opt/conda/lib/python3.8/site-packages/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
      "STS12:  0.606808656062751\n",
      "STS13:  0.7813506166310635\n",
      "STS14:  0.683820932414784\n",
      "STS15:  0.7873980626574266\n",
      "STSB:  0.7588590595903669\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.771976596844894, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7364594283237442, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.8061169486988025, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.8058723212656451, pvalue=0.0),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7702848097245685, 2.5255131120930325e-271),\n",
       "   'spearman': SpearmanrResult(correlation=0.7588590595903669, pvalue=9.70782246819368e-259),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.7780259799993474,\n",
       "    'mean': 0.7827927850894216,\n",
       "    'wmean': 0.7776415891191097},\n",
       "   'spearman': {'all': 0.7563435928533441,\n",
       "    'mean': 0.7670636030599187,\n",
       "    'wmean': 0.7521071370545653}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.5097282767201947, 7.7161138904291e-51),\n",
       "   'spearman': SpearmanrResult(correlation=0.5206510764473636, pvalue=2.4522876436761703e-53),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.8598572737481505, 1.3582537060526376e-220),\n",
       "   'spearman': SpearmanrResult(correlation=0.8536278420207454, pvalue=4.521281998277874e-214),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.5337538540946184, 3.6797261687252373e-35),\n",
       "   'spearman': SpearmanrResult(correlation=0.6066504638102937, pvalue=1.766674184677687e-47),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.7362511422358708, 5.466403087307609e-129),\n",
       "   'spearman': SpearmanrResult(correlation=0.6945459475881116, pvalue=4.552394902101671e-109),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.5643884006338988, 6.123974435933927e-35),\n",
       "   'spearman': SpearmanrResult(correlation=0.5501437110905522, pvalue=6.071632289014993e-33),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.6748850716148578,\n",
       "    'mean': 0.6407957894865467,\n",
       "    'wmean': 0.6594470754216595},\n",
       "   'spearman': {'all': 0.606808656062751,\n",
       "    'mean': 0.6451238081914134,\n",
       "    'wmean': 0.6594525589305729}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.5755591368462838, 4.590699698129527e-18),\n",
       "   'spearman': SpearmanrResult(correlation=0.6152795474078885, pvalue=4.517669636789221e-21),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7543072287496407, 7.746797136503595e-139),\n",
       "   'spearman': SpearmanrResult(correlation=0.7451224242173102, pvalue=1.0070913125566946e-133),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.8322141182986467, 2.6819780008908732e-145),\n",
       "   'spearman': SpearmanrResult(correlation=0.815901283899474, pvalue=4.1113233657772975e-135),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.7760849733599291,\n",
       "    'mean': 0.7206934946315237,\n",
       "    'wmean': 0.7609221458611459},\n",
       "   'spearman': {'all': 0.7813506166310635,\n",
       "    'mean': 0.7254344185082243,\n",
       "    'wmean': 0.7552335152604523}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.5401468310480687,\n",
       "    1.913587064661618e-35),\n",
       "   'spearman': SpearmanrResult(correlation=0.536835464443354, pvalue=5.930673603413892e-35),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7595457854573044, 1.3224224612180616e-57),\n",
       "   'spearman': SpearmanrResult(correlation=0.7398922938724247, pvalue=3.0886761864436067e-53),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7113944332432828, 1.0941390677336096e-116),\n",
       "   'spearman': SpearmanrResult(correlation=0.6656004702743946, pvalue=3.8348979459416577e-97),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8293856224664827, 2.6414184589590222e-191),\n",
       "   'spearman': SpearmanrResult(correlation=0.7864765895225755, pvalue=1.0676262402280548e-158),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.870271967124157, 3.1048394269932814e-232),\n",
       "   'spearman': SpearmanrResult(correlation=0.858041707171333, pvalue=1.1641183120990557e-218),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7575397161865152, 1.084233675012643e-140),\n",
       "   'spearman': SpearmanrResult(correlation=0.6851238185567445, pvalue=4.931868656857751e-105),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7317425761055674,\n",
       "    'mean': 0.7447140592543019,\n",
       "    'wmean': 0.7592996303664401},\n",
       "   'spearman': {'all': 0.683820932414784,\n",
       "    'mean': 0.7119950573068045,\n",
       "    'wmean': 0.722660156348006}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.7557372938025484,\n",
       "    1.457547256293759e-70),\n",
       "   'spearman': SpearmanrResult(correlation=0.762253091399444, pvalue=1.862187889024809e-72),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.6867655764818565,\n",
       "    1.0024090436001581e-105),\n",
       "   'spearman': SpearmanrResult(correlation=0.6826580689479851, pvalue=5.293053401528745e-104),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.7924111882302503, 4.3733752719399826e-82),\n",
       "   'spearman': SpearmanrResult(correlation=0.8055835280854381, pvalue=8.259513568536688e-87),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7707632141630238, 1.3673643991568905e-148),\n",
       "   'spearman': SpearmanrResult(correlation=0.7644367168442467, pvalue=9.550144950988618e-145),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8624211894434151, 2.271650069870243e-223),\n",
       "   'spearman': SpearmanrResult(correlation=0.8689742480566297, pvalue=9.923878934555919e-231),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7826143211176098,\n",
       "    'mean': 0.7736196924242188,\n",
       "    'wmean': 0.7735060552761737},\n",
       "   'spearman': {'all': 0.7873980626574266,\n",
       "    'mean': 0.7767811306667487,\n",
       "    'wmean': 0.7749968358978256}}}}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "results = evaluate_model()\n",
    "results"
   ]
  }
 ]
}