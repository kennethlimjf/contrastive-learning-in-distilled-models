{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Learning From Scratch - DistilBERT\n",
    "\n",
    "An attempt to build contrastive learning model from scratch. Parts include:\n",
    "\n",
    "- Loading and preparing Wiki-1M data for model input\n",
    "- Contrastive learning model\n",
    "  - Forward passing using pre-trained model\n",
    "  - Constrastive layer\n",
    "  - Calculate loss\n",
    "- Training procedure\n",
    "  - Default trainer optimizer\n",
    "  - Default trainer hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/gatech/cs7643-deep-learning/contrastive-learning-in-distilled-models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set Project home\n",
    "PROJECT_HOME = os.path.join('/',\n",
    "                            'workspace',\n",
    "                            'gatech',\n",
    "                            'cs7643-deep-learning',\n",
    "                            'contrastive-learning-in-distilled-models')\n",
    "%cd {PROJECT_HOME}\n",
    "\n",
    "# Load project code\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "import distilface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "pooling_method = 'avg'\n",
    "batch_size = 64\n",
    "epochs = 2\n",
    "max_steps = 30_000\n",
    "temperature = 0.05\n",
    "learning_rate = 5e-5\n",
    "max_len = 32\n",
    "fp16 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preparing Wiki-1M data\n",
    "\n",
    "Use huggingface `datasets` library to load local file data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c294b10b923459c8\n",
      "Reusing dataset text (./data/text/default-c294b10b923459c8/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b011d33f9bda4a2b9a08b6d1c9d01ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {'train': 'data/training/wiki1m_for_simcse.txt'}\n",
    "# data_files = {'train': 'data/training/wiki5k.txt'}\n",
    "datasets = load_dataset('text', data_files=data_files, cache_dir='./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised / Self-supervised dataset\n",
    "\n",
    "column_names = datasets[\"train\"].column_names\n",
    "sent0_cname = column_names[0]\n",
    "sent1_cname = column_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(examples):\n",
    "    total = len(examples[sent0_cname])\n",
    "\n",
    "    # Avoid \"None\" fields \n",
    "    for idx in range(total):\n",
    "        if examples[sent0_cname][idx] is None:\n",
    "            examples[sent0_cname][idx] = \" \"\n",
    "        if examples[sent1_cname][idx] is None:\n",
    "            examples[sent1_cname][idx] = \" \"\n",
    "\n",
    "    sentences = examples[sent0_cname] + examples[sent1_cname]\n",
    "\n",
    "    sent_features = tokenizer(\n",
    "        sentences,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    features = {}\n",
    "    for key in sent_features:\n",
    "        features[key] = [[sent_features[key][i], sent_features[key][i+total]] for i in range(total)]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ./data/text/default-c294b10b923459c8/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-c4bf6d1c3203683e.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"].map(prepare_features,\n",
    "                                      batched=True,\n",
    "                                    #   num_proc=24,\n",
    "                                      remove_columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Contrastive Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertCLModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertCLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertCLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel, DistilBertPreTrainedModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPooling\n",
    "\n",
    "from distilface.modules.pooler import Pooler\n",
    "from distilface.modules.similarity import Similarity\n",
    "\n",
    "\n",
    "class DistilBertCLModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, pooler_type=pooling_method, temp=temperature):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.pooler_type = pooler_type\n",
    "        self.temp = temperature\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pooler = Pooler(pooler_type)\n",
    "        self.sim = Similarity(temp=temp)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        if self.training:\n",
    "            return self.cl_forward(self.distilbert, input_ids, attention_mask)\n",
    "        else:\n",
    "            return self.sent_emb(self.distilbert, input_ids, attention_mask)\n",
    "\n",
    "    def cl_forward(self, encoder, input_ids=None, attention_mask=None):\n",
    "        batch_size = input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # Number of sentences in one instance: 2 sentences\n",
    "\n",
    "        # Flatten all input tensors\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "\n",
    "        # Pre-trained Model Encoder\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # Pooling\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "        pooler_output = pooler_output.view((batch_size, num_sent, pooler_output.size(-1)))  # (bs, num_sent, hidden)\n",
    "\n",
    "        # Separate representation\n",
    "        z1, z2 = pooler_output[:, 0], pooler_output[:, 1]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def sent_emb(self, encoder, input_ids=None, attention_mask=None):\n",
    "        outputs = encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooler_output = self.pooler(attention_mask, outputs)\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            pooler_output=pooler_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "\n",
    "pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model = DistilBertCLModel.from_pretrained(pretrained_model_name, config=config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initial DistilBERT embeddings performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senteval\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [\" \".join(s) for s in batch]\n",
    "    batch = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    pooled_result = outputs.pooler_output.cpu()\n",
    "\n",
    "    return pooled_result\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    PATH_TO_DATA = \"./data\"\n",
    "\n",
    "    params = {\"task_path\": PATH_TO_DATA, \"usepytorch\": True, \"kfold\": 10}\n",
    "    tasks = [\"STSBenchmark\", 'STS12', 'STS13', 'STS14', 'STS15']\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    results = se.eval(tasks)\n",
    "\n",
    "    print('STS12: ', results[\"STS12\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS13: ', results[\"STS13\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS14: ', results[\"STS14\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STS15: ', results[\"STS15\"][\"all\"][\"spearman\"][\"all\"])\n",
    "    print('STSB: ', results[\"STSBenchmark\"][\"test\"][\"spearman\"][0])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.8/site-packages/SentEval-0.1.0-py3.8.egg/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/root/.local/lib/python3.8/site-packages/SentEval-0.1.0-py3.8.egg/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.43443015229245047\n",
      "STS13:  0.6487514031881138\n",
      "STS14:  0.5412015933163623\n",
      "STS15:  0.6662516773044048\n",
      "STSB:  0.5716834482710682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.6091975834836189, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.5852399969491585, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.6598506534654376, 3.520009115276044e-188),\n",
       "   'spearman': SpearmanrResult(correlation=0.6764461625522538, pvalue=3.1719351991598352e-201),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.5676559826514312, 1.8896403029210557e-118),\n",
       "   'spearman': SpearmanrResult(correlation=0.5716834482710682, pvalue=1.7460390828514904e-120),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.6144014575168626,\n",
       "    'mean': 0.6122347398668292,\n",
       "    'wmean': 0.611364219717409},\n",
       "   'spearman': {'all': 0.6056188019716447,\n",
       "    'mean': 0.6111232025908268,\n",
       "    'wmean': 0.5989297011421993}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.3836908968138479, 1.0253160982954526e-27),\n",
       "   'spearman': SpearmanrResult(correlation=0.42938048102002657, pvalue=5.350676593605311e-35),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.5547097706799646, 9.747152009502212e-62),\n",
       "   'spearman': SpearmanrResult(correlation=0.5746992478799179, pvalue=3.8771034185032584e-67),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.4799576499073436, 8.0212780280562095e-28),\n",
       "   'spearman': SpearmanrResult(correlation=0.5893337067843926, pvalue=2.880856003894867e-44),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.6340143079269382, 1.4293997713236417e-85),\n",
       "   'spearman': SpearmanrResult(correlation=0.6543583484359415, pvalue=7.275704251139131e-93),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6488538567746898, 4.7714293445740876e-49),\n",
       "   'spearman': SpearmanrResult(correlation=0.5591560326713801, pvalue=3.4002585062080935e-34),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.40363422135900745,\n",
       "    'mean': 0.5402452964205569,\n",
       "    'wmean': 0.5336243506197345},\n",
       "   'spearman': {'all': 0.43443015229245047,\n",
       "    'mean': 0.5613855633583318,\n",
       "    'wmean': 0.5590205876614643}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.48018344038929206, 2.7111955183991846e-12),\n",
       "   'spearman': SpearmanrResult(correlation=0.5111857173913771, pvalue=5.646246899079869e-14),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.6764145861735327, 1.9429642387350894e-101),\n",
       "   'spearman': SpearmanrResult(correlation=0.6650870893435945, pvalue=6.069960959605457e-97),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.5896518243172219, 7.871220214125359e-54),\n",
       "   'spearman': SpearmanrResult(correlation=0.6177197200329575, pvalue=2.5130962094517995e-60),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.6230884322825614,\n",
       "    'mean': 0.5820832836266822,\n",
       "    'wmean': 0.6192401888704581},\n",
       "   'spearman': {'all': 0.6487514031881138,\n",
       "    'mean': 0.597997508922643,\n",
       "    'wmean': 0.6279801203554368}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.36149209360456674,\n",
       "    2.4456506334428474e-15),\n",
       "   'spearman': SpearmanrResult(correlation=0.37333446183376395, pvalue=2.4894853463680933e-16),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7684684546585734, 9.925655405444969e-60),\n",
       "   'spearman': SpearmanrResult(correlation=0.7265775320048388, pvalue=1.7018561627406473e-50),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.6460761708652663, 7.912170928819492e-90),\n",
       "   'spearman': SpearmanrResult(correlation=0.5877424347714207, pvalue=7.233946022302475e-71),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.6039249629180994, 9.782865972677557e-76),\n",
       "   'spearman': SpearmanrResult(correlation=0.5884805237058973, pvalue=4.3980653493180744e-71),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7122006273803281, 4.57848754066507e-117),\n",
       "   'spearman': SpearmanrResult(correlation=0.7413954518236964, pvalue=1.0372279368176591e-131),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.6885681284487308, 1.7218365450458042e-106),\n",
       "   'spearman': SpearmanrResult(correlation=0.6088025041366361, pvalue=2.934546471692086e-77),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.5742432954418222,\n",
       "    'mean': 0.6301217396459274,\n",
       "    'wmean': 0.6350105055277189},\n",
       "   'spearman': {'all': 0.5412015933163623,\n",
       "    'mean': 0.6043888180460422,\n",
       "    'wmean': 0.6082105208679689}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.6079737456073077,\n",
       "    2.846147513970905e-39),\n",
       "   'spearman': SpearmanrResult(correlation=0.6023339666357713, pvalue=2.1408581307900848e-38),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.6309036607334058, 1.669008993690012e-84),\n",
       "   'spearman': SpearmanrResult(correlation=0.6345951066462099, pvalue=9.005663604070645e-86),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.710272168240661, 7.781798594493387e-59),\n",
       "   'spearman': SpearmanrResult(correlation=0.7439223880100706, pvalue=2.8148605218311407e-67),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7016844222806629, 3.1308384595545867e-112),\n",
       "   'spearman': SpearmanrResult(correlation=0.6887142995458488, pvalue=1.491788284753835e-106),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7155707346319568, 1.1610457081077537e-118),\n",
       "   'spearman': SpearmanrResult(correlation=0.7209832152535437, pvalue=2.8352437173850136e-121),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.6533233081239975,\n",
       "    'mean': 0.6732809462987988,\n",
       "    'wmean': 0.6768204436425025},\n",
       "   'spearman': {'all': 0.6662516773044048,\n",
       "    'mean': 0.6781097952182888,\n",
       "    'wmean': 0.6793551996921309}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate_model()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "# import mlflow\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_epochs=epochs,\n",
    "    max_steps=max_steps,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    save_strategy='steps',\n",
    "    save_steps=max_steps,\n",
    "    fp16=fp16,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cl-distilled/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 2:28:36, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-30000\n",
      "Configuration saved in output/checkpoint-30000/config.json\n",
      "Model weights saved in output/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in output/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in output/checkpoint-30000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "# [30000/30000 2:26:08, Epoch 1/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(trainer.state.log_history).to_csv(f'logs/cl-distilled_pooling_{pooling_method}_fp16.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate DistilBert CL Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.8/site-packages/SentEval-0.1.0-py3.8.egg/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/root/.local/lib/python3.8/site-packages/SentEval-0.1.0-py3.8.egg/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS12:  0.6093238686589825\n",
      "STS13:  0.7676229347262692\n",
      "STS14:  0.678416946312019\n",
      "STS15:  0.7694737537943053\n",
      "STSB:  0.7238160334432627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'STSBenchmark': {'train': {'pearson': (0.7676559412752437, 0.0),\n",
       "   'spearman': SpearmanrResult(correlation=0.7435383430522411, pvalue=0.0),\n",
       "   'nsamples': 5749},\n",
       "  'dev': {'pearson': (0.7871453260861279, 1.04696364e-316),\n",
       "   'spearman': SpearmanrResult(correlation=0.7888545878028007, pvalue=5.0968e-319),\n",
       "   'nsamples': 1500},\n",
       "  'test': {'pearson': (0.7356335858476611, 3.3216539772929344e-235),\n",
       "   'spearman': SpearmanrResult(correlation=0.7238160334432627, pvalue=3.644327634816282e-224),\n",
       "   'nsamples': 1379},\n",
       "  'all': {'pearson': {'all': 0.7661128650053888,\n",
       "    'mean': 0.7634782844030109,\n",
       "    'wmean': 0.765926137042709},\n",
       "   'spearman': {'all': 0.7525692443111563,\n",
       "    'mean': 0.7520696547661014,\n",
       "    'wmean': 0.7482645023214874}}},\n",
       " 'STS12': {'MSRpar': {'pearson': (0.6555915230013849, 2.520889303227067e-93),\n",
       "   'spearman': SpearmanrResult(correlation=0.6285462156170082, pvalue=1.0549890600280447e-83),\n",
       "   'nsamples': 750},\n",
       "  'MSRvid': {'pearson': (0.8301916935288001, 5.2937812154077136e-192),\n",
       "   'spearman': SpearmanrResult(correlation=0.8258256989560865, pvalue=2.8941079208350294e-188),\n",
       "   'nsamples': 750},\n",
       "  'SMTeuroparl': {'pearson': (0.4815939932964578, 5.008517435611413e-28),\n",
       "   'spearman': SpearmanrResult(correlation=0.5894831590186032, pvalue=2.707838263926242e-44),\n",
       "   'nsamples': 459},\n",
       "  'surprise.OnWN': {'pearson': (0.6796955379586056, 8.884813827964813e-103),\n",
       "   'spearman': SpearmanrResult(correlation=0.6634996863036335, pvalue=2.4965240824099715e-96),\n",
       "   'nsamples': 750},\n",
       "  'surprise.SMTnews': {'pearson': (0.6047095932547661, 3.7838328593124024e-41),\n",
       "   'spearman': SpearmanrResult(correlation=0.5560648381465507, pvalue=9.229391549423176e-34),\n",
       "   'nsamples': 399},\n",
       "  'all': {'pearson': {'all': 0.6575717086509739,\n",
       "    'mean': 0.6503564682080029,\n",
       "    'wmean': 0.6713126887060227},\n",
       "   'spearman': {'all': 0.6093238686589825,\n",
       "    'mean': 0.6526839196083764,\n",
       "    'wmean': 0.6695129797514668}}},\n",
       " 'STS13': {'FNWN': {'pearson': (0.49896573542469047, 2.7215685645829757e-13),\n",
       "   'spearman': SpearmanrResult(correlation=0.5302604097059794, pvalue=4.2605323147387145e-15),\n",
       "   'nsamples': 189},\n",
       "  'headlines': {'pearson': (0.7688003175550495, 2.1964942903937028e-147),\n",
       "   'spearman': SpearmanrResult(correlation=0.7605695673675379, pvalue=1.8648953591874136e-142),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.7878701011023027, 8.795119191009057e-120),\n",
       "   'spearman': SpearmanrResult(correlation=0.7821857231332288, pvalue=5.898280239835274e-117),\n",
       "   'nsamples': 561},\n",
       "  'all': {'pearson': {'all': 0.761477005512687,\n",
       "    'mean': 0.685212051360681,\n",
       "    'wmean': 0.7419332592532971},\n",
       "   'spearman': {'all': 0.7676229347262692,\n",
       "    'mean': 0.6910052334022486,\n",
       "    'wmean': 0.7396350557585498}}},\n",
       " 'STS14': {'deft-forum': {'pearson': (0.5317746817469563,\n",
       "    3.2618765155829645e-34),\n",
       "   'spearman': SpearmanrResult(correlation=0.5270482208879024, pvalue=1.562168661178578e-33),\n",
       "   'nsamples': 450},\n",
       "  'deft-news': {'pearson': (0.7807636071178579, 8.078760979053127e-63),\n",
       "   'spearman': SpearmanrResult(correlation=0.759943004941987, pvalue=1.0684796183819364e-57),\n",
       "   'nsamples': 300},\n",
       "  'headlines': {'pearson': (0.7439390930858514, 4.425255500881122e-133),\n",
       "   'spearman': SpearmanrResult(correlation=0.7140851189881164, pvalue=5.904719905564992e-118),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.7778211202289954, 4.995270876353136e-153),\n",
       "   'spearman': SpearmanrResult(correlation=0.7515820492530997, pvalue=2.690649170299661e-137),\n",
       "   'nsamples': 750},\n",
       "  'OnWN': {'pearson': (0.8200875341488617, 1.6524299673237773e-183),\n",
       "   'spearman': SpearmanrResult(correlation=0.8226052949911472, pvalue=1.419786939414026e-185),\n",
       "   'nsamples': 750},\n",
       "  'tweet-news': {'pearson': (0.7416085848737971, 7.974567887000873e-132),\n",
       "   'spearman': SpearmanrResult(correlation=0.6895403916059865, pvalue=6.622253396037335e-107),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7123050042854537,\n",
       "    'mean': 0.7326657702003866,\n",
       "    'wmean': 0.7429653168465645},\n",
       "   'spearman': {'all': 0.678416946312019,\n",
       "    'mean': 0.7108006801113733,\n",
       "    'wmean': 0.7196037978695772}}},\n",
       " 'STS15': {'answers-forums': {'pearson': (0.7074118908837406,\n",
       "    3.5722041364833995e-58),\n",
       "   'spearman': SpearmanrResult(correlation=0.7089478570704206, pvalue=1.5794992383499075e-58),\n",
       "   'nsamples': 375},\n",
       "  'answers-students': {'pearson': (0.7151078684466043,\n",
       "    1.9293426132941398e-118),\n",
       "   'spearman': SpearmanrResult(correlation=0.7167799712412827, pvalue=3.065833344737e-119),\n",
       "   'nsamples': 750},\n",
       "  'belief': {'pearson': (0.7655996418111196, 1.877576920432038e-73),\n",
       "   'spearman': SpearmanrResult(correlation=0.7806433378059563, pvalue=3.8004193594498053e-78),\n",
       "   'nsamples': 375},\n",
       "  'headlines': {'pearson': (0.7748753533171167, 3.7172814490296167e-151),\n",
       "   'spearman': SpearmanrResult(correlation=0.7743409113859467, pvalue=8.067653130642207e-151),\n",
       "   'nsamples': 750},\n",
       "  'images': {'pearson': (0.8459934894096032, 1.7658155985414938e-206),\n",
       "   'spearman': SpearmanrResult(correlation=0.8507810774386246, pvalue=3.4334686558931564e-211),\n",
       "   'nsamples': 750},\n",
       "  'all': {'pearson': {'all': 0.7681423611868123,\n",
       "    'mean': 0.7617976487736369,\n",
       "    'wmean': 0.7681206193801885},\n",
       "   'spearman': {'all': 0.7694737537943053,\n",
       "    'mean': 0.7662986309884463,\n",
       "    'wmean': 0.7716743893760106}}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "results = evaluate_model()\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl-distilled",
   "language": "python",
   "name": "cl-distilled"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
